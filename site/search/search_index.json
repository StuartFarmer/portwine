{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Portwine Portwine is a clean, elegant portfolio backtester that makes strategy development and testing simple and intuitive. What is Portwine? Portfolio construction, optimization, and backtesting can be a complicated web of data wrangling, signal generation, lookahead bias reduction, and parameter tuning. But with portwine , strategies are clear and written in an 'online' fashion that removes most of the complexity that comes with backtesting, analyzing, and deploying your trading strategies. Key Features \ud83c\udfaf Simple Strategies Strategies are only given the last day of prices to make their determinations and allocate weights. This allows them to be completely encapsulated and portable. \u26a1 Breezy Backtesting Backtesting strategies is a breeze. Simply tell the backtester where your data is located with a data loader manager and give it a strategy. You get results immediately. \ud83d\udcca Streamlined Data Managing data can be a massive pain. But as long as you have your daily flat files from EODHD or Polygon saved in a directory, the data loaders will manage the rest. \ud83d\udcc8 Effortless Analysis After running a strategy through the backtester, put it through an array of analyzers that are simple, visual, and clear. Quick Start pip install portwine from portwine import SimpleMomentumStrategy , Backtester , EODHDMarketDataLoader # Define your universe universe = [ 'MTUM' , 'VTV' , 'VUG' , 'IJR' , 'MDY' ] # Create a strategy strategy = SimpleMomentumStrategy ( tickers = universe , lookback_days = 10 ) # Set up data and backtester data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/data/' ) backtester = Backtester ( market_data_loader = data_loader ) # Run backtest results = backtester . run_backtest ( strategy , benchmark_ticker = 'SPY' ) What's Next? Installation - Get portwine up and running Quick Start - Your first strategy in minutes User Guide - Learn how to build strategies API Reference - Complete API documentation Examples - See portwine in action Contributing We welcome contributions! See our Contributing Guide for details on how to get started.","title":"Home"},{"location":"#welcome-to-portwine","text":"Portwine is a clean, elegant portfolio backtester that makes strategy development and testing simple and intuitive.","title":"Welcome to Portwine"},{"location":"#what-is-portwine","text":"Portfolio construction, optimization, and backtesting can be a complicated web of data wrangling, signal generation, lookahead bias reduction, and parameter tuning. But with portwine , strategies are clear and written in an 'online' fashion that removes most of the complexity that comes with backtesting, analyzing, and deploying your trading strategies.","title":"What is Portwine?"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#simple-strategies","text":"Strategies are only given the last day of prices to make their determinations and allocate weights. This allows them to be completely encapsulated and portable.","title":"\ud83c\udfaf Simple Strategies"},{"location":"#breezy-backtesting","text":"Backtesting strategies is a breeze. Simply tell the backtester where your data is located with a data loader manager and give it a strategy. You get results immediately.","title":"\u26a1 Breezy Backtesting"},{"location":"#streamlined-data","text":"Managing data can be a massive pain. But as long as you have your daily flat files from EODHD or Polygon saved in a directory, the data loaders will manage the rest.","title":"\ud83d\udcca Streamlined Data"},{"location":"#effortless-analysis","text":"After running a strategy through the backtester, put it through an array of analyzers that are simple, visual, and clear.","title":"\ud83d\udcc8 Effortless Analysis"},{"location":"#quick-start","text":"pip install portwine from portwine import SimpleMomentumStrategy , Backtester , EODHDMarketDataLoader # Define your universe universe = [ 'MTUM' , 'VTV' , 'VUG' , 'IJR' , 'MDY' ] # Create a strategy strategy = SimpleMomentumStrategy ( tickers = universe , lookback_days = 10 ) # Set up data and backtester data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/data/' ) backtester = Backtester ( market_data_loader = data_loader ) # Run backtest results = backtester . run_backtest ( strategy , benchmark_ticker = 'SPY' )","title":"Quick Start"},{"location":"#whats-next","text":"Installation - Get portwine up and running Quick Start - Your first strategy in minutes User Guide - Learn how to build strategies API Reference - Complete API documentation Examples - See portwine in action","title":"What's Next?"},{"location":"#contributing","text":"We welcome contributions! See our Contributing Guide for details on how to get started.","title":"Contributing"},{"location":"contributing/","text":"Contributing to Portwine Thank you for your interest in contributing to portwine! This guide will help you get started. Getting Started Prerequisites Python 3.8 or higher Git Poetry (recommended) or pip Setting Up Development Environment Fork and clone the repository git clone https://github.com/yourusername/portwine.git cd portwine Install dependencies # Using Poetry (recommended) poetry install # Or using pip pip install -e . pip install -r requirements-dev.txt Set up pre-commit hooks pre-commit install Development Workflow 1. Create a Feature Branch git checkout main git pull origin main git checkout -b feature/your-feature-name 2. Make Your Changes Write your code Add tests for new functionality Update documentation if needed Ensure all tests pass 3. Run Tests # Run all tests pytest # Run with coverage pytest --cov = portwine # Run specific test file pytest tests/test_backtester.py 4. Code Quality Checks # Run linting flake8 portwine/ # Run type checking mypy portwine/ # Run formatting black portwine/ isort portwine/ 5. Commit Your Changes git add . git commit -m \"feat: add new feature description\" 6. Push and Create Pull Request git push origin feature/your-feature-name Then create a pull request on GitHub. Code Style Python Code Follow PEP 8 style guidelines Use type hints for function parameters and return values Write docstrings for all public functions and classes Keep functions focused and concise Example from typing import Dict , List , Optional import pandas as pd def calculate_returns ( prices : pd . DataFrame , method : str = \"simple\" ) -> pd . Series : \"\"\" Calculate returns from price data. Parameters ---------- prices : pd.DataFrame DataFrame with price data method : str, default \"simple\" Return calculation method (\"simple\" or \"log\") Returns ------- pd.Series Calculated returns \"\"\" if method == \"simple\" : return prices . pct_change () elif method == \"log\" : return prices . apply ( np . log ) . diff () else : raise ValueError ( f \"Unknown method: { method } \" ) Documentation Use clear, concise language Include code examples Update API documentation when adding new features Follow the existing documentation structure Testing Writing Tests Write tests for all new functionality Use descriptive test names Test both success and error cases Use fixtures for common test data Example Test import pytest import pandas as pd from portwine import Backtester def test_backtester_initialization (): \"\"\"Test Backtester initialization with valid parameters.\"\"\" data_loader = MockDataLoader () backtester = Backtester ( market_data_loader = data_loader ) assert backtester . market_data_loader == data_loader assert backtester . calendar is None def test_backtester_invalid_benchmark (): \"\"\"Test Backtester raises error for invalid benchmark.\"\"\" data_loader = MockDataLoader () backtester = Backtester ( market_data_loader = data_loader ) with pytest . raises ( InvalidBenchmarkError ): backtester . run_backtest ( strategy = MockStrategy (), benchmark = \"invalid_benchmark\" ) Pull Request Guidelines Before Submitting Ensure all tests pass Update documentation if adding new features Add tests for new functionality Run code quality checks Update CHANGELOG.md if applicable Pull Request Description Include: Summary : Brief description of changes Motivation : Why this change is needed Changes : Detailed list of changes Testing : How you tested the changes Breaking Changes : Any API changes Example ## Summary Add support for custom benchmark functions in Backtester ## Motivation Users need more flexibility in benchmark selection beyond built-in options. ## Changes - Add `CUSTOM_METHOD` benchmark type - Update `get_benchmark_type()` to detect callable benchmarks - Add validation for custom benchmark functions - Update documentation with examples ## Testing - Added unit tests for custom benchmark detection - Tested with sample strategy and custom benchmark function - All existing tests pass ## Breaking Changes None Issue Reporting Bug Reports When reporting bugs, include: Description : Clear description of the bug Steps to reproduce : Detailed steps to reproduce the issue Expected behavior : What you expected to happen Actual behavior : What actually happened Environment : Python version, OS, portwine version Code example : Minimal code to reproduce the issue Feature Requests When requesting features, include: Description : Clear description of the feature Use case : Why this feature would be useful Proposed implementation : Any ideas for implementation Alternatives : Any existing workarounds Release Process Versioning We follow Semantic Versioning : MAJOR : Breaking changes MINOR : New features (backward compatible) PATCH : Bug fixes (backward compatible) Release Checklist Update version in pyproject.toml Update CHANGELOG.md Create release branch Run full test suite Update documentation Create GitHub release Publish to PyPI Getting Help GitHub Issues : For bug reports and feature requests Discussions : For questions and general discussion Documentation : Check the docs first Code of Conduct We are committed to providing a welcoming and inclusive environment. Please read our Code of Conduct for details. Thank you for contributing to portwine! \ud83c\udf77","title":"Contributing"},{"location":"contributing/#contributing-to-portwine","text":"Thank you for your interest in contributing to portwine! This guide will help you get started.","title":"Contributing to Portwine"},{"location":"contributing/#getting-started","text":"","title":"Getting Started"},{"location":"contributing/#prerequisites","text":"Python 3.8 or higher Git Poetry (recommended) or pip","title":"Prerequisites"},{"location":"contributing/#setting-up-development-environment","text":"Fork and clone the repository git clone https://github.com/yourusername/portwine.git cd portwine Install dependencies # Using Poetry (recommended) poetry install # Or using pip pip install -e . pip install -r requirements-dev.txt Set up pre-commit hooks pre-commit install","title":"Setting Up Development Environment"},{"location":"contributing/#development-workflow","text":"","title":"Development Workflow"},{"location":"contributing/#1-create-a-feature-branch","text":"git checkout main git pull origin main git checkout -b feature/your-feature-name","title":"1. Create a Feature Branch"},{"location":"contributing/#2-make-your-changes","text":"Write your code Add tests for new functionality Update documentation if needed Ensure all tests pass","title":"2. Make Your Changes"},{"location":"contributing/#3-run-tests","text":"# Run all tests pytest # Run with coverage pytest --cov = portwine # Run specific test file pytest tests/test_backtester.py","title":"3. Run Tests"},{"location":"contributing/#4-code-quality-checks","text":"# Run linting flake8 portwine/ # Run type checking mypy portwine/ # Run formatting black portwine/ isort portwine/","title":"4. Code Quality Checks"},{"location":"contributing/#5-commit-your-changes","text":"git add . git commit -m \"feat: add new feature description\"","title":"5. Commit Your Changes"},{"location":"contributing/#6-push-and-create-pull-request","text":"git push origin feature/your-feature-name Then create a pull request on GitHub.","title":"6. Push and Create Pull Request"},{"location":"contributing/#code-style","text":"","title":"Code Style"},{"location":"contributing/#python-code","text":"Follow PEP 8 style guidelines Use type hints for function parameters and return values Write docstrings for all public functions and classes Keep functions focused and concise","title":"Python Code"},{"location":"contributing/#example","text":"from typing import Dict , List , Optional import pandas as pd def calculate_returns ( prices : pd . DataFrame , method : str = \"simple\" ) -> pd . Series : \"\"\" Calculate returns from price data. Parameters ---------- prices : pd.DataFrame DataFrame with price data method : str, default \"simple\" Return calculation method (\"simple\" or \"log\") Returns ------- pd.Series Calculated returns \"\"\" if method == \"simple\" : return prices . pct_change () elif method == \"log\" : return prices . apply ( np . log ) . diff () else : raise ValueError ( f \"Unknown method: { method } \" )","title":"Example"},{"location":"contributing/#documentation","text":"Use clear, concise language Include code examples Update API documentation when adding new features Follow the existing documentation structure","title":"Documentation"},{"location":"contributing/#testing","text":"","title":"Testing"},{"location":"contributing/#writing-tests","text":"Write tests for all new functionality Use descriptive test names Test both success and error cases Use fixtures for common test data","title":"Writing Tests"},{"location":"contributing/#example-test","text":"import pytest import pandas as pd from portwine import Backtester def test_backtester_initialization (): \"\"\"Test Backtester initialization with valid parameters.\"\"\" data_loader = MockDataLoader () backtester = Backtester ( market_data_loader = data_loader ) assert backtester . market_data_loader == data_loader assert backtester . calendar is None def test_backtester_invalid_benchmark (): \"\"\"Test Backtester raises error for invalid benchmark.\"\"\" data_loader = MockDataLoader () backtester = Backtester ( market_data_loader = data_loader ) with pytest . raises ( InvalidBenchmarkError ): backtester . run_backtest ( strategy = MockStrategy (), benchmark = \"invalid_benchmark\" )","title":"Example Test"},{"location":"contributing/#pull-request-guidelines","text":"","title":"Pull Request Guidelines"},{"location":"contributing/#before-submitting","text":"Ensure all tests pass Update documentation if adding new features Add tests for new functionality Run code quality checks Update CHANGELOG.md if applicable","title":"Before Submitting"},{"location":"contributing/#pull-request-description","text":"Include: Summary : Brief description of changes Motivation : Why this change is needed Changes : Detailed list of changes Testing : How you tested the changes Breaking Changes : Any API changes","title":"Pull Request Description"},{"location":"contributing/#example_1","text":"## Summary Add support for custom benchmark functions in Backtester ## Motivation Users need more flexibility in benchmark selection beyond built-in options. ## Changes - Add `CUSTOM_METHOD` benchmark type - Update `get_benchmark_type()` to detect callable benchmarks - Add validation for custom benchmark functions - Update documentation with examples ## Testing - Added unit tests for custom benchmark detection - Tested with sample strategy and custom benchmark function - All existing tests pass ## Breaking Changes None","title":"Example"},{"location":"contributing/#issue-reporting","text":"","title":"Issue Reporting"},{"location":"contributing/#bug-reports","text":"When reporting bugs, include: Description : Clear description of the bug Steps to reproduce : Detailed steps to reproduce the issue Expected behavior : What you expected to happen Actual behavior : What actually happened Environment : Python version, OS, portwine version Code example : Minimal code to reproduce the issue","title":"Bug Reports"},{"location":"contributing/#feature-requests","text":"When requesting features, include: Description : Clear description of the feature Use case : Why this feature would be useful Proposed implementation : Any ideas for implementation Alternatives : Any existing workarounds","title":"Feature Requests"},{"location":"contributing/#release-process","text":"","title":"Release Process"},{"location":"contributing/#versioning","text":"We follow Semantic Versioning : MAJOR : Breaking changes MINOR : New features (backward compatible) PATCH : Bug fixes (backward compatible)","title":"Versioning"},{"location":"contributing/#release-checklist","text":"Update version in pyproject.toml Update CHANGELOG.md Create release branch Run full test suite Update documentation Create GitHub release Publish to PyPI","title":"Release Checklist"},{"location":"contributing/#getting-help","text":"GitHub Issues : For bug reports and feature requests Discussions : For questions and general discussion Documentation : Check the docs first","title":"Getting Help"},{"location":"contributing/#code-of-conduct","text":"We are committed to providing a welcoming and inclusive environment. Please read our Code of Conduct for details. Thank you for contributing to portwine! \ud83c\udf77","title":"Code of Conduct"},{"location":"api/analyzers/","text":"Analyzers API Portwine provides a comprehensive suite of analyzers to help you understand and visualize strategy performance. Base Analyzer All analyzers inherit from the base Analyzer class: from portwine.analyzers import Analyzer class Analyzer : \"\"\" Base class for all analyzers in portwine. \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Generate plots for the given backtest results. Parameters ---------- results : Dict[str, pd.DataFrame] Results dictionary from Backtester.run_backtest() **kwargs Additional plotting parameters \"\"\" raise NotImplementedError ( \"Subclasses must implement plot method\" ) Built-in Analyzers EquityDrawdownAnalyzer Analyzes equity curves and drawdowns: from portwine.analyzers import EquityDrawdownAnalyzer class EquityDrawdownAnalyzer ( Analyzer ): \"\"\" Analyzer for equity curves and drawdown analysis. Generates: - Equity curve comparison (strategy vs benchmark) - Drawdown analysis - Performance metrics table \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Plot equity curves and drawdown analysis. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters: - figsize : tuple, default (15, 10) - title : str, default \"Equity and Drawdown Analysis\" \"\"\" # Implementation details... Usage Example # Create analyzer analyzer = EquityDrawdownAnalyzer () # Plot results analyzer . plot ( results ) # With custom parameters analyzer . plot ( results , figsize = ( 20 , 12 ), title = \"My Strategy Performance\" ) MonteCarloAnalyzer Performs Monte Carlo simulations: from portwine.analyzers import MonteCarloAnalyzer class MonteCarloAnalyzer ( Analyzer ): \"\"\" Monte Carlo simulation analyzer. Generates: - Distribution of possible outcomes - Confidence intervals - Risk metrics \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], n_simulations : int = 1000 , ** kwargs ): \"\"\" Run Monte Carlo simulation and plot results. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() n_simulations : int, default 1000 Number of Monte Carlo simulations to run **kwargs Additional plotting parameters \"\"\" # Implementation details... Usage Example # Create analyzer analyzer = MonteCarloAnalyzer () # Run Monte Carlo analysis analyzer . plot ( results , n_simulations = 5000 ) # With custom parameters analyzer . plot ( results , n_simulations = 10000 , confidence_levels = [ 0.05 , 0.25 , 0.5 , 0.75 , 0.95 ] ) SeasonalityAnalyzer Analyzes seasonal patterns: from portwine.analyzers import SeasonalityAnalyzer class SeasonalityAnalyzer ( Analyzer ): \"\"\" Seasonality analysis analyzer. Generates: - Monthly performance patterns - Day-of-week patterns - Seasonal trends \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Analyze and plot seasonal patterns. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters: - period : str, default \"monthly\" Analysis period (\"monthly\", \"weekly\", \"quarterly\") \"\"\" # Implementation details... Usage Example # Create analyzer analyzer = SeasonalityAnalyzer () # Analyze monthly patterns analyzer . plot ( results , period = \"monthly\" ) # Analyze weekly patterns analyzer . plot ( results , period = \"weekly\" ) Creating Custom Analyzers Basic Analyzer Template from portwine.analyzers import Analyzer import matplotlib.pyplot as plt import pandas as pd class MyCustomAnalyzer ( Analyzer ): \"\"\" Custom analyzer for specific analysis needs. \"\"\" def __init__ ( self , ** parameters ): \"\"\" Initialize the analyzer. Parameters ---------- **parameters Analyzer-specific parameters \"\"\" self . parameters = parameters def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Generate custom analysis plots. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters \"\"\" # Extract data from results strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results [ 'benchmark_returns' ] # Your custom analysis logic here self . _analyze_data ( strategy_returns , benchmark_returns ) # Generate plots self . _create_plots ( ** kwargs ) def _analyze_data ( self , strategy_returns : pd . Series , benchmark_returns : pd . Series ): \"\"\"Perform data analysis.\"\"\" # Your analysis logic here pass def _create_plots ( self , ** kwargs ): \"\"\"Create visualization plots.\"\"\" # Your plotting logic here pass Advanced Analyzer Example class RiskMetricsAnalyzer ( Analyzer ): \"\"\" Comprehensive risk metrics analyzer. \"\"\" def __init__ ( self , risk_free_rate : float = 0.02 ): self . risk_free_rate = risk_free_rate def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Generate comprehensive risk analysis.\"\"\" strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results [ 'benchmark_returns' ] # Calculate risk metrics metrics = self . _calculate_risk_metrics ( strategy_returns , benchmark_returns ) # Create visualization self . _create_risk_plots ( metrics , ** kwargs ) # Print summary self . _print_summary ( metrics ) def _calculate_risk_metrics ( self , strategy_returns : pd . Series , benchmark_returns : pd . Series ) -> Dict : \"\"\"Calculate comprehensive risk metrics.\"\"\" # Basic metrics annual_return = strategy_returns . mean () * 252 volatility = strategy_returns . std () * np . sqrt ( 252 ) # Risk-adjusted metrics sharpe_ratio = ( annual_return - self . risk_free_rate ) / volatility # Drawdown analysis cumulative = ( 1 + strategy_returns ) . cumprod () running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min () # VaR and CVaR var_95 = np . percentile ( strategy_returns , 5 ) cvar_95 = strategy_returns [ strategy_returns <= var_95 ] . mean () # Beta and Alpha covariance = np . cov ( strategy_returns , benchmark_returns )[ 0 , 1 ] benchmark_variance = np . var ( benchmark_returns ) beta = covariance / benchmark_variance if benchmark_variance != 0 else 0 benchmark_annual_return = benchmark_returns . mean () * 252 alpha = annual_return - ( self . risk_free_rate + beta * ( benchmark_annual_return - self . risk_free_rate )) return { 'annual_return' : annual_return , 'volatility' : volatility , 'sharpe_ratio' : sharpe_ratio , 'max_drawdown' : max_drawdown , 'var_95' : var_95 , 'cvar_95' : cvar_95 , 'beta' : beta , 'alpha' : alpha } def _create_risk_plots ( self , metrics : Dict , ** kwargs ): \"\"\"Create risk visualization plots.\"\"\" fig , axes = plt . subplots ( 2 , 2 , figsize = kwargs . get ( 'figsize' , ( 15 , 10 ))) # 1. Risk-return scatter axes [ 0 , 0 ] . scatter ( metrics [ 'volatility' ], metrics [ 'annual_return' ], s = 100 , alpha = 0.7 ) axes [ 0 , 0 ] . set_xlabel ( 'Volatility' ) axes [ 0 , 0 ] . set_ylabel ( 'Annual Return' ) axes [ 0 , 0 ] . set_title ( 'Risk-Return Profile' ) axes [ 0 , 0 ] . grid ( True ) # 2. Sharpe ratio axes [ 0 , 1 ] . bar ([ 'Strategy' ], [ metrics [ 'sharpe_ratio' ]]) axes [ 0 , 1 ] . set_ylabel ( 'Sharpe Ratio' ) axes [ 0 , 1 ] . set_title ( 'Risk-Adjusted Return' ) axes [ 0 , 1 ] . grid ( True ) # 3. Drawdown axes [ 1 , 0 ] . bar ([ 'Max Drawdown' ], [ abs ( metrics [ 'max_drawdown' ])]) axes [ 1 , 0 ] . set_ylabel ( 'Drawdown' ) axes [ 1 , 0 ] . set_title ( 'Maximum Drawdown' ) axes [ 1 , 0 ] . grid ( True ) # 4. Beta axes [ 1 , 1 ] . bar ([ 'Beta' ], [ metrics [ 'beta' ]]) axes [ 1 , 1 ] . axhline ( y = 1 , color = 'red' , linestyle = '--' , label = 'Market Beta' ) axes [ 1 , 1 ] . set_ylabel ( 'Beta' ) axes [ 1 , 1 ] . set_title ( 'Market Beta' ) axes [ 1 , 1 ] . legend () axes [ 1 , 1 ] . grid ( True ) plt . tight_layout () plt . show () def _print_summary ( self , metrics : Dict ): \"\"\"Print risk metrics summary.\"\"\" print ( \"=== Risk Metrics Summary ===\" ) print ( f \"Annual Return: { metrics [ 'annual_return' ] : .2% } \" ) print ( f \"Volatility: { metrics [ 'volatility' ] : .2% } \" ) print ( f \"Sharpe Ratio: { metrics [ 'sharpe_ratio' ] : .2f } \" ) print ( f \"Maximum Drawdown: { metrics [ 'max_drawdown' ] : .2% } \" ) print ( f \"VaR (95%): { metrics [ 'var_95' ] : .2% } \" ) print ( f \"CVaR (95%): { metrics [ 'cvar_95' ] : .2% } \" ) print ( f \"Beta: { metrics [ 'beta' ] : .2f } \" ) print ( f \"Alpha: { metrics [ 'alpha' ] : .2% } \" ) Analyzer Best Practices 1. Consistent Interface class ConsistentAnalyzer ( Analyzer ): def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Standard plot method with consistent parameters. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() figsize : tuple, optional Figure size (width, height) title : str, optional Plot title save_path : str, optional Path to save the plot \"\"\" # Extract common parameters figsize = kwargs . get ( 'figsize' , ( 12 , 8 )) title = kwargs . get ( 'title' , 'Analysis Results' ) save_path = kwargs . get ( 'save_path' , None ) # Your analysis logic here # ... # Save if requested if save_path : plt . savefig ( save_path , dpi = 300 , bbox_inches = 'tight' ) 2. Error Handling class RobustAnalyzer ( Analyzer ): def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Robust analyzer with error handling.\"\"\" try : # Validate input self . _validate_results ( results ) # Perform analysis analysis_data = self . _perform_analysis ( results ) # Create plots self . _create_plots ( analysis_data , ** kwargs ) except KeyError as e : print ( f \"Missing required data: { e } \" ) print ( \"Available keys:\" , list ( results . keys ())) except Exception as e : print ( f \"Analysis failed: { e } \" ) def _validate_results ( self , results : Dict [ str , pd . DataFrame ]): \"\"\"Validate that results contain required data.\"\"\" required_keys = [ 'strategy_returns' , 'benchmark_returns' ] for key in required_keys : if key not in results : raise KeyError ( f \"Missing required key: { key } \" ) if not isinstance ( results [ key ], pd . Series ): raise TypeError ( f \" { key } must be a pandas Series\" ) 3. Performance Optimization class EfficientAnalyzer ( Analyzer ): def __init__ ( self ): self . cache = {} def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Efficient analyzer with caching.\"\"\" # Check cache first cache_key = self . _get_cache_key ( results , kwargs ) if cache_key in self . cache : return self . cache [ cache_key ] # Perform analysis analysis_result = self . _perform_analysis ( results , ** kwargs ) # Cache result self . cache [ cache_key ] = analysis_result return analysis_result def _get_cache_key ( self , results : Dict [ str , pd . DataFrame ], kwargs : Dict ) -> str : \"\"\"Generate cache key for results and parameters.\"\"\" # Create a hash of the results and parameters import hashlib # Simple hash of results length and kwargs data_str = f \" { len ( results ) } - { sorted ( kwargs . items ()) } \" return hashlib . md5 ( data_str . encode ()) . hexdigest () Combining Analyzers Multi-Analyzer class MultiAnalyzer ( Analyzer ): \"\"\" Combines multiple analyzers into a single comprehensive analysis. \"\"\" def __init__ ( self , analyzers : List [ Analyzer ]): self . analyzers = analyzers def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Run all analyzers and display results.\"\"\" for i , analyzer in enumerate ( self . analyzers ): print ( f \" \\n === Analysis { i + 1 } : { analyzer . __class__ . __name__ } ===\" ) analyzer . plot ( results , ** kwargs ) Usage Example # Create multiple analyzers equity_analyzer = EquityDrawdownAnalyzer () monte_carlo_analyzer = MonteCarloAnalyzer () risk_analyzer = RiskMetricsAnalyzer () # Combine them multi_analyzer = MultiAnalyzer ([ equity_analyzer , monte_carlo_analyzer , risk_analyzer ]) # Run comprehensive analysis multi_analyzer . plot ( results ) Testing Analyzers Unit Testing import pytest import pandas as pd import numpy as np def test_analyzer_initialization (): \"\"\"Test analyzer initialization.\"\"\" analyzer = MyCustomAnalyzer ( param1 = 10 , param2 = \"test\" ) assert analyzer . parameters [ 'param1' ] == 10 assert analyzer . parameters [ 'param2' ] == \"test\" def test_analyzer_plot (): \"\"\"Test analyzer plot method.\"\"\" analyzer = MyCustomAnalyzer () # Mock results dates = pd . date_range ( '2023-01-01' , periods = 100 , freq = 'D' ) strategy_returns = pd . Series ( np . random . normal ( 0.001 , 0.02 , 100 ), index = dates ) benchmark_returns = pd . Series ( np . random . normal ( 0.0008 , 0.015 , 100 ), index = dates ) results = { 'strategy_returns' : strategy_returns , 'benchmark_returns' : benchmark_returns } # Should not raise an exception analyzer . plot ( results ) def test_analyzer_error_handling (): \"\"\"Test analyzer error handling.\"\"\" analyzer = MyCustomAnalyzer () # Invalid results invalid_results = { 'invalid_key' : pd . Series ()} # Should handle gracefully with pytest . raises ( KeyError ): analyzer . plot ( invalid_results ) Next Steps Learn about backtesting Explore strategies Check out performance analysis","title":"Analyzers API"},{"location":"api/analyzers/#analyzers-api","text":"Portwine provides a comprehensive suite of analyzers to help you understand and visualize strategy performance.","title":"Analyzers API"},{"location":"api/analyzers/#base-analyzer","text":"All analyzers inherit from the base Analyzer class: from portwine.analyzers import Analyzer class Analyzer : \"\"\" Base class for all analyzers in portwine. \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Generate plots for the given backtest results. Parameters ---------- results : Dict[str, pd.DataFrame] Results dictionary from Backtester.run_backtest() **kwargs Additional plotting parameters \"\"\" raise NotImplementedError ( \"Subclasses must implement plot method\" )","title":"Base Analyzer"},{"location":"api/analyzers/#built-in-analyzers","text":"","title":"Built-in Analyzers"},{"location":"api/analyzers/#equitydrawdownanalyzer","text":"Analyzes equity curves and drawdowns: from portwine.analyzers import EquityDrawdownAnalyzer class EquityDrawdownAnalyzer ( Analyzer ): \"\"\" Analyzer for equity curves and drawdown analysis. Generates: - Equity curve comparison (strategy vs benchmark) - Drawdown analysis - Performance metrics table \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Plot equity curves and drawdown analysis. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters: - figsize : tuple, default (15, 10) - title : str, default \"Equity and Drawdown Analysis\" \"\"\" # Implementation details...","title":"EquityDrawdownAnalyzer"},{"location":"api/analyzers/#usage-example","text":"# Create analyzer analyzer = EquityDrawdownAnalyzer () # Plot results analyzer . plot ( results ) # With custom parameters analyzer . plot ( results , figsize = ( 20 , 12 ), title = \"My Strategy Performance\" )","title":"Usage Example"},{"location":"api/analyzers/#montecarloanalyzer","text":"Performs Monte Carlo simulations: from portwine.analyzers import MonteCarloAnalyzer class MonteCarloAnalyzer ( Analyzer ): \"\"\" Monte Carlo simulation analyzer. Generates: - Distribution of possible outcomes - Confidence intervals - Risk metrics \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], n_simulations : int = 1000 , ** kwargs ): \"\"\" Run Monte Carlo simulation and plot results. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() n_simulations : int, default 1000 Number of Monte Carlo simulations to run **kwargs Additional plotting parameters \"\"\" # Implementation details...","title":"MonteCarloAnalyzer"},{"location":"api/analyzers/#usage-example_1","text":"# Create analyzer analyzer = MonteCarloAnalyzer () # Run Monte Carlo analysis analyzer . plot ( results , n_simulations = 5000 ) # With custom parameters analyzer . plot ( results , n_simulations = 10000 , confidence_levels = [ 0.05 , 0.25 , 0.5 , 0.75 , 0.95 ] )","title":"Usage Example"},{"location":"api/analyzers/#seasonalityanalyzer","text":"Analyzes seasonal patterns: from portwine.analyzers import SeasonalityAnalyzer class SeasonalityAnalyzer ( Analyzer ): \"\"\" Seasonality analysis analyzer. Generates: - Monthly performance patterns - Day-of-week patterns - Seasonal trends \"\"\" def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Analyze and plot seasonal patterns. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters: - period : str, default \"monthly\" Analysis period (\"monthly\", \"weekly\", \"quarterly\") \"\"\" # Implementation details...","title":"SeasonalityAnalyzer"},{"location":"api/analyzers/#usage-example_2","text":"# Create analyzer analyzer = SeasonalityAnalyzer () # Analyze monthly patterns analyzer . plot ( results , period = \"monthly\" ) # Analyze weekly patterns analyzer . plot ( results , period = \"weekly\" )","title":"Usage Example"},{"location":"api/analyzers/#creating-custom-analyzers","text":"","title":"Creating Custom Analyzers"},{"location":"api/analyzers/#basic-analyzer-template","text":"from portwine.analyzers import Analyzer import matplotlib.pyplot as plt import pandas as pd class MyCustomAnalyzer ( Analyzer ): \"\"\" Custom analyzer for specific analysis needs. \"\"\" def __init__ ( self , ** parameters ): \"\"\" Initialize the analyzer. Parameters ---------- **parameters Analyzer-specific parameters \"\"\" self . parameters = parameters def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Generate custom analysis plots. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() **kwargs Additional plotting parameters \"\"\" # Extract data from results strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results [ 'benchmark_returns' ] # Your custom analysis logic here self . _analyze_data ( strategy_returns , benchmark_returns ) # Generate plots self . _create_plots ( ** kwargs ) def _analyze_data ( self , strategy_returns : pd . Series , benchmark_returns : pd . Series ): \"\"\"Perform data analysis.\"\"\" # Your analysis logic here pass def _create_plots ( self , ** kwargs ): \"\"\"Create visualization plots.\"\"\" # Your plotting logic here pass","title":"Basic Analyzer Template"},{"location":"api/analyzers/#advanced-analyzer-example","text":"class RiskMetricsAnalyzer ( Analyzer ): \"\"\" Comprehensive risk metrics analyzer. \"\"\" def __init__ ( self , risk_free_rate : float = 0.02 ): self . risk_free_rate = risk_free_rate def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Generate comprehensive risk analysis.\"\"\" strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results [ 'benchmark_returns' ] # Calculate risk metrics metrics = self . _calculate_risk_metrics ( strategy_returns , benchmark_returns ) # Create visualization self . _create_risk_plots ( metrics , ** kwargs ) # Print summary self . _print_summary ( metrics ) def _calculate_risk_metrics ( self , strategy_returns : pd . Series , benchmark_returns : pd . Series ) -> Dict : \"\"\"Calculate comprehensive risk metrics.\"\"\" # Basic metrics annual_return = strategy_returns . mean () * 252 volatility = strategy_returns . std () * np . sqrt ( 252 ) # Risk-adjusted metrics sharpe_ratio = ( annual_return - self . risk_free_rate ) / volatility # Drawdown analysis cumulative = ( 1 + strategy_returns ) . cumprod () running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min () # VaR and CVaR var_95 = np . percentile ( strategy_returns , 5 ) cvar_95 = strategy_returns [ strategy_returns <= var_95 ] . mean () # Beta and Alpha covariance = np . cov ( strategy_returns , benchmark_returns )[ 0 , 1 ] benchmark_variance = np . var ( benchmark_returns ) beta = covariance / benchmark_variance if benchmark_variance != 0 else 0 benchmark_annual_return = benchmark_returns . mean () * 252 alpha = annual_return - ( self . risk_free_rate + beta * ( benchmark_annual_return - self . risk_free_rate )) return { 'annual_return' : annual_return , 'volatility' : volatility , 'sharpe_ratio' : sharpe_ratio , 'max_drawdown' : max_drawdown , 'var_95' : var_95 , 'cvar_95' : cvar_95 , 'beta' : beta , 'alpha' : alpha } def _create_risk_plots ( self , metrics : Dict , ** kwargs ): \"\"\"Create risk visualization plots.\"\"\" fig , axes = plt . subplots ( 2 , 2 , figsize = kwargs . get ( 'figsize' , ( 15 , 10 ))) # 1. Risk-return scatter axes [ 0 , 0 ] . scatter ( metrics [ 'volatility' ], metrics [ 'annual_return' ], s = 100 , alpha = 0.7 ) axes [ 0 , 0 ] . set_xlabel ( 'Volatility' ) axes [ 0 , 0 ] . set_ylabel ( 'Annual Return' ) axes [ 0 , 0 ] . set_title ( 'Risk-Return Profile' ) axes [ 0 , 0 ] . grid ( True ) # 2. Sharpe ratio axes [ 0 , 1 ] . bar ([ 'Strategy' ], [ metrics [ 'sharpe_ratio' ]]) axes [ 0 , 1 ] . set_ylabel ( 'Sharpe Ratio' ) axes [ 0 , 1 ] . set_title ( 'Risk-Adjusted Return' ) axes [ 0 , 1 ] . grid ( True ) # 3. Drawdown axes [ 1 , 0 ] . bar ([ 'Max Drawdown' ], [ abs ( metrics [ 'max_drawdown' ])]) axes [ 1 , 0 ] . set_ylabel ( 'Drawdown' ) axes [ 1 , 0 ] . set_title ( 'Maximum Drawdown' ) axes [ 1 , 0 ] . grid ( True ) # 4. Beta axes [ 1 , 1 ] . bar ([ 'Beta' ], [ metrics [ 'beta' ]]) axes [ 1 , 1 ] . axhline ( y = 1 , color = 'red' , linestyle = '--' , label = 'Market Beta' ) axes [ 1 , 1 ] . set_ylabel ( 'Beta' ) axes [ 1 , 1 ] . set_title ( 'Market Beta' ) axes [ 1 , 1 ] . legend () axes [ 1 , 1 ] . grid ( True ) plt . tight_layout () plt . show () def _print_summary ( self , metrics : Dict ): \"\"\"Print risk metrics summary.\"\"\" print ( \"=== Risk Metrics Summary ===\" ) print ( f \"Annual Return: { metrics [ 'annual_return' ] : .2% } \" ) print ( f \"Volatility: { metrics [ 'volatility' ] : .2% } \" ) print ( f \"Sharpe Ratio: { metrics [ 'sharpe_ratio' ] : .2f } \" ) print ( f \"Maximum Drawdown: { metrics [ 'max_drawdown' ] : .2% } \" ) print ( f \"VaR (95%): { metrics [ 'var_95' ] : .2% } \" ) print ( f \"CVaR (95%): { metrics [ 'cvar_95' ] : .2% } \" ) print ( f \"Beta: { metrics [ 'beta' ] : .2f } \" ) print ( f \"Alpha: { metrics [ 'alpha' ] : .2% } \" )","title":"Advanced Analyzer Example"},{"location":"api/analyzers/#analyzer-best-practices","text":"","title":"Analyzer Best Practices"},{"location":"api/analyzers/#1-consistent-interface","text":"class ConsistentAnalyzer ( Analyzer ): def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\" Standard plot method with consistent parameters. Parameters ---------- results : Dict[str, pd.DataFrame] Results from Backtester.run_backtest() figsize : tuple, optional Figure size (width, height) title : str, optional Plot title save_path : str, optional Path to save the plot \"\"\" # Extract common parameters figsize = kwargs . get ( 'figsize' , ( 12 , 8 )) title = kwargs . get ( 'title' , 'Analysis Results' ) save_path = kwargs . get ( 'save_path' , None ) # Your analysis logic here # ... # Save if requested if save_path : plt . savefig ( save_path , dpi = 300 , bbox_inches = 'tight' )","title":"1. Consistent Interface"},{"location":"api/analyzers/#2-error-handling","text":"class RobustAnalyzer ( Analyzer ): def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Robust analyzer with error handling.\"\"\" try : # Validate input self . _validate_results ( results ) # Perform analysis analysis_data = self . _perform_analysis ( results ) # Create plots self . _create_plots ( analysis_data , ** kwargs ) except KeyError as e : print ( f \"Missing required data: { e } \" ) print ( \"Available keys:\" , list ( results . keys ())) except Exception as e : print ( f \"Analysis failed: { e } \" ) def _validate_results ( self , results : Dict [ str , pd . DataFrame ]): \"\"\"Validate that results contain required data.\"\"\" required_keys = [ 'strategy_returns' , 'benchmark_returns' ] for key in required_keys : if key not in results : raise KeyError ( f \"Missing required key: { key } \" ) if not isinstance ( results [ key ], pd . Series ): raise TypeError ( f \" { key } must be a pandas Series\" )","title":"2. Error Handling"},{"location":"api/analyzers/#3-performance-optimization","text":"class EfficientAnalyzer ( Analyzer ): def __init__ ( self ): self . cache = {} def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Efficient analyzer with caching.\"\"\" # Check cache first cache_key = self . _get_cache_key ( results , kwargs ) if cache_key in self . cache : return self . cache [ cache_key ] # Perform analysis analysis_result = self . _perform_analysis ( results , ** kwargs ) # Cache result self . cache [ cache_key ] = analysis_result return analysis_result def _get_cache_key ( self , results : Dict [ str , pd . DataFrame ], kwargs : Dict ) -> str : \"\"\"Generate cache key for results and parameters.\"\"\" # Create a hash of the results and parameters import hashlib # Simple hash of results length and kwargs data_str = f \" { len ( results ) } - { sorted ( kwargs . items ()) } \" return hashlib . md5 ( data_str . encode ()) . hexdigest ()","title":"3. Performance Optimization"},{"location":"api/analyzers/#combining-analyzers","text":"","title":"Combining Analyzers"},{"location":"api/analyzers/#multi-analyzer","text":"class MultiAnalyzer ( Analyzer ): \"\"\" Combines multiple analyzers into a single comprehensive analysis. \"\"\" def __init__ ( self , analyzers : List [ Analyzer ]): self . analyzers = analyzers def plot ( self , results : Dict [ str , pd . DataFrame ], ** kwargs ): \"\"\"Run all analyzers and display results.\"\"\" for i , analyzer in enumerate ( self . analyzers ): print ( f \" \\n === Analysis { i + 1 } : { analyzer . __class__ . __name__ } ===\" ) analyzer . plot ( results , ** kwargs )","title":"Multi-Analyzer"},{"location":"api/analyzers/#usage-example_3","text":"# Create multiple analyzers equity_analyzer = EquityDrawdownAnalyzer () monte_carlo_analyzer = MonteCarloAnalyzer () risk_analyzer = RiskMetricsAnalyzer () # Combine them multi_analyzer = MultiAnalyzer ([ equity_analyzer , monte_carlo_analyzer , risk_analyzer ]) # Run comprehensive analysis multi_analyzer . plot ( results )","title":"Usage Example"},{"location":"api/analyzers/#testing-analyzers","text":"","title":"Testing Analyzers"},{"location":"api/analyzers/#unit-testing","text":"import pytest import pandas as pd import numpy as np def test_analyzer_initialization (): \"\"\"Test analyzer initialization.\"\"\" analyzer = MyCustomAnalyzer ( param1 = 10 , param2 = \"test\" ) assert analyzer . parameters [ 'param1' ] == 10 assert analyzer . parameters [ 'param2' ] == \"test\" def test_analyzer_plot (): \"\"\"Test analyzer plot method.\"\"\" analyzer = MyCustomAnalyzer () # Mock results dates = pd . date_range ( '2023-01-01' , periods = 100 , freq = 'D' ) strategy_returns = pd . Series ( np . random . normal ( 0.001 , 0.02 , 100 ), index = dates ) benchmark_returns = pd . Series ( np . random . normal ( 0.0008 , 0.015 , 100 ), index = dates ) results = { 'strategy_returns' : strategy_returns , 'benchmark_returns' : benchmark_returns } # Should not raise an exception analyzer . plot ( results ) def test_analyzer_error_handling (): \"\"\"Test analyzer error handling.\"\"\" analyzer = MyCustomAnalyzer () # Invalid results invalid_results = { 'invalid_key' : pd . Series ()} # Should handle gracefully with pytest . raises ( KeyError ): analyzer . plot ( invalid_results )","title":"Unit Testing"},{"location":"api/analyzers/#next-steps","text":"Learn about backtesting Explore strategies Check out performance analysis","title":"Next Steps"},{"location":"api/backtester/","text":"Backtester API Reference This module provides a step-driven backtester that supports intraday bars and optional exchange trading calendars. Exceptions InvalidBenchmarkError class InvalidBenchmarkError ( Exception ): \"\"\"Raised when the requested benchmark is neither a standard name nor a valid ticker.\"\"\" Description : Custom exception raised when an invalid benchmark is provided to the backtester. Functions benchmark_equal_weight def benchmark_equal_weight ( ret_df : pd . DataFrame , * _ , ** __ ) -> pd . Series : \"\"\" Calculate equal-weighted benchmark returns. Parameters ---------- ret_df : pd.DataFrame DataFrame containing asset returns with tickers as columns and dates as index. *_, **__ : Additional arguments (ignored for compatibility). Returns ------- pd.Series Equal-weighted portfolio returns. Notes ----- This benchmark assigns equal weights (1/n) to all assets in the portfolio. \"\"\" return ret_df . mean ( axis = 1 ) benchmark_markowitz def benchmark_markowitz ( ret_df : pd . DataFrame , lookback : int = 60 , shift_signals : bool = True , verbose : bool = False , ) -> pd . Series : \"\"\" Calculate Markowitz mean-variance optimized benchmark returns. Parameters ---------- ret_df : pd.DataFrame DataFrame containing asset returns with tickers as columns and dates as index. lookback : int, default=60 Number of periods to use for covariance estimation. shift_signals : bool, default=True Whether to apply weights on the next day to prevent lookahead bias. verbose : bool, default=False Whether to show progress bar during optimization. Returns ------- pd.Series Markowitz optimized portfolio returns. Notes ----- Uses convex optimization to minimize portfolio variance subject to full investment constraint. Falls back to equal weights if optimization fails. \"\"\" Constants STANDARD_BENCHMARKS STANDARD_BENCHMARKS : Dict [ str , Callable ] = { \"equal_weight\" : benchmark_equal_weight , \"markowitz\" : benchmark_markowitz , } Description : Dictionary mapping standard benchmark names to their corresponding functions. Classes BenchmarkTypes class BenchmarkTypes : \"\"\" Enumeration of benchmark types used by the backtester. Attributes ---------- STANDARD_BENCHMARK : int Built-in benchmark (equal_weight, markowitz). TICKER : int Single ticker symbol benchmark. CUSTOM_METHOD : int Custom benchmark function. INVALID : int Invalid benchmark type. \"\"\" STANDARD_BENCHMARK = 0 TICKER = 1 CUSTOM_METHOD = 2 INVALID = 3 Backtester class Backtester : \"\"\" A step-driven backtester that supports intraday bars and optional exchange trading calendars. The Backtester class is the core component for executing trading strategies and generating performance results. It handles data loading, signal generation, return calculation, and benchmark comparison. Parameters ---------- market_data_loader : MarketDataLoader The primary data loader for market data. alternative_data_loader : optional Additional data loader for alternative data sources. calendar : str or mcal.ExchangeCalendar, optional Trading calendar for date filtering. Can be a string (calendar name) or ExchangeCalendar object. Attributes ---------- market_data_loader : MarketDataLoader The primary market data loader instance. alternative_data_loader : optional Alternative data loader instance. calendar : mcal.ExchangeCalendar or None Trading calendar instance. Examples -------- >>> from portwine import Backtester, EODHDMarketDataLoader >>> import pandas_market_calendars as mcal >>> >>> # Basic backtester >>> data_loader = EODHDMarketDataLoader(data_path='path/to/data/') >>> backtester = Backtester(market_data_loader=data_loader) >>> >>> # With trading calendar >>> calendar = mcal.get_calendar('NYSE') >>> backtester = Backtester( ... market_data_loader=data_loader, ... calendar=calendar ... ) \"\"\" Methods init def __init__ ( self , market_data_loader : MarketDataLoader , alternative_data_loader = None , calendar : Optional [ Union [ str , mcal . ExchangeCalendar ]] = None ): \"\"\" Initialize the Backtester. Parameters ---------- market_data_loader : MarketDataLoader The primary data loader for market data. alternative_data_loader : optional Additional data loader for alternative data sources. calendar : str or mcal.ExchangeCalendar, optional Trading calendar for date filtering. Can be a string (calendar name) or ExchangeCalendar object. \"\"\" _split_tickers def _split_tickers ( self , tickers : List [ str ]) -> Tuple [ List [ str ], List [ str ]]: \"\"\" Split tickers into regular and alternative data tickers. Parameters ---------- tickers : List[str] List of ticker symbols to split. Returns ------- Tuple[List[str], List[str]] Tuple of (regular_tickers, alternative_tickers). Notes ----- Alternative data tickers are identified by the presence of ':' in the ticker symbol. \"\"\" get_benchmark_type def get_benchmark_type ( self , benchmark ) -> int : \"\"\" Determine the type of benchmark provided. Parameters ---------- benchmark : str or callable The benchmark to classify. Returns ------- int Benchmark type from BenchmarkTypes enum. Notes ----- Checks if benchmark is a standard name, valid ticker, or custom function. \"\"\" run_backtest def run_backtest ( self , strategy , shift_signals : bool = True , benchmark : Union [ str , Callable , None ] = \"equal_weight\" , start_date = None , end_date = None , require_all_history : bool = False , require_all_tickers : bool = False , verbose : bool = False ) -> Optional [ Dict [ str , pd . DataFrame ]]: \"\"\" Execute a backtest using the provided strategy. Parameters ---------- strategy : object Strategy object that must implement a `step` method. shift_signals : bool, default=True Whether to apply signals on the next day (prevents lookahead bias). benchmark : str, callable, or None, default=\"equal_weight\" Benchmark for comparison. Options: - String: \"equal_weight\", \"markowitz\", or ticker symbol - Callable: Custom benchmark function - None: No benchmark start_date : datetime or str, optional Start date for backtest. end_date : datetime or str, optional End date for backtest. require_all_history : bool, default=False Require all tickers to have data from the same start date. require_all_tickers : bool, default=False Require data for all requested tickers. verbose : bool, default=False Show progress bars during execution. Returns ------- Dict[str, pd.DataFrame] or None Dictionary containing backtest results: - 'signals_df': Strategy allocations over time - 'tickers_returns': Individual asset returns - 'strategy_returns': Strategy performance - 'benchmark_returns': Benchmark performance Raises ------ ValueError If start_date > end_date or no trading dates after filtering. InvalidBenchmarkError If benchmark is invalid. Notes ----- The strategy object must have: - A `tickers` attribute containing the list of ticker symbols - A `step(timestamp, bar_data)` method that returns allocation weights Examples -------- >>> # Basic backtest >>> results = backtester.run_backtest( ... strategy=my_strategy, ... benchmark='SPY', ... start_date='2020-01-01', ... end_date='2023-12-31' ... ) >>> >>> # With custom benchmark >>> def custom_benchmark(returns_df): ... return returns_df.mean(axis=1) >>> >>> results = backtester.run_backtest( ... strategy=my_strategy, ... benchmark=custom_benchmark, ... verbose=True ... ) \"\"\" _bar_dict @staticmethod def _bar_dict ( ts : pd . Timestamp , data : Dict [ str , pd . DataFrame ]) -> Dict [ str , dict | None ]: \"\"\" Create bar data dictionary for a specific timestamp. Parameters ---------- ts : pd.Timestamp Timestamp for which to create bar data. data : Dict[str, pd.DataFrame] Dictionary mapping ticker symbols to their price data. Returns ------- Dict[str, dict | None] Dictionary mapping ticker symbols to bar data or None if no data available. Notes ----- Bar data includes open, high, low, close, and volume for each ticker. Returns None for tickers without data at the specified timestamp. \"\"\" Data Structures Bar Data Format The bar data passed to strategy step methods has the following structure: { \"ticker_symbol\" : { \"open\" : float , \"high\" : float , \"low\" : float , \"close\" : float , \"volume\" : float } } Strategy Step Method Strategies must implement a step method with the following signature: def step ( self , timestamp : pd . Timestamp , bar_data : Dict [ str , dict ]) -> Dict [ str , float ]: \"\"\" Generate allocation weights for the current timestamp. Parameters ---------- timestamp : pd.Timestamp Current timestamp. bar_data : Dict[str, dict] Bar data for all tickers. Returns ------- Dict[str, float] Allocation weights for each ticker (should sum to 1.0). \"\"\" Backtest Results The run_backtest method returns a dictionary with the following structure: { \"signals_df\" : pd . DataFrame , # Strategy allocations over time \"tickers_returns\" : pd . DataFrame , # Individual asset returns \"strategy_returns\" : pd . Series , # Strategy performance \"benchmark_returns\" : pd . Series # Benchmark performance } Error Handling Common Exceptions InvalidBenchmarkError : Raised when an invalid benchmark is provided ValueError : Raised for invalid date ranges or missing data requirements KeyError : May be raised when accessing ticker data Data Validation The backtester performs several validation checks: Date range validation : Ensures start_date \u2264 end_date Data availability : Checks for missing tickers based on require_all_tickers History requirements : Validates data availability based on require_all_history Trading calendar : Ensures valid trading dates when calendar is provided Performance Considerations Memory usage : Large datasets may require significant memory Processing time : Complex strategies or long time periods increase computation time Data validation : Use require_all_tickers=True for strict data requirements Progress tracking : Enable verbose=True for long-running backtests Best Practices Always use shift_signals=True to prevent lookahead bias Validate your data before running backtests Use appropriate benchmarks for meaningful comparisons Handle missing data gracefully in your strategies Test with small datasets before running large backtests Use trading calendars for realistic backtesting scenarios","title":"Backtester API Reference"},{"location":"api/backtester/#backtester-api-reference","text":"This module provides a step-driven backtester that supports intraday bars and optional exchange trading calendars.","title":"Backtester API Reference"},{"location":"api/backtester/#exceptions","text":"","title":"Exceptions"},{"location":"api/backtester/#invalidbenchmarkerror","text":"class InvalidBenchmarkError ( Exception ): \"\"\"Raised when the requested benchmark is neither a standard name nor a valid ticker.\"\"\" Description : Custom exception raised when an invalid benchmark is provided to the backtester.","title":"InvalidBenchmarkError"},{"location":"api/backtester/#functions","text":"","title":"Functions"},{"location":"api/backtester/#benchmark_equal_weight","text":"def benchmark_equal_weight ( ret_df : pd . DataFrame , * _ , ** __ ) -> pd . Series : \"\"\" Calculate equal-weighted benchmark returns. Parameters ---------- ret_df : pd.DataFrame DataFrame containing asset returns with tickers as columns and dates as index. *_, **__ : Additional arguments (ignored for compatibility). Returns ------- pd.Series Equal-weighted portfolio returns. Notes ----- This benchmark assigns equal weights (1/n) to all assets in the portfolio. \"\"\" return ret_df . mean ( axis = 1 )","title":"benchmark_equal_weight"},{"location":"api/backtester/#benchmark_markowitz","text":"def benchmark_markowitz ( ret_df : pd . DataFrame , lookback : int = 60 , shift_signals : bool = True , verbose : bool = False , ) -> pd . Series : \"\"\" Calculate Markowitz mean-variance optimized benchmark returns. Parameters ---------- ret_df : pd.DataFrame DataFrame containing asset returns with tickers as columns and dates as index. lookback : int, default=60 Number of periods to use for covariance estimation. shift_signals : bool, default=True Whether to apply weights on the next day to prevent lookahead bias. verbose : bool, default=False Whether to show progress bar during optimization. Returns ------- pd.Series Markowitz optimized portfolio returns. Notes ----- Uses convex optimization to minimize portfolio variance subject to full investment constraint. Falls back to equal weights if optimization fails. \"\"\"","title":"benchmark_markowitz"},{"location":"api/backtester/#constants","text":"","title":"Constants"},{"location":"api/backtester/#standard_benchmarks","text":"STANDARD_BENCHMARKS : Dict [ str , Callable ] = { \"equal_weight\" : benchmark_equal_weight , \"markowitz\" : benchmark_markowitz , } Description : Dictionary mapping standard benchmark names to their corresponding functions.","title":"STANDARD_BENCHMARKS"},{"location":"api/backtester/#classes","text":"","title":"Classes"},{"location":"api/backtester/#benchmarktypes","text":"class BenchmarkTypes : \"\"\" Enumeration of benchmark types used by the backtester. Attributes ---------- STANDARD_BENCHMARK : int Built-in benchmark (equal_weight, markowitz). TICKER : int Single ticker symbol benchmark. CUSTOM_METHOD : int Custom benchmark function. INVALID : int Invalid benchmark type. \"\"\" STANDARD_BENCHMARK = 0 TICKER = 1 CUSTOM_METHOD = 2 INVALID = 3","title":"BenchmarkTypes"},{"location":"api/backtester/#backtester","text":"class Backtester : \"\"\" A step-driven backtester that supports intraday bars and optional exchange trading calendars. The Backtester class is the core component for executing trading strategies and generating performance results. It handles data loading, signal generation, return calculation, and benchmark comparison. Parameters ---------- market_data_loader : MarketDataLoader The primary data loader for market data. alternative_data_loader : optional Additional data loader for alternative data sources. calendar : str or mcal.ExchangeCalendar, optional Trading calendar for date filtering. Can be a string (calendar name) or ExchangeCalendar object. Attributes ---------- market_data_loader : MarketDataLoader The primary market data loader instance. alternative_data_loader : optional Alternative data loader instance. calendar : mcal.ExchangeCalendar or None Trading calendar instance. Examples -------- >>> from portwine import Backtester, EODHDMarketDataLoader >>> import pandas_market_calendars as mcal >>> >>> # Basic backtester >>> data_loader = EODHDMarketDataLoader(data_path='path/to/data/') >>> backtester = Backtester(market_data_loader=data_loader) >>> >>> # With trading calendar >>> calendar = mcal.get_calendar('NYSE') >>> backtester = Backtester( ... market_data_loader=data_loader, ... calendar=calendar ... ) \"\"\"","title":"Backtester"},{"location":"api/backtester/#methods","text":"","title":"Methods"},{"location":"api/backtester/#init","text":"def __init__ ( self , market_data_loader : MarketDataLoader , alternative_data_loader = None , calendar : Optional [ Union [ str , mcal . ExchangeCalendar ]] = None ): \"\"\" Initialize the Backtester. Parameters ---------- market_data_loader : MarketDataLoader The primary data loader for market data. alternative_data_loader : optional Additional data loader for alternative data sources. calendar : str or mcal.ExchangeCalendar, optional Trading calendar for date filtering. Can be a string (calendar name) or ExchangeCalendar object. \"\"\"","title":"init"},{"location":"api/backtester/#_split_tickers","text":"def _split_tickers ( self , tickers : List [ str ]) -> Tuple [ List [ str ], List [ str ]]: \"\"\" Split tickers into regular and alternative data tickers. Parameters ---------- tickers : List[str] List of ticker symbols to split. Returns ------- Tuple[List[str], List[str]] Tuple of (regular_tickers, alternative_tickers). Notes ----- Alternative data tickers are identified by the presence of ':' in the ticker symbol. \"\"\"","title":"_split_tickers"},{"location":"api/backtester/#get_benchmark_type","text":"def get_benchmark_type ( self , benchmark ) -> int : \"\"\" Determine the type of benchmark provided. Parameters ---------- benchmark : str or callable The benchmark to classify. Returns ------- int Benchmark type from BenchmarkTypes enum. Notes ----- Checks if benchmark is a standard name, valid ticker, or custom function. \"\"\"","title":"get_benchmark_type"},{"location":"api/backtester/#run_backtest","text":"def run_backtest ( self , strategy , shift_signals : bool = True , benchmark : Union [ str , Callable , None ] = \"equal_weight\" , start_date = None , end_date = None , require_all_history : bool = False , require_all_tickers : bool = False , verbose : bool = False ) -> Optional [ Dict [ str , pd . DataFrame ]]: \"\"\" Execute a backtest using the provided strategy. Parameters ---------- strategy : object Strategy object that must implement a `step` method. shift_signals : bool, default=True Whether to apply signals on the next day (prevents lookahead bias). benchmark : str, callable, or None, default=\"equal_weight\" Benchmark for comparison. Options: - String: \"equal_weight\", \"markowitz\", or ticker symbol - Callable: Custom benchmark function - None: No benchmark start_date : datetime or str, optional Start date for backtest. end_date : datetime or str, optional End date for backtest. require_all_history : bool, default=False Require all tickers to have data from the same start date. require_all_tickers : bool, default=False Require data for all requested tickers. verbose : bool, default=False Show progress bars during execution. Returns ------- Dict[str, pd.DataFrame] or None Dictionary containing backtest results: - 'signals_df': Strategy allocations over time - 'tickers_returns': Individual asset returns - 'strategy_returns': Strategy performance - 'benchmark_returns': Benchmark performance Raises ------ ValueError If start_date > end_date or no trading dates after filtering. InvalidBenchmarkError If benchmark is invalid. Notes ----- The strategy object must have: - A `tickers` attribute containing the list of ticker symbols - A `step(timestamp, bar_data)` method that returns allocation weights Examples -------- >>> # Basic backtest >>> results = backtester.run_backtest( ... strategy=my_strategy, ... benchmark='SPY', ... start_date='2020-01-01', ... end_date='2023-12-31' ... ) >>> >>> # With custom benchmark >>> def custom_benchmark(returns_df): ... return returns_df.mean(axis=1) >>> >>> results = backtester.run_backtest( ... strategy=my_strategy, ... benchmark=custom_benchmark, ... verbose=True ... ) \"\"\"","title":"run_backtest"},{"location":"api/backtester/#_bar_dict","text":"@staticmethod def _bar_dict ( ts : pd . Timestamp , data : Dict [ str , pd . DataFrame ]) -> Dict [ str , dict | None ]: \"\"\" Create bar data dictionary for a specific timestamp. Parameters ---------- ts : pd.Timestamp Timestamp for which to create bar data. data : Dict[str, pd.DataFrame] Dictionary mapping ticker symbols to their price data. Returns ------- Dict[str, dict | None] Dictionary mapping ticker symbols to bar data or None if no data available. Notes ----- Bar data includes open, high, low, close, and volume for each ticker. Returns None for tickers without data at the specified timestamp. \"\"\"","title":"_bar_dict"},{"location":"api/backtester/#data-structures","text":"","title":"Data Structures"},{"location":"api/backtester/#bar-data-format","text":"The bar data passed to strategy step methods has the following structure: { \"ticker_symbol\" : { \"open\" : float , \"high\" : float , \"low\" : float , \"close\" : float , \"volume\" : float } }","title":"Bar Data Format"},{"location":"api/backtester/#strategy-step-method","text":"Strategies must implement a step method with the following signature: def step ( self , timestamp : pd . Timestamp , bar_data : Dict [ str , dict ]) -> Dict [ str , float ]: \"\"\" Generate allocation weights for the current timestamp. Parameters ---------- timestamp : pd.Timestamp Current timestamp. bar_data : Dict[str, dict] Bar data for all tickers. Returns ------- Dict[str, float] Allocation weights for each ticker (should sum to 1.0). \"\"\"","title":"Strategy Step Method"},{"location":"api/backtester/#backtest-results","text":"The run_backtest method returns a dictionary with the following structure: { \"signals_df\" : pd . DataFrame , # Strategy allocations over time \"tickers_returns\" : pd . DataFrame , # Individual asset returns \"strategy_returns\" : pd . Series , # Strategy performance \"benchmark_returns\" : pd . Series # Benchmark performance }","title":"Backtest Results"},{"location":"api/backtester/#error-handling","text":"","title":"Error Handling"},{"location":"api/backtester/#common-exceptions","text":"InvalidBenchmarkError : Raised when an invalid benchmark is provided ValueError : Raised for invalid date ranges or missing data requirements KeyError : May be raised when accessing ticker data","title":"Common Exceptions"},{"location":"api/backtester/#data-validation","text":"The backtester performs several validation checks: Date range validation : Ensures start_date \u2264 end_date Data availability : Checks for missing tickers based on require_all_tickers History requirements : Validates data availability based on require_all_history Trading calendar : Ensures valid trading dates when calendar is provided","title":"Data Validation"},{"location":"api/backtester/#performance-considerations","text":"Memory usage : Large datasets may require significant memory Processing time : Complex strategies or long time periods increase computation time Data validation : Use require_all_tickers=True for strict data requirements Progress tracking : Enable verbose=True for long-running backtests","title":"Performance Considerations"},{"location":"api/backtester/#best-practices","text":"Always use shift_signals=True to prevent lookahead bias Validate your data before running backtests Use appropriate benchmarks for meaningful comparisons Handle missing data gracefully in your strategies Test with small datasets before running large backtests Use trading calendars for realistic backtesting scenarios","title":"Best Practices"},{"location":"api/strategies/","text":"Strategies API Strategies are the core components of portwine that define how your portfolio allocates capital based on market conditions. StrategyBase Class All strategies in portwine inherit from the StrategyBase class: from portwine import StrategyBase class StrategyBase : \"\"\" Base class for all strategies in portwine. All strategies must inherit from this class and implement the `step` method. \"\"\" def __init__ ( self , tickers : List [ str ]): \"\"\" Initialize the strategy. Parameters ---------- tickers : List[str] List of ticker symbols this strategy will trade \"\"\" self . tickers = tickers def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Process daily data and return allocations. This method is called for each trading day and must return allocation weights for each ticker. Parameters ---------- current_date : pd.Timestamp Current trading date daily_data : Dict[str, Dict] Dictionary with ticker -> OHLCV data Returns ------- Dict[str, float] Dictionary mapping ticker symbols to allocation weights (0.0 to 1.0) \"\"\" raise NotImplementedError ( \"Subclasses must implement step method\" ) Built-in Strategies SimpleMomentumStrategy A simple momentum strategy that invests in the best-performing asset: from portwine import SimpleMomentumStrategy class SimpleMomentumStrategy ( StrategyBase ): \"\"\" A simple momentum strategy that: 1. Calculates N-day momentum for each ticker 2. Invests in the top performing ticker 3. Rebalances weekly (every Friday) \"\"\" def __init__ ( self , tickers : List [ str ], lookback_days : int = 10 ): \"\"\" Parameters ---------- tickers : List[str] List of ticker symbols to consider for investment lookback_days : int, default 10 Number of days to use for momentum calculation \"\"\" super () . __init__ ( tickers ) self . lookback_days = lookback_days self . price_history = { ticker : [] for ticker in tickers } self . current_signals = { ticker : 0.0 for ticker in tickers } self . dates = [] def is_friday ( self , date : pd . Timestamp ) -> bool : \"\"\"Check if given date is a Friday (weekday 4)\"\"\" return date . weekday () == 4 def calculate_momentum ( self , ticker : str ) -> float : \"\"\"Calculate simple price momentum over lookback period\"\"\" prices = self . price_history [ ticker ] # Need at least lookback_days+1 data points if len ( prices ) <= self . lookback_days : return - 999.0 # Get starting and ending prices for momentum calculation start_price = prices [ - self . lookback_days - 1 ] end_price = prices [ - 1 ] # Check for valid prices if start_price is None or end_price is None or start_price <= 0 : return - 999.0 # Return simple momentum (end/start - 1) return end_price / start_price - 1.0 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Process daily data and determine allocations \"\"\" # Track dates for rebalancing logic self . dates . append ( current_date ) # Update price history for each ticker for ticker in self . tickers : price = None if daily_data . get ( ticker ) is not None : price = daily_data [ ticker ] . get ( 'close' , None ) # Forward fill missing data if price is None and len ( self . price_history [ ticker ]) > 0 : price = self . price_history [ ticker ][ - 1 ] self . price_history [ ticker ] . append ( price ) # Only rebalance on Fridays if self . is_friday ( current_date ): # Calculate momentum for each ticker momentum_scores = {} for ticker in self . tickers : momentum_scores [ ticker ] = self . calculate_momentum ( ticker ) # Find best performing ticker best_ticker = max ( momentum_scores . items (), key = lambda x : x [ 1 ] if x [ 1 ] != - 999.0 else - float ( 'inf' ))[ 0 ] # Reset all allocations to zero self . current_signals = { ticker : 0.0 for ticker in self . tickers } # Allocate 100% to best performer if we have valid momentum if momentum_scores [ best_ticker ] != - 999.0 : self . current_signals [ best_ticker ] = 1.0 # Return current allocations return self . current_signals . copy () Creating Custom Strategies Basic Strategy Template class MyCustomStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ], ** parameters ): super () . __init__ ( tickers ) # Initialize your strategy parameters and state self . parameters = parameters self . state = {} def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Your strategy logic goes here. Parameters ---------- current_date : pd.Timestamp Current trading date daily_data : Dict[str, Dict] Dictionary with ticker -> OHLCV data Returns ------- Dict[str, float] Allocation weights for each ticker \"\"\" # Your strategy implementation allocations = {} # Example: Equal weight allocation weight = 1.0 / len ( self . tickers ) for ticker in self . tickers : allocations [ ticker ] = weight return allocations Advanced Strategy Example class MeanReversionStrategy ( StrategyBase ): \"\"\" A mean reversion strategy that: 1. Calculates rolling z-scores for each asset 2. Goes long assets with negative z-scores (oversold) 3. Goes short assets with positive z-scores (overbought) \"\"\" def __init__ ( self , tickers : List [ str ], lookback_days : int = 60 , z_threshold : float = 1.0 ): super () . __init__ ( tickers ) self . lookback_days = lookback_days self . z_threshold = z_threshold self . price_history = { ticker : [] for ticker in tickers } def calculate_z_score ( self , ticker : str ) -> float : \"\"\"Calculate z-score for a ticker\"\"\" prices = self . price_history [ ticker ] if len ( prices ) < self . lookback_days : return 0.0 recent_prices = prices [ - self . lookback_days :] current_price = recent_prices [ - 1 ] if current_price is None : return 0.0 mean_price = np . mean ([ p for p in recent_prices if p is not None ]) std_price = np . std ([ p for p in recent_prices if p is not None ]) if std_price == 0 : return 0.0 return ( current_price - mean_price ) / std_price def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Update price history for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) else : # Forward fill if no new data if len ( self . price_history [ ticker ]) > 0 : self . price_history [ ticker ] . append ( self . price_history [ ticker ][ - 1 ]) else : self . price_history [ ticker ] . append ( None ) # Calculate allocations based on z-scores allocations = {} total_weight = 0.0 for ticker in self . tickers : z_score = self . calculate_z_score ( ticker ) if z_score < - self . z_threshold : # Oversold - go long allocations [ ticker ] = 1.0 total_weight += 1.0 elif z_score > self . z_threshold : # Overbought - go short allocations [ ticker ] = - 1.0 total_weight += 1.0 else : # Neutral allocations [ ticker ] = 0.0 # Normalize weights if total_weight > 0 : for ticker in allocations : allocations [ ticker ] /= total_weight return allocations Strategy Best Practices 1. Handle Missing Data def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: allocations = {} for ticker in self . tickers : if ticker in daily_data and daily_data [ ticker ] is not None : # Process valid data allocations [ ticker ] = self . calculate_weight ( ticker , daily_data [ ticker ]) else : # Handle missing data gracefully allocations [ ticker ] = 0.0 return allocations 2. Validate Allocations def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Calculate raw allocations allocations = self . calculate_allocations ( daily_data ) # Ensure weights sum to 1.0 (or 0.0 for cash) total_weight = sum ( abs ( weight ) for weight in allocations . values ()) if total_weight > 0 : # Normalize weights for ticker in allocations : allocations [ ticker ] /= total_weight return allocations 3. Use Efficient Data Structures def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Pre-allocate data structures for efficiency self . price_history = { ticker : [] for ticker in tickers } self . signals = { ticker : 0.0 for ticker in tickers } self . last_rebalance = None 4. Implement State Management class StatefulStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) self . position_history = [] self . last_rebalance_date = None self . current_positions = { ticker : 0.0 for ticker in tickers } def should_rebalance ( self , current_date : pd . Timestamp ) -> bool : \"\"\"Determine if rebalancing is needed\"\"\" if self . last_rebalance_date is None : return True # Rebalance weekly days_since_rebalance = ( current_date - self . last_rebalance_date ) . days return days_since_rebalance >= 7 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: if self . should_rebalance ( current_date ): # Perform rebalancing self . last_rebalance_date = current_date new_allocations = self . calculate_new_allocations ( daily_data ) # Track position changes for ticker in self . tickers : old_position = self . current_positions . get ( ticker , 0.0 ) new_position = new_allocations . get ( ticker , 0.0 ) if abs ( new_position - old_position ) > 0.01 : # 1% threshold self . position_history . append ({ 'date' : current_date , 'ticker' : ticker , 'old_position' : old_position , 'new_position' : new_position }) self . current_positions = new_allocations . copy () return self . current_positions . copy () Strategy Testing Unit Testing Your Strategy import pytest import pandas as pd from unittest.mock import Mock def test_strategy_initialization (): \"\"\"Test strategy initialization\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) assert strategy . tickers == [ 'AAPL' , 'GOOGL' ] def test_strategy_step (): \"\"\"Test strategy step method\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) # Mock daily data daily_data = { 'AAPL' : { 'open' : 150 , 'high' : 152 , 'low' : 149 , 'close' : 151 , 'volume' : 1000000 }, 'GOOGL' : { 'open' : 2800 , 'high' : 2820 , 'low' : 2790 , 'close' : 2810 , 'volume' : 500000 } } current_date = pd . Timestamp ( '2023-01-01' ) allocations = strategy . step ( current_date , daily_data ) # Verify allocations assert 'AAPL' in allocations assert 'GOOGL' in allocations assert sum ( allocations . values ()) == 1.0 # Should sum to 1.0 def test_strategy_missing_data (): \"\"\"Test strategy handles missing data gracefully\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) # Mock daily data with missing ticker daily_data = { 'AAPL' : { 'open' : 150 , 'high' : 152 , 'low' : 149 , 'close' : 151 , 'volume' : 1000000 } # GOOGL missing } current_date = pd . Timestamp ( '2023-01-01' ) allocations = strategy . step ( current_date , daily_data ) # Should handle missing data assert 'GOOGL' in allocations assert allocations [ 'GOOGL' ] == 0.0 # Should be 0 for missing data Performance Considerations Memory Management class MemoryEfficientStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ], max_history : int = 1000 ): super () . __init__ ( tickers ) self . max_history = max_history self . price_history = { ticker : [] for ticker in tickers } def add_price ( self , ticker : str , price : float ): \"\"\"Add price while maintaining maximum history size\"\"\" self . price_history [ ticker ] . append ( price ) # Keep only the most recent prices if len ( self . price_history [ ticker ]) > self . max_history : self . price_history [ ticker ] = self . price_history [ ticker ][ - self . max_history :] Computational Efficiency class EfficientStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Pre-calculate constants self . n_tickers = len ( tickers ) self . equal_weight = 1.0 / self . n_tickers # Use numpy arrays for faster computation self . price_array = np . zeros (( self . n_tickers , 1000 )) # Pre-allocate self . current_index = 0 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Use vectorized operations when possible prices = np . array ([ daily_data . get ( ticker , {}) . get ( 'close' , 0 ) for ticker in self . tickers ]) # Your efficient strategy logic here # ... return { ticker : self . equal_weight for ticker in self . tickers } Next Steps Learn about backtesting strategies Explore performance analysis Check out data management","title":"Strategies API"},{"location":"api/strategies/#strategies-api","text":"Strategies are the core components of portwine that define how your portfolio allocates capital based on market conditions.","title":"Strategies API"},{"location":"api/strategies/#strategybase-class","text":"All strategies in portwine inherit from the StrategyBase class: from portwine import StrategyBase class StrategyBase : \"\"\" Base class for all strategies in portwine. All strategies must inherit from this class and implement the `step` method. \"\"\" def __init__ ( self , tickers : List [ str ]): \"\"\" Initialize the strategy. Parameters ---------- tickers : List[str] List of ticker symbols this strategy will trade \"\"\" self . tickers = tickers def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Process daily data and return allocations. This method is called for each trading day and must return allocation weights for each ticker. Parameters ---------- current_date : pd.Timestamp Current trading date daily_data : Dict[str, Dict] Dictionary with ticker -> OHLCV data Returns ------- Dict[str, float] Dictionary mapping ticker symbols to allocation weights (0.0 to 1.0) \"\"\" raise NotImplementedError ( \"Subclasses must implement step method\" )","title":"StrategyBase Class"},{"location":"api/strategies/#built-in-strategies","text":"","title":"Built-in Strategies"},{"location":"api/strategies/#simplemomentumstrategy","text":"A simple momentum strategy that invests in the best-performing asset: from portwine import SimpleMomentumStrategy class SimpleMomentumStrategy ( StrategyBase ): \"\"\" A simple momentum strategy that: 1. Calculates N-day momentum for each ticker 2. Invests in the top performing ticker 3. Rebalances weekly (every Friday) \"\"\" def __init__ ( self , tickers : List [ str ], lookback_days : int = 10 ): \"\"\" Parameters ---------- tickers : List[str] List of ticker symbols to consider for investment lookback_days : int, default 10 Number of days to use for momentum calculation \"\"\" super () . __init__ ( tickers ) self . lookback_days = lookback_days self . price_history = { ticker : [] for ticker in tickers } self . current_signals = { ticker : 0.0 for ticker in tickers } self . dates = [] def is_friday ( self , date : pd . Timestamp ) -> bool : \"\"\"Check if given date is a Friday (weekday 4)\"\"\" return date . weekday () == 4 def calculate_momentum ( self , ticker : str ) -> float : \"\"\"Calculate simple price momentum over lookback period\"\"\" prices = self . price_history [ ticker ] # Need at least lookback_days+1 data points if len ( prices ) <= self . lookback_days : return - 999.0 # Get starting and ending prices for momentum calculation start_price = prices [ - self . lookback_days - 1 ] end_price = prices [ - 1 ] # Check for valid prices if start_price is None or end_price is None or start_price <= 0 : return - 999.0 # Return simple momentum (end/start - 1) return end_price / start_price - 1.0 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Process daily data and determine allocations \"\"\" # Track dates for rebalancing logic self . dates . append ( current_date ) # Update price history for each ticker for ticker in self . tickers : price = None if daily_data . get ( ticker ) is not None : price = daily_data [ ticker ] . get ( 'close' , None ) # Forward fill missing data if price is None and len ( self . price_history [ ticker ]) > 0 : price = self . price_history [ ticker ][ - 1 ] self . price_history [ ticker ] . append ( price ) # Only rebalance on Fridays if self . is_friday ( current_date ): # Calculate momentum for each ticker momentum_scores = {} for ticker in self . tickers : momentum_scores [ ticker ] = self . calculate_momentum ( ticker ) # Find best performing ticker best_ticker = max ( momentum_scores . items (), key = lambda x : x [ 1 ] if x [ 1 ] != - 999.0 else - float ( 'inf' ))[ 0 ] # Reset all allocations to zero self . current_signals = { ticker : 0.0 for ticker in self . tickers } # Allocate 100% to best performer if we have valid momentum if momentum_scores [ best_ticker ] != - 999.0 : self . current_signals [ best_ticker ] = 1.0 # Return current allocations return self . current_signals . copy ()","title":"SimpleMomentumStrategy"},{"location":"api/strategies/#creating-custom-strategies","text":"","title":"Creating Custom Strategies"},{"location":"api/strategies/#basic-strategy-template","text":"class MyCustomStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ], ** parameters ): super () . __init__ ( tickers ) # Initialize your strategy parameters and state self . parameters = parameters self . state = {} def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: \"\"\" Your strategy logic goes here. Parameters ---------- current_date : pd.Timestamp Current trading date daily_data : Dict[str, Dict] Dictionary with ticker -> OHLCV data Returns ------- Dict[str, float] Allocation weights for each ticker \"\"\" # Your strategy implementation allocations = {} # Example: Equal weight allocation weight = 1.0 / len ( self . tickers ) for ticker in self . tickers : allocations [ ticker ] = weight return allocations","title":"Basic Strategy Template"},{"location":"api/strategies/#advanced-strategy-example","text":"class MeanReversionStrategy ( StrategyBase ): \"\"\" A mean reversion strategy that: 1. Calculates rolling z-scores for each asset 2. Goes long assets with negative z-scores (oversold) 3. Goes short assets with positive z-scores (overbought) \"\"\" def __init__ ( self , tickers : List [ str ], lookback_days : int = 60 , z_threshold : float = 1.0 ): super () . __init__ ( tickers ) self . lookback_days = lookback_days self . z_threshold = z_threshold self . price_history = { ticker : [] for ticker in tickers } def calculate_z_score ( self , ticker : str ) -> float : \"\"\"Calculate z-score for a ticker\"\"\" prices = self . price_history [ ticker ] if len ( prices ) < self . lookback_days : return 0.0 recent_prices = prices [ - self . lookback_days :] current_price = recent_prices [ - 1 ] if current_price is None : return 0.0 mean_price = np . mean ([ p for p in recent_prices if p is not None ]) std_price = np . std ([ p for p in recent_prices if p is not None ]) if std_price == 0 : return 0.0 return ( current_price - mean_price ) / std_price def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Update price history for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) else : # Forward fill if no new data if len ( self . price_history [ ticker ]) > 0 : self . price_history [ ticker ] . append ( self . price_history [ ticker ][ - 1 ]) else : self . price_history [ ticker ] . append ( None ) # Calculate allocations based on z-scores allocations = {} total_weight = 0.0 for ticker in self . tickers : z_score = self . calculate_z_score ( ticker ) if z_score < - self . z_threshold : # Oversold - go long allocations [ ticker ] = 1.0 total_weight += 1.0 elif z_score > self . z_threshold : # Overbought - go short allocations [ ticker ] = - 1.0 total_weight += 1.0 else : # Neutral allocations [ ticker ] = 0.0 # Normalize weights if total_weight > 0 : for ticker in allocations : allocations [ ticker ] /= total_weight return allocations","title":"Advanced Strategy Example"},{"location":"api/strategies/#strategy-best-practices","text":"","title":"Strategy Best Practices"},{"location":"api/strategies/#1-handle-missing-data","text":"def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: allocations = {} for ticker in self . tickers : if ticker in daily_data and daily_data [ ticker ] is not None : # Process valid data allocations [ ticker ] = self . calculate_weight ( ticker , daily_data [ ticker ]) else : # Handle missing data gracefully allocations [ ticker ] = 0.0 return allocations","title":"1. Handle Missing Data"},{"location":"api/strategies/#2-validate-allocations","text":"def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Calculate raw allocations allocations = self . calculate_allocations ( daily_data ) # Ensure weights sum to 1.0 (or 0.0 for cash) total_weight = sum ( abs ( weight ) for weight in allocations . values ()) if total_weight > 0 : # Normalize weights for ticker in allocations : allocations [ ticker ] /= total_weight return allocations","title":"2. Validate Allocations"},{"location":"api/strategies/#3-use-efficient-data-structures","text":"def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Pre-allocate data structures for efficiency self . price_history = { ticker : [] for ticker in tickers } self . signals = { ticker : 0.0 for ticker in tickers } self . last_rebalance = None","title":"3. Use Efficient Data Structures"},{"location":"api/strategies/#4-implement-state-management","text":"class StatefulStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) self . position_history = [] self . last_rebalance_date = None self . current_positions = { ticker : 0.0 for ticker in tickers } def should_rebalance ( self , current_date : pd . Timestamp ) -> bool : \"\"\"Determine if rebalancing is needed\"\"\" if self . last_rebalance_date is None : return True # Rebalance weekly days_since_rebalance = ( current_date - self . last_rebalance_date ) . days return days_since_rebalance >= 7 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: if self . should_rebalance ( current_date ): # Perform rebalancing self . last_rebalance_date = current_date new_allocations = self . calculate_new_allocations ( daily_data ) # Track position changes for ticker in self . tickers : old_position = self . current_positions . get ( ticker , 0.0 ) new_position = new_allocations . get ( ticker , 0.0 ) if abs ( new_position - old_position ) > 0.01 : # 1% threshold self . position_history . append ({ 'date' : current_date , 'ticker' : ticker , 'old_position' : old_position , 'new_position' : new_position }) self . current_positions = new_allocations . copy () return self . current_positions . copy ()","title":"4. Implement State Management"},{"location":"api/strategies/#strategy-testing","text":"","title":"Strategy Testing"},{"location":"api/strategies/#unit-testing-your-strategy","text":"import pytest import pandas as pd from unittest.mock import Mock def test_strategy_initialization (): \"\"\"Test strategy initialization\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) assert strategy . tickers == [ 'AAPL' , 'GOOGL' ] def test_strategy_step (): \"\"\"Test strategy step method\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) # Mock daily data daily_data = { 'AAPL' : { 'open' : 150 , 'high' : 152 , 'low' : 149 , 'close' : 151 , 'volume' : 1000000 }, 'GOOGL' : { 'open' : 2800 , 'high' : 2820 , 'low' : 2790 , 'close' : 2810 , 'volume' : 500000 } } current_date = pd . Timestamp ( '2023-01-01' ) allocations = strategy . step ( current_date , daily_data ) # Verify allocations assert 'AAPL' in allocations assert 'GOOGL' in allocations assert sum ( allocations . values ()) == 1.0 # Should sum to 1.0 def test_strategy_missing_data (): \"\"\"Test strategy handles missing data gracefully\"\"\" strategy = MyCustomStrategy ([ 'AAPL' , 'GOOGL' ]) # Mock daily data with missing ticker daily_data = { 'AAPL' : { 'open' : 150 , 'high' : 152 , 'low' : 149 , 'close' : 151 , 'volume' : 1000000 } # GOOGL missing } current_date = pd . Timestamp ( '2023-01-01' ) allocations = strategy . step ( current_date , daily_data ) # Should handle missing data assert 'GOOGL' in allocations assert allocations [ 'GOOGL' ] == 0.0 # Should be 0 for missing data","title":"Unit Testing Your Strategy"},{"location":"api/strategies/#performance-considerations","text":"","title":"Performance Considerations"},{"location":"api/strategies/#memory-management","text":"class MemoryEfficientStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ], max_history : int = 1000 ): super () . __init__ ( tickers ) self . max_history = max_history self . price_history = { ticker : [] for ticker in tickers } def add_price ( self , ticker : str , price : float ): \"\"\"Add price while maintaining maximum history size\"\"\" self . price_history [ ticker ] . append ( price ) # Keep only the most recent prices if len ( self . price_history [ ticker ]) > self . max_history : self . price_history [ ticker ] = self . price_history [ ticker ][ - self . max_history :]","title":"Memory Management"},{"location":"api/strategies/#computational-efficiency","text":"class EfficientStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Pre-calculate constants self . n_tickers = len ( tickers ) self . equal_weight = 1.0 / self . n_tickers # Use numpy arrays for faster computation self . price_array = np . zeros (( self . n_tickers , 1000 )) # Pre-allocate self . current_index = 0 def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Use vectorized operations when possible prices = np . array ([ daily_data . get ( ticker , {}) . get ( 'close' , 0 ) for ticker in self . tickers ]) # Your efficient strategy logic here # ... return { ticker : self . equal_weight for ticker in self . tickers }","title":"Computational Efficiency"},{"location":"api/strategies/#next-steps","text":"Learn about backtesting strategies Explore performance analysis Check out data management","title":"Next Steps"},{"location":"getting-started/installation/","text":"Installation Prerequisites Portwine requires Python 3.8 or higher. We recommend using a virtual environment to manage dependencies. Installing Portwine Using pip The easiest way to install portwine is using pip: pip install portwine Using Poetry If you prefer using Poetry for dependency management: poetry add portwine From Source To install from the latest development version: git clone https://github.com/yourusername/portwine.git cd portwine pip install -e . Dependencies Portwine has the following key dependencies: pandas - Data manipulation and analysis numpy - Numerical computing cvxpy - Convex optimization (for some benchmarks) tqdm - Progress bars pandas-market-calendars - Trading calendar support Optional Dependencies Some features require additional packages: matplotlib - For plotting and visualization seaborn - Enhanced plotting capabilities plotly - Interactive plots Verification To verify your installation, run: import portwine print ( portwine . __version__ ) Next Steps Once installed, head over to the Quick Start guide to run your first backtest!","title":"Installation"},{"location":"getting-started/installation/#installation","text":"","title":"Installation"},{"location":"getting-started/installation/#prerequisites","text":"Portwine requires Python 3.8 or higher. We recommend using a virtual environment to manage dependencies.","title":"Prerequisites"},{"location":"getting-started/installation/#installing-portwine","text":"","title":"Installing Portwine"},{"location":"getting-started/installation/#using-pip","text":"The easiest way to install portwine is using pip: pip install portwine","title":"Using pip"},{"location":"getting-started/installation/#using-poetry","text":"If you prefer using Poetry for dependency management: poetry add portwine","title":"Using Poetry"},{"location":"getting-started/installation/#from-source","text":"To install from the latest development version: git clone https://github.com/yourusername/portwine.git cd portwine pip install -e .","title":"From Source"},{"location":"getting-started/installation/#dependencies","text":"Portwine has the following key dependencies: pandas - Data manipulation and analysis numpy - Numerical computing cvxpy - Convex optimization (for some benchmarks) tqdm - Progress bars pandas-market-calendars - Trading calendar support","title":"Dependencies"},{"location":"getting-started/installation/#optional-dependencies","text":"Some features require additional packages: matplotlib - For plotting and visualization seaborn - Enhanced plotting capabilities plotly - Interactive plots","title":"Optional Dependencies"},{"location":"getting-started/installation/#verification","text":"To verify your installation, run: import portwine print ( portwine . __version__ )","title":"Verification"},{"location":"getting-started/installation/#next-steps","text":"Once installed, head over to the Quick Start guide to run your first backtest!","title":"Next Steps"},{"location":"getting-started/quick-start/","text":"Quick Start This guide will walk you through creating and running your first strategy with portwine. Your First Strategy Let's create a simple momentum strategy that invests in the best-performing asset from the previous period. from portwine.backtester import Backtester from portwine.loaders import EODHDMarketDataLoader from portwine.strategies import StrategyBase class SimpleMomentumStrategy ( StrategyBase ): \"\"\" A simple momentum strategy that: 1. Calculates N-day momentum for each ticker 2. Invests in the top performing ticker 3. Rebalances weekly (every Friday) \"\"\" def __init__ ( self , tickers , lookback_days = 10 ): \"\"\" Parameters ---------- tickers : list List of ticker symbols to consider for investment lookback_days : int, default 10 Number of days to use for momentum calculation \"\"\" # Pass tickers to parent class (StrategyBase) for initialization super () . __init__ ( tickers ) # Set the lookback window size for momentum calculation self . lookback_days = lookback_days # Initialize price history storage for each ticker # Because portwine is ONLY walkforward, we must store data after every timestep # to build up a history to run our analysis on self . price_history = { ticker : [] for ticker in tickers } def is_friday ( self , date ): \"\"\"Check if given date is a Friday (weekday 4)\"\"\" return date . weekday () == 4 def calculate_momentum ( self , ticker ): \"\"\"Calculate simple price momentum over lookback period\"\"\" # Get the price history for this specific ticker prices = self . price_history [ ticker ] # Need at least lookback_days+1 data points to calculate momentum # (we need start_price and end_price with lookback_days between them) if len ( prices ) <= self . lookback_days : return - 999.0 # Sentinel value indicating insufficient data # Get starting price (lookback_days ago) and ending price (today) start_price = prices [ - self . lookback_days - 1 ] # Price from lookback_days+1 ago end_price = prices [ - 1 ] # Most recent price (today) # Check for valid prices (not None and positive) if start_price is None or end_price is None or start_price <= 0 : return - 999.0 # Sentinel value for invalid data # Calculate momentum: (end_price / start_price) - 1 # This gives us the percentage change over the lookback period return end_price / start_price - 1.0 def step ( self , current_date , daily_data ): \"\"\" Process daily data and determine allocations Called by portwine for each trading day \"\"\" # Update price history for each ticker with today's data for ticker in self . tickers : price = None # Extract close price from daily data if available if daily_data . get ( ticker ) is not None : price = daily_data [ ticker ] . get ( 'close' , None ) # Forward fill missing data: if no price today, use yesterday's price if price is None and len ( self . price_history [ ticker ]) > 0 : price = self . price_history [ ticker ][ - 1 ] # Last known price # Add today's price (or forward-filled price) to history self . price_history [ ticker ] . append ( price ) # Only rebalance on Fridays to reduce trading costs if self . is_friday ( current_date ): # Calculate momentum score for each ticker momentum_scores = {} for ticker in self . tickers : momentum_scores [ ticker ] = self . calculate_momentum ( ticker ) # Find the ticker with the highest momentum score # Handle sentinel values (-999.0) by treating them as negative infinity best_ticker = max ( momentum_scores . items (), key = lambda x : x [ 1 ] if x [ 1 ] != - 999.0 else - float ( 'inf' ))[ 0 ] # Create new allocation signals signals = { ticker : 0.0 for ticker in self . tickers } # Allocate 100% to best performer if we have valid momentum data if momentum_scores [ best_ticker ] != - 999.0 : signals [ best_ticker ] = 1.0 return signals else : # On non-Friday days, return zero allocation (cash) # This maintains the previous Friday's allocation until next rebalance return { ticker : 0.0 for ticker in self . tickers } # Define your investment universe universe = [ 'MTUM' , 'VTV' , 'VUG' , 'IJR' , 'MDY' ] # Create a momentum strategy strategy = SimpleMomentumStrategy ( tickers = universe , lookback_days = 10 ) # Set up your data loader data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/eodhd/data/' ) # Create the backtester backtester = Backtester ( market_data_loader = data_loader ) # Run the backtest results = backtester . run_backtest ( strategy = strategy , benchmark_ticker = 'SPY' , start_date = '2020-01-01' , end_date = '2023-12-31' , verbose = True ) For a more detailed tutorial on writing strategies, click here . Understanding the Results The backtest returns a dictionary with several key components: # Strategy signals over time signals_df = results [ 'signals_df' ] # Individual asset returns ticker_returns = results [ 'tickers_returns' ] # Strategy performance strategy_returns = results [ 'strategy_returns' ] # Benchmark performance benchmark_returns = results [ 'benchmark_returns' ] These components contain all the information you need to analyze your strategy in any capacity. Analyzing Performance Portwine comes with built-in analyzers to help you understand your strategy's performance: from portwine.analyzers import EquityDrawdownAnalyzer , MonteCarloAnalyzer # Equity and drawdown analysis EquityDrawdownAnalyzer () . plot ( results ) # Monte Carlo simulation MonteCarloAnalyzer () . plot ( results ) For more information on the available analyzers and how to write your own analyzer, click here . What's Happening Under the Hood Data Loading : The data loader fetches historical price data for your universe Strategy Execution : Each day, your strategy receives the latest prices and decides allocations Signal Processing : Portwine handles the mechanics of applying your signals to the market Performance Calculation : Returns are calculated and compared against your benchmark Next Steps Learn more about building strategies Explore different analyzers Check out advanced examples","title":"Quick Start"},{"location":"getting-started/quick-start/#quick-start","text":"This guide will walk you through creating and running your first strategy with portwine.","title":"Quick Start"},{"location":"getting-started/quick-start/#your-first-strategy","text":"Let's create a simple momentum strategy that invests in the best-performing asset from the previous period. from portwine.backtester import Backtester from portwine.loaders import EODHDMarketDataLoader from portwine.strategies import StrategyBase class SimpleMomentumStrategy ( StrategyBase ): \"\"\" A simple momentum strategy that: 1. Calculates N-day momentum for each ticker 2. Invests in the top performing ticker 3. Rebalances weekly (every Friday) \"\"\" def __init__ ( self , tickers , lookback_days = 10 ): \"\"\" Parameters ---------- tickers : list List of ticker symbols to consider for investment lookback_days : int, default 10 Number of days to use for momentum calculation \"\"\" # Pass tickers to parent class (StrategyBase) for initialization super () . __init__ ( tickers ) # Set the lookback window size for momentum calculation self . lookback_days = lookback_days # Initialize price history storage for each ticker # Because portwine is ONLY walkforward, we must store data after every timestep # to build up a history to run our analysis on self . price_history = { ticker : [] for ticker in tickers } def is_friday ( self , date ): \"\"\"Check if given date is a Friday (weekday 4)\"\"\" return date . weekday () == 4 def calculate_momentum ( self , ticker ): \"\"\"Calculate simple price momentum over lookback period\"\"\" # Get the price history for this specific ticker prices = self . price_history [ ticker ] # Need at least lookback_days+1 data points to calculate momentum # (we need start_price and end_price with lookback_days between them) if len ( prices ) <= self . lookback_days : return - 999.0 # Sentinel value indicating insufficient data # Get starting price (lookback_days ago) and ending price (today) start_price = prices [ - self . lookback_days - 1 ] # Price from lookback_days+1 ago end_price = prices [ - 1 ] # Most recent price (today) # Check for valid prices (not None and positive) if start_price is None or end_price is None or start_price <= 0 : return - 999.0 # Sentinel value for invalid data # Calculate momentum: (end_price / start_price) - 1 # This gives us the percentage change over the lookback period return end_price / start_price - 1.0 def step ( self , current_date , daily_data ): \"\"\" Process daily data and determine allocations Called by portwine for each trading day \"\"\" # Update price history for each ticker with today's data for ticker in self . tickers : price = None # Extract close price from daily data if available if daily_data . get ( ticker ) is not None : price = daily_data [ ticker ] . get ( 'close' , None ) # Forward fill missing data: if no price today, use yesterday's price if price is None and len ( self . price_history [ ticker ]) > 0 : price = self . price_history [ ticker ][ - 1 ] # Last known price # Add today's price (or forward-filled price) to history self . price_history [ ticker ] . append ( price ) # Only rebalance on Fridays to reduce trading costs if self . is_friday ( current_date ): # Calculate momentum score for each ticker momentum_scores = {} for ticker in self . tickers : momentum_scores [ ticker ] = self . calculate_momentum ( ticker ) # Find the ticker with the highest momentum score # Handle sentinel values (-999.0) by treating them as negative infinity best_ticker = max ( momentum_scores . items (), key = lambda x : x [ 1 ] if x [ 1 ] != - 999.0 else - float ( 'inf' ))[ 0 ] # Create new allocation signals signals = { ticker : 0.0 for ticker in self . tickers } # Allocate 100% to best performer if we have valid momentum data if momentum_scores [ best_ticker ] != - 999.0 : signals [ best_ticker ] = 1.0 return signals else : # On non-Friday days, return zero allocation (cash) # This maintains the previous Friday's allocation until next rebalance return { ticker : 0.0 for ticker in self . tickers } # Define your investment universe universe = [ 'MTUM' , 'VTV' , 'VUG' , 'IJR' , 'MDY' ] # Create a momentum strategy strategy = SimpleMomentumStrategy ( tickers = universe , lookback_days = 10 ) # Set up your data loader data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/eodhd/data/' ) # Create the backtester backtester = Backtester ( market_data_loader = data_loader ) # Run the backtest results = backtester . run_backtest ( strategy = strategy , benchmark_ticker = 'SPY' , start_date = '2020-01-01' , end_date = '2023-12-31' , verbose = True ) For a more detailed tutorial on writing strategies, click here .","title":"Your First Strategy"},{"location":"getting-started/quick-start/#understanding-the-results","text":"The backtest returns a dictionary with several key components: # Strategy signals over time signals_df = results [ 'signals_df' ] # Individual asset returns ticker_returns = results [ 'tickers_returns' ] # Strategy performance strategy_returns = results [ 'strategy_returns' ] # Benchmark performance benchmark_returns = results [ 'benchmark_returns' ] These components contain all the information you need to analyze your strategy in any capacity.","title":"Understanding the Results"},{"location":"getting-started/quick-start/#analyzing-performance","text":"Portwine comes with built-in analyzers to help you understand your strategy's performance: from portwine.analyzers import EquityDrawdownAnalyzer , MonteCarloAnalyzer # Equity and drawdown analysis EquityDrawdownAnalyzer () . plot ( results ) # Monte Carlo simulation MonteCarloAnalyzer () . plot ( results ) For more information on the available analyzers and how to write your own analyzer, click here .","title":"Analyzing Performance"},{"location":"getting-started/quick-start/#whats-happening-under-the-hood","text":"Data Loading : The data loader fetches historical price data for your universe Strategy Execution : Each day, your strategy receives the latest prices and decides allocations Signal Processing : Portwine handles the mechanics of applying your signals to the market Performance Calculation : Returns are calculated and compared against your benchmark","title":"What's Happening Under the Hood"},{"location":"getting-started/quick-start/#next-steps","text":"Learn more about building strategies Explore different analyzers Check out advanced examples","title":"Next Steps"},{"location":"user-guide/analysis/","text":"Performance Analysis Portwine provides comprehensive tools for analyzing strategy performance, from basic metrics to advanced visualizations. Built-in Analyzers Portwine comes with a comprehensive suite of analyzers that make it easy to understand your strategy's performance across different dimensions: Equity Drawdown Analyzer The foundational analyzer that provides essential performance visualization and metrics. This analyzer creates clear, professional plots showing equity curves and drawdown analysis. What it generates: - Equity curve comparison (strategy vs benchmark) with clear visual distinction - Drawdown analysis showing peak-to-trough declines - Performance metrics table with key statistics - Professional formatting with proper legends and grid lines Best for: Initial strategy evaluation, performance overview, and stakeholder presentations. from portwine.analyzers import EquityDrawdownAnalyzer # Create analyzer analyzer = EquityDrawdownAnalyzer () # Plot results analyzer . plot ( results ) Grid Equity Drawdown Analyzer A powerful multi-strategy comparison tool that displays multiple strategy results in a grid layout. Each grid cell contains both equity curves and drawdown analysis for easy side-by-side comparison. What it generates: - Grid layout with customizable columns (default: 2 columns) - Each cell shows equity curves and drawdowns for one strategy - Color-coded fill areas showing outperformance/underperformance - Compact design perfect for comparing multiple strategies or parameter sets Best for: Comparing multiple strategies, parameter optimization results, or basket analysis. from portwine.analyzers import GridEquityDrawdownAnalyzer # Create analyzer analyzer = GridEquityDrawdownAnalyzer () # Plot multiple strategies analyzer . plot ( results_list , titles , ncols = 2 ) Monte Carlo Analyzer Performs Monte Carlo simulations to assess strategy robustness and understand the distribution of possible outcomes. This analyzer helps determine if your strategy's performance is stable or subject to significant randomness. What it generates: - Distribution of possible outcomes through random sampling - Confidence intervals for key metrics - Risk assessment through multiple simulation paths - Statistical validation of strategy performance Best for: Risk assessment, strategy validation, and understanding performance uncertainty. from portwine.analyzers import MonteCarloAnalyzer # Run Monte Carlo analysis analyzer = MonteCarloAnalyzer () analyzer . plot ( results , n_simulations = 1000 ) Seasonality Analyzer Analyzes performance patterns across different time periods to identify seasonal effects, day-of-week patterns, and other temporal dependencies in your strategy. What it generates: - Monthly performance heatmaps and bar charts - Day-of-week analysis showing intra-week patterns - Quarterly and annual seasonal trends - Statistical significance testing for seasonal effects Best for: Understanding temporal patterns, optimizing rebalancing schedules, and identifying seasonal opportunities. from portwine.analyzers import SeasonalityAnalyzer # Analyze seasonal patterns analyzer = SeasonalityAnalyzer () analyzer . plot ( results , period = \"monthly\" ) Correlation Analyzer Computes and visualizes correlation matrices among the assets in your strategy. This analyzer helps understand the relationships between different positions and identify potential diversification benefits or concentration risks. What it generates: - Correlation matrix heatmap with color-coded values - Statistical correlation analysis using multiple methods (Pearson, Spearman, Kendall) - Asset relationship visualization - Diversification assessment Best for: Portfolio construction, risk management, and understanding asset relationships. from portwine.analyzers import CorrelationAnalyzer # Analyze correlations analyzer = CorrelationAnalyzer ( method = 'pearson' ) analyzer . plot ( results ) Strategy Comparison Analyzer A comprehensive tool for comparing two strategies side-by-side with statistical rigor. This analyzer provides detailed statistical tests and rolling analysis to understand the differences between strategies. What it generates: - Side-by-side equity curve comparison with fill areas - Statistical significance tests (t-tests) between strategies - Rolling correlation, alpha, and beta analysis - Performance metrics comparison table Best for: Strategy selection, A/B testing, and understanding strategy differences. from portwine.analyzers import StrategyComparisonAnalyzer # Compare strategies analyzer = StrategyComparisonAnalyzer () analyzer . plot ( results , comparison_results , label_main = \"Strategy A\" , label_compare = \"Strategy B\" ) Train Test Equity Drawdown Analyzer Evaluates strategy robustness by splitting data into training and testing periods. This analyzer helps identify overfitting and ensures your strategy generalizes well to unseen data. What it generates: - Equity curves with clear train/test split visualization - Drawdown analysis for both periods - Histogram comparison of train vs test returns - Comprehensive metrics table with overfitting ratios - Color-coded performance indicators Best for: Model validation, overfitting detection, and ensuring strategy robustness. from portwine.analyzers import TrainTestEquityDrawdownAnalyzer # Analyze train/test performance analyzer = TrainTestEquityDrawdownAnalyzer () analyzer . plot ( results , split = 0.7 ) Student's T-Test Analyzer Provides statistical rigor to your strategy evaluation through formal hypothesis testing. This analyzer determines whether your strategy's performance is statistically significant compared to zero or a benchmark. What it generates: - Statistical significance testing vs zero returns - Comparison testing vs benchmark returns - Return distribution histograms - Color-coded significance indicators - Plain English interpretation of results Best for: Statistical validation, academic research, and formal strategy evaluation. from portwine.analyzers import StudentsTTestAnalyzer # Perform statistical testing analyzer = StudentsTTestAnalyzer () analyzer . plot ( results , with_equity_curve = True ) Transaction Cost Analyzer Models the real-world impact of transaction costs on strategy performance. This analyzer helps understand how different cost levels affect your strategy and identifies the breakeven point for profitability. What it generates: - Performance degradation analysis across cost levels - Portfolio turnover analysis with rolling metrics - Breakeven analysis showing cost tolerance - Equity curves for different cost scenarios - Comprehensive cost impact report Best for: Real-world implementation planning, cost optimization, and profitability analysis. from portwine.analyzers import TransactionCostAnalyzer # Analyze transaction cost impact analyzer = TransactionCostAnalyzer ( cost_levels = [ 0 , 0.0005 , 0.001 , 0.002 , 0.005 ]) analyzer . plot ( results ) Noise Robustness Analyzer Tests strategy stability by injecting controlled levels of noise into market data. This analyzer helps determine if your strategy is robust to market noise or if it's overfitted to specific data patterns. What it generates: - Performance stability across noise levels - Statistical distribution of outcomes - Robustness metrics and confidence intervals - Noise tolerance assessment Best for: Strategy validation, robustness testing, and overfitting detection. from portwine.analyzers import NoiseRobustnessAnalyzer # Test noise robustness analyzer = NoiseRobustnessAnalyzer ( base_loader , noise_levels = [ 0.5 , 1.0 , 1.5 , 2.0 ]) analyzer . plot ( results ) Regime Change Analyzer Analyzes strategy performance across different market regimes (bull, bear, volatile, etc.). This analyzer helps identify how your strategy behaves in different market conditions and potential vulnerabilities. What it generates: - Market regime identification and classification - Performance metrics for each regime - Regime transition analysis - Strategy behavior across market conditions - Comprehensive regime performance report Best for: Risk management, strategy optimization, and understanding market condition dependencies. from portwine.analyzers import RegimeChangeAnalyzer # Analyze regime performance analyzer = RegimeChangeAnalyzer () analyzer . plot ( results , method = 'combined' ) Writing Your Own Analyzers You can also write your own analyzers by following the simple analyzer API. Here's a step-by-step example of creating a custom \"Volatility Regime Analyzer\" that identifies and analyzes performance in different volatility environments. Step 1: Import Required Libraries import pandas as pd import numpy as np import matplotlib.pyplot as plt from portwine.analyzers.base import Analyzer Explanation: - pandas and numpy for data manipulation and calculations - matplotlib.pyplot for creating visualizations - Analyzer base class from portwine that all analyzers must inherit from Step 2: Define Your Analyzer Class class VolatilityRegimeAnalyzer ( Analyzer ): \"\"\" Custom analyzer that identifies different volatility regimes and analyzes strategy performance in each regime. This analyzer helps understand how your strategy performs in: - Low volatility periods (calm markets) - Medium volatility periods (normal markets) - High volatility periods (stressful markets) \"\"\" Explanation: - Inherit from the Analyzer base class - Add a comprehensive docstring explaining what your analyzer does - This makes your analyzer compatible with the portwine framework Step 3: Initialize Your Analyzer def __init__ ( self , volatility_window = 60 , regime_thresholds = None ): \"\"\" Initialize the analyzer with customizable parameters. Parameters ---------- volatility_window : int, default 60 Rolling window for volatility calculation (in days) regime_thresholds : dict, optional Custom thresholds for regime classification \"\"\" self . volatility_window = volatility_window # Default thresholds (30th and 70th percentiles) self . regime_thresholds = regime_thresholds or { 'low' : 0.30 , # Below 30th percentile = low volatility 'high' : 0.70 # Above 70th percentile = high volatility } Explanation: - __init__ method sets up your analyzer with configurable parameters - volatility_window determines how many days to use for rolling volatility - regime_thresholds allows users to customize how regimes are defined - Default thresholds use 30 th and 70 th percentiles for robust regime classification Step 4: Implement the Analysis Logic def identify_volatility_regimes ( self , returns ): \"\"\" Identify volatility regimes based on rolling volatility. Parameters ---------- returns : pd.Series Daily returns series Returns ------- pd.Series Regime labels for each date \"\"\" # Calculate rolling volatility (annualized) rolling_vol = returns . rolling ( window = self . volatility_window ) . std () * np . sqrt ( 252 ) # Calculate percentile thresholds low_threshold = rolling_vol . quantile ( self . regime_thresholds [ 'low' ]) high_threshold = rolling_vol . quantile ( self . regime_thresholds [ 'high' ]) # Classify regimes regimes = pd . Series ( index = returns . index , dtype = 'object' ) regimes [ rolling_vol <= low_threshold ] = 'low_vol' regimes [ rolling_vol >= high_threshold ] = 'high_vol' regimes [( rolling_vol > low_threshold ) & ( rolling_vol < high_threshold )] = 'medium_vol' return regimes , rolling_vol Explanation: - identify_volatility_regimes is a helper method that does the core analysis - Calculates rolling volatility using the specified window - Annualizes volatility by multiplying by \u221a252 (trading days) - Uses quantiles to determine regime thresholds dynamically - Returns both regime labels and the volatility series for plotting Step 5: Calculate Performance Metrics def calculate_regime_metrics ( self , returns , regimes , ann_factor = 252 ): \"\"\" Calculate performance metrics for each volatility regime. Parameters ---------- returns : pd.Series Strategy returns regimes : pd.Series Regime labels for each date ann_factor : int, default 252 Annualization factor Returns ------- dict Performance metrics for each regime \"\"\" metrics = {} for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: # Filter returns for this regime regime_returns = returns [ regimes == regime ] if len ( regime_returns ) == 0 : metrics [ regime ] = None continue # Calculate basic metrics total_return = ( 1 + regime_returns ) . prod () - 1 annual_return = regime_returns . mean () * ann_factor volatility = regime_returns . std () * np . sqrt ( ann_factor ) sharpe_ratio = annual_return / volatility if volatility > 0 else 0 # Calculate maximum drawdown cumulative = ( 1 + regime_returns ) . cumprod () running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min () # Calculate win rate win_rate = ( regime_returns > 0 ) . mean () metrics [ regime ] = { 'total_return' : total_return , 'annual_return' : annual_return , 'volatility' : volatility , 'sharpe_ratio' : sharpe_ratio , 'max_drawdown' : max_drawdown , 'win_rate' : win_rate , 'days' : len ( regime_returns ) } return metrics Explanation: - calculate_regime_metrics computes performance statistics for each regime - Filters returns by regime and calculates comprehensive metrics - Handles edge cases (empty regimes) gracefully - Returns a structured dictionary with all metrics organized by regime Step 6: Implement the Required Plot Method def plot ( self , results , figsize = ( 15 , 10 ), benchmark_label = \"Benchmark\" ): \"\"\" Create comprehensive visualization of volatility regime analysis. Parameters ---------- results : dict Results dictionary from backtester figsize : tuple, default (15, 10) Figure size (width, height) benchmark_label : str, default \"Benchmark\" Label for benchmark in plots \"\"\" # Extract data from results strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results . get ( 'benchmark_returns' , pd . Series ( dtype = float )) # Identify regimes regimes , rolling_vol = self . identify_volatility_regimes ( benchmark_returns ) # Calculate metrics strategy_metrics = self . calculate_regime_metrics ( strategy_returns , regimes ) benchmark_metrics = self . calculate_regime_metrics ( benchmark_returns , regimes ) # Create the visualization fig , axes = plt . subplots ( 2 , 2 , figsize = figsize ) fig . suptitle ( 'Volatility Regime Analysis' , fontsize = 16 , fontweight = 'bold' ) # Plot 1: Rolling Volatility with Regime Overlay ax1 = axes [ 0 , 0 ] ax1 . plot ( rolling_vol . index , rolling_vol . values , color = 'blue' , linewidth = 1 , label = 'Rolling Volatility' ) # Color-code by regime for regime , color in [( 'low_vol' , 'green' ), ( 'medium_vol' , 'yellow' ), ( 'high_vol' , 'red' )]: regime_mask = regimes == regime if regime_mask . any (): ax1 . scatter ( rolling_vol [ regime_mask ] . index , rolling_vol [ regime_mask ] . values , c = color , alpha = 0.6 , s = 20 , label = f ' { regime . replace ( \"_\" , \" \" ) . title () } ' ) ax1 . set_title ( 'Rolling Volatility with Regime Classification' ) ax1 . set_ylabel ( 'Annualized Volatility' ) ax1 . legend () ax1 . grid ( True , alpha = 0.3 ) # Plot 2: Cumulative Returns by Regime ax2 = axes [ 0 , 1 ] cumulative_strategy = ( 1 + strategy_returns ) . cumprod () for regime , color in [( 'low_vol' , 'green' ), ( 'medium_vol' , 'yellow' ), ( 'high_vol' , 'red' )]: regime_mask = regimes == regime if regime_mask . any (): regime_returns = strategy_returns [ regime_mask ] regime_cumulative = ( 1 + regime_returns ) . cumprod () ax2 . plot ( regime_cumulative . index , regime_cumulative . values , color = color , linewidth = 2 , label = f ' { regime . replace ( \"_\" , \" \" ) . title () } ' ) ax2 . set_title ( 'Strategy Performance by Volatility Regime' ) ax2 . set_ylabel ( 'Cumulative Return' ) ax2 . legend () ax2 . grid ( True , alpha = 0.3 ) # Plot 3: Performance Metrics Comparison ax3 = axes [ 1 , 0 ] ax3 . axis ( 'off' ) # Create metrics table metrics_data = [] for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: if strategy_metrics [ regime ]: metrics_data . append ([ regime . replace ( '_' , ' ' ) . title (), f \" { strategy_metrics [ regime ][ 'annual_return' ] : .2% } \" , f \" { strategy_metrics [ regime ][ 'sharpe_ratio' ] : .2f } \" , f \" { strategy_metrics [ regime ][ 'max_drawdown' ] : .2% } \" , f \" { strategy_metrics [ regime ][ 'days' ] } \" ]) table = ax3 . table ( cellText = metrics_data , colLabels = [ 'Regime' , 'Ann. Return' , 'Sharpe' , 'Max DD' , 'Days' ], loc = 'center' , cellLoc = 'center' ) table . auto_set_font_size ( False ) table . set_fontsize ( 10 ) table . scale ( 1.2 , 1.5 ) ax3 . set_title ( 'Strategy Performance by Regime' ) # Plot 4: Regime Distribution ax4 = axes [ 1 , 1 ] regime_counts = regimes . value_counts () colors = [ 'green' , 'yellow' , 'red' ] ax4 . pie ( regime_counts . values , labels = regime_counts . index , autopct = ' %1.1f%% ' , colors = colors ) ax4 . set_title ( 'Distribution of Volatility Regimes' ) plt . tight_layout () plt . show () # Print summary statistics self . _print_summary ( strategy_metrics , benchmark_metrics ) Explanation: - The plot method is the main interface that users will call - Extracts data from the results dictionary - Calls helper methods to perform analysis - Creates a comprehensive 2x2 subplot layout - Each subplot shows different aspects of the analysis - Includes proper labeling, legends, and formatting - Calls a helper method to print summary statistics Step 7: Add Helper Methods def _print_summary ( self , strategy_metrics , benchmark_metrics ): \"\"\" Print a summary of the analysis results. Parameters ---------- strategy_metrics : dict Strategy performance metrics by regime benchmark_metrics : dict Benchmark performance metrics by regime \"\"\" print ( \" \\n \" + \"=\" * 60 ) print ( \"VOLATILITY REGIME ANALYSIS SUMMARY\" ) print ( \"=\" * 60 ) for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: if strategy_metrics [ regime ]: print ( f \" \\n { regime . replace ( '_' , ' ' ) . title () } Regime:\" ) print ( f \" Days: { strategy_metrics [ regime ][ 'days' ] } \" ) print ( f \" Annual Return: { strategy_metrics [ regime ][ 'annual_return' ] : .2% } \" ) print ( f \" Sharpe Ratio: { strategy_metrics [ regime ][ 'sharpe_ratio' ] : .2f } \" ) print ( f \" Max Drawdown: { strategy_metrics [ regime ][ 'max_drawdown' ] : .2% } \" ) print ( f \" Win Rate: { strategy_metrics [ regime ][ 'win_rate' ] : .2% } \" ) print ( \" \\n \" + \"=\" * 60 ) Explanation: - Helper method to print formatted summary statistics - Provides clear, readable output of key findings - Uses consistent formatting for professional presentation Step 8: Usage Example # Create and use your custom analyzer from portwine.analyzers import VolatilityRegimeAnalyzer # Initialize with custom parameters analyzer = VolatilityRegimeAnalyzer ( volatility_window = 90 , # 90-day rolling window regime_thresholds = { 'low' : 0.25 , # Bottom 25% = low volatility 'high' : 0.75 # Top 25% = high volatility } ) # Run the analysis analyzer . plot ( results , figsize = ( 16 , 12 )) Explanation: - Shows how to instantiate your custom analyzer - Demonstrates parameter customization - Shows the simple interface for running the analysis Key Design Principles Inherit from Analyzer : Always inherit from the base Analyzer class Clear Documentation : Provide comprehensive docstrings for all methods Flexible Parameters : Allow users to customize key parameters Error Handling : Handle edge cases gracefully (empty data, missing regimes) Professional Visualization : Create clear, informative plots with proper formatting Modular Design : Break complex logic into smaller, focused methods Consistent Interface : Follow the same pattern as built-in analyzers This example demonstrates how to create a sophisticated custom analyzer that provides valuable insights while maintaining the same professional interface as the built-in analyzers. Next Steps Learn about building strategies Explore backtesting Check out data management","title":"Analysis"},{"location":"user-guide/analysis/#performance-analysis","text":"Portwine provides comprehensive tools for analyzing strategy performance, from basic metrics to advanced visualizations.","title":"Performance Analysis"},{"location":"user-guide/analysis/#built-in-analyzers","text":"Portwine comes with a comprehensive suite of analyzers that make it easy to understand your strategy's performance across different dimensions:","title":"Built-in Analyzers"},{"location":"user-guide/analysis/#equity-drawdown-analyzer","text":"The foundational analyzer that provides essential performance visualization and metrics. This analyzer creates clear, professional plots showing equity curves and drawdown analysis. What it generates: - Equity curve comparison (strategy vs benchmark) with clear visual distinction - Drawdown analysis showing peak-to-trough declines - Performance metrics table with key statistics - Professional formatting with proper legends and grid lines Best for: Initial strategy evaluation, performance overview, and stakeholder presentations. from portwine.analyzers import EquityDrawdownAnalyzer # Create analyzer analyzer = EquityDrawdownAnalyzer () # Plot results analyzer . plot ( results )","title":"Equity Drawdown Analyzer"},{"location":"user-guide/analysis/#grid-equity-drawdown-analyzer","text":"A powerful multi-strategy comparison tool that displays multiple strategy results in a grid layout. Each grid cell contains both equity curves and drawdown analysis for easy side-by-side comparison. What it generates: - Grid layout with customizable columns (default: 2 columns) - Each cell shows equity curves and drawdowns for one strategy - Color-coded fill areas showing outperformance/underperformance - Compact design perfect for comparing multiple strategies or parameter sets Best for: Comparing multiple strategies, parameter optimization results, or basket analysis. from portwine.analyzers import GridEquityDrawdownAnalyzer # Create analyzer analyzer = GridEquityDrawdownAnalyzer () # Plot multiple strategies analyzer . plot ( results_list , titles , ncols = 2 )","title":"Grid Equity Drawdown Analyzer"},{"location":"user-guide/analysis/#monte-carlo-analyzer","text":"Performs Monte Carlo simulations to assess strategy robustness and understand the distribution of possible outcomes. This analyzer helps determine if your strategy's performance is stable or subject to significant randomness. What it generates: - Distribution of possible outcomes through random sampling - Confidence intervals for key metrics - Risk assessment through multiple simulation paths - Statistical validation of strategy performance Best for: Risk assessment, strategy validation, and understanding performance uncertainty. from portwine.analyzers import MonteCarloAnalyzer # Run Monte Carlo analysis analyzer = MonteCarloAnalyzer () analyzer . plot ( results , n_simulations = 1000 )","title":"Monte Carlo Analyzer"},{"location":"user-guide/analysis/#seasonality-analyzer","text":"Analyzes performance patterns across different time periods to identify seasonal effects, day-of-week patterns, and other temporal dependencies in your strategy. What it generates: - Monthly performance heatmaps and bar charts - Day-of-week analysis showing intra-week patterns - Quarterly and annual seasonal trends - Statistical significance testing for seasonal effects Best for: Understanding temporal patterns, optimizing rebalancing schedules, and identifying seasonal opportunities. from portwine.analyzers import SeasonalityAnalyzer # Analyze seasonal patterns analyzer = SeasonalityAnalyzer () analyzer . plot ( results , period = \"monthly\" )","title":"Seasonality Analyzer"},{"location":"user-guide/analysis/#correlation-analyzer","text":"Computes and visualizes correlation matrices among the assets in your strategy. This analyzer helps understand the relationships between different positions and identify potential diversification benefits or concentration risks. What it generates: - Correlation matrix heatmap with color-coded values - Statistical correlation analysis using multiple methods (Pearson, Spearman, Kendall) - Asset relationship visualization - Diversification assessment Best for: Portfolio construction, risk management, and understanding asset relationships. from portwine.analyzers import CorrelationAnalyzer # Analyze correlations analyzer = CorrelationAnalyzer ( method = 'pearson' ) analyzer . plot ( results )","title":"Correlation Analyzer"},{"location":"user-guide/analysis/#strategy-comparison-analyzer","text":"A comprehensive tool for comparing two strategies side-by-side with statistical rigor. This analyzer provides detailed statistical tests and rolling analysis to understand the differences between strategies. What it generates: - Side-by-side equity curve comparison with fill areas - Statistical significance tests (t-tests) between strategies - Rolling correlation, alpha, and beta analysis - Performance metrics comparison table Best for: Strategy selection, A/B testing, and understanding strategy differences. from portwine.analyzers import StrategyComparisonAnalyzer # Compare strategies analyzer = StrategyComparisonAnalyzer () analyzer . plot ( results , comparison_results , label_main = \"Strategy A\" , label_compare = \"Strategy B\" )","title":"Strategy Comparison Analyzer"},{"location":"user-guide/analysis/#train-test-equity-drawdown-analyzer","text":"Evaluates strategy robustness by splitting data into training and testing periods. This analyzer helps identify overfitting and ensures your strategy generalizes well to unseen data. What it generates: - Equity curves with clear train/test split visualization - Drawdown analysis for both periods - Histogram comparison of train vs test returns - Comprehensive metrics table with overfitting ratios - Color-coded performance indicators Best for: Model validation, overfitting detection, and ensuring strategy robustness. from portwine.analyzers import TrainTestEquityDrawdownAnalyzer # Analyze train/test performance analyzer = TrainTestEquityDrawdownAnalyzer () analyzer . plot ( results , split = 0.7 )","title":"Train Test Equity Drawdown Analyzer"},{"location":"user-guide/analysis/#students-t-test-analyzer","text":"Provides statistical rigor to your strategy evaluation through formal hypothesis testing. This analyzer determines whether your strategy's performance is statistically significant compared to zero or a benchmark. What it generates: - Statistical significance testing vs zero returns - Comparison testing vs benchmark returns - Return distribution histograms - Color-coded significance indicators - Plain English interpretation of results Best for: Statistical validation, academic research, and formal strategy evaluation. from portwine.analyzers import StudentsTTestAnalyzer # Perform statistical testing analyzer = StudentsTTestAnalyzer () analyzer . plot ( results , with_equity_curve = True )","title":"Student's T-Test Analyzer"},{"location":"user-guide/analysis/#transaction-cost-analyzer","text":"Models the real-world impact of transaction costs on strategy performance. This analyzer helps understand how different cost levels affect your strategy and identifies the breakeven point for profitability. What it generates: - Performance degradation analysis across cost levels - Portfolio turnover analysis with rolling metrics - Breakeven analysis showing cost tolerance - Equity curves for different cost scenarios - Comprehensive cost impact report Best for: Real-world implementation planning, cost optimization, and profitability analysis. from portwine.analyzers import TransactionCostAnalyzer # Analyze transaction cost impact analyzer = TransactionCostAnalyzer ( cost_levels = [ 0 , 0.0005 , 0.001 , 0.002 , 0.005 ]) analyzer . plot ( results )","title":"Transaction Cost Analyzer"},{"location":"user-guide/analysis/#noise-robustness-analyzer","text":"Tests strategy stability by injecting controlled levels of noise into market data. This analyzer helps determine if your strategy is robust to market noise or if it's overfitted to specific data patterns. What it generates: - Performance stability across noise levels - Statistical distribution of outcomes - Robustness metrics and confidence intervals - Noise tolerance assessment Best for: Strategy validation, robustness testing, and overfitting detection. from portwine.analyzers import NoiseRobustnessAnalyzer # Test noise robustness analyzer = NoiseRobustnessAnalyzer ( base_loader , noise_levels = [ 0.5 , 1.0 , 1.5 , 2.0 ]) analyzer . plot ( results )","title":"Noise Robustness Analyzer"},{"location":"user-guide/analysis/#regime-change-analyzer","text":"Analyzes strategy performance across different market regimes (bull, bear, volatile, etc.). This analyzer helps identify how your strategy behaves in different market conditions and potential vulnerabilities. What it generates: - Market regime identification and classification - Performance metrics for each regime - Regime transition analysis - Strategy behavior across market conditions - Comprehensive regime performance report Best for: Risk management, strategy optimization, and understanding market condition dependencies. from portwine.analyzers import RegimeChangeAnalyzer # Analyze regime performance analyzer = RegimeChangeAnalyzer () analyzer . plot ( results , method = 'combined' )","title":"Regime Change Analyzer"},{"location":"user-guide/analysis/#writing-your-own-analyzers","text":"You can also write your own analyzers by following the simple analyzer API. Here's a step-by-step example of creating a custom \"Volatility Regime Analyzer\" that identifies and analyzes performance in different volatility environments.","title":"Writing Your Own Analyzers"},{"location":"user-guide/analysis/#step-1-import-required-libraries","text":"import pandas as pd import numpy as np import matplotlib.pyplot as plt from portwine.analyzers.base import Analyzer Explanation: - pandas and numpy for data manipulation and calculations - matplotlib.pyplot for creating visualizations - Analyzer base class from portwine that all analyzers must inherit from","title":"Step 1: Import Required Libraries"},{"location":"user-guide/analysis/#step-2-define-your-analyzer-class","text":"class VolatilityRegimeAnalyzer ( Analyzer ): \"\"\" Custom analyzer that identifies different volatility regimes and analyzes strategy performance in each regime. This analyzer helps understand how your strategy performs in: - Low volatility periods (calm markets) - Medium volatility periods (normal markets) - High volatility periods (stressful markets) \"\"\" Explanation: - Inherit from the Analyzer base class - Add a comprehensive docstring explaining what your analyzer does - This makes your analyzer compatible with the portwine framework","title":"Step 2: Define Your Analyzer Class"},{"location":"user-guide/analysis/#step-3-initialize-your-analyzer","text":"def __init__ ( self , volatility_window = 60 , regime_thresholds = None ): \"\"\" Initialize the analyzer with customizable parameters. Parameters ---------- volatility_window : int, default 60 Rolling window for volatility calculation (in days) regime_thresholds : dict, optional Custom thresholds for regime classification \"\"\" self . volatility_window = volatility_window # Default thresholds (30th and 70th percentiles) self . regime_thresholds = regime_thresholds or { 'low' : 0.30 , # Below 30th percentile = low volatility 'high' : 0.70 # Above 70th percentile = high volatility } Explanation: - __init__ method sets up your analyzer with configurable parameters - volatility_window determines how many days to use for rolling volatility - regime_thresholds allows users to customize how regimes are defined - Default thresholds use 30 th and 70 th percentiles for robust regime classification","title":"Step 3: Initialize Your Analyzer"},{"location":"user-guide/analysis/#step-4-implement-the-analysis-logic","text":"def identify_volatility_regimes ( self , returns ): \"\"\" Identify volatility regimes based on rolling volatility. Parameters ---------- returns : pd.Series Daily returns series Returns ------- pd.Series Regime labels for each date \"\"\" # Calculate rolling volatility (annualized) rolling_vol = returns . rolling ( window = self . volatility_window ) . std () * np . sqrt ( 252 ) # Calculate percentile thresholds low_threshold = rolling_vol . quantile ( self . regime_thresholds [ 'low' ]) high_threshold = rolling_vol . quantile ( self . regime_thresholds [ 'high' ]) # Classify regimes regimes = pd . Series ( index = returns . index , dtype = 'object' ) regimes [ rolling_vol <= low_threshold ] = 'low_vol' regimes [ rolling_vol >= high_threshold ] = 'high_vol' regimes [( rolling_vol > low_threshold ) & ( rolling_vol < high_threshold )] = 'medium_vol' return regimes , rolling_vol Explanation: - identify_volatility_regimes is a helper method that does the core analysis - Calculates rolling volatility using the specified window - Annualizes volatility by multiplying by \u221a252 (trading days) - Uses quantiles to determine regime thresholds dynamically - Returns both regime labels and the volatility series for plotting","title":"Step 4: Implement the Analysis Logic"},{"location":"user-guide/analysis/#step-5-calculate-performance-metrics","text":"def calculate_regime_metrics ( self , returns , regimes , ann_factor = 252 ): \"\"\" Calculate performance metrics for each volatility regime. Parameters ---------- returns : pd.Series Strategy returns regimes : pd.Series Regime labels for each date ann_factor : int, default 252 Annualization factor Returns ------- dict Performance metrics for each regime \"\"\" metrics = {} for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: # Filter returns for this regime regime_returns = returns [ regimes == regime ] if len ( regime_returns ) == 0 : metrics [ regime ] = None continue # Calculate basic metrics total_return = ( 1 + regime_returns ) . prod () - 1 annual_return = regime_returns . mean () * ann_factor volatility = regime_returns . std () * np . sqrt ( ann_factor ) sharpe_ratio = annual_return / volatility if volatility > 0 else 0 # Calculate maximum drawdown cumulative = ( 1 + regime_returns ) . cumprod () running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min () # Calculate win rate win_rate = ( regime_returns > 0 ) . mean () metrics [ regime ] = { 'total_return' : total_return , 'annual_return' : annual_return , 'volatility' : volatility , 'sharpe_ratio' : sharpe_ratio , 'max_drawdown' : max_drawdown , 'win_rate' : win_rate , 'days' : len ( regime_returns ) } return metrics Explanation: - calculate_regime_metrics computes performance statistics for each regime - Filters returns by regime and calculates comprehensive metrics - Handles edge cases (empty regimes) gracefully - Returns a structured dictionary with all metrics organized by regime","title":"Step 5: Calculate Performance Metrics"},{"location":"user-guide/analysis/#step-6-implement-the-required-plot-method","text":"def plot ( self , results , figsize = ( 15 , 10 ), benchmark_label = \"Benchmark\" ): \"\"\" Create comprehensive visualization of volatility regime analysis. Parameters ---------- results : dict Results dictionary from backtester figsize : tuple, default (15, 10) Figure size (width, height) benchmark_label : str, default \"Benchmark\" Label for benchmark in plots \"\"\" # Extract data from results strategy_returns = results [ 'strategy_returns' ] benchmark_returns = results . get ( 'benchmark_returns' , pd . Series ( dtype = float )) # Identify regimes regimes , rolling_vol = self . identify_volatility_regimes ( benchmark_returns ) # Calculate metrics strategy_metrics = self . calculate_regime_metrics ( strategy_returns , regimes ) benchmark_metrics = self . calculate_regime_metrics ( benchmark_returns , regimes ) # Create the visualization fig , axes = plt . subplots ( 2 , 2 , figsize = figsize ) fig . suptitle ( 'Volatility Regime Analysis' , fontsize = 16 , fontweight = 'bold' ) # Plot 1: Rolling Volatility with Regime Overlay ax1 = axes [ 0 , 0 ] ax1 . plot ( rolling_vol . index , rolling_vol . values , color = 'blue' , linewidth = 1 , label = 'Rolling Volatility' ) # Color-code by regime for regime , color in [( 'low_vol' , 'green' ), ( 'medium_vol' , 'yellow' ), ( 'high_vol' , 'red' )]: regime_mask = regimes == regime if regime_mask . any (): ax1 . scatter ( rolling_vol [ regime_mask ] . index , rolling_vol [ regime_mask ] . values , c = color , alpha = 0.6 , s = 20 , label = f ' { regime . replace ( \"_\" , \" \" ) . title () } ' ) ax1 . set_title ( 'Rolling Volatility with Regime Classification' ) ax1 . set_ylabel ( 'Annualized Volatility' ) ax1 . legend () ax1 . grid ( True , alpha = 0.3 ) # Plot 2: Cumulative Returns by Regime ax2 = axes [ 0 , 1 ] cumulative_strategy = ( 1 + strategy_returns ) . cumprod () for regime , color in [( 'low_vol' , 'green' ), ( 'medium_vol' , 'yellow' ), ( 'high_vol' , 'red' )]: regime_mask = regimes == regime if regime_mask . any (): regime_returns = strategy_returns [ regime_mask ] regime_cumulative = ( 1 + regime_returns ) . cumprod () ax2 . plot ( regime_cumulative . index , regime_cumulative . values , color = color , linewidth = 2 , label = f ' { regime . replace ( \"_\" , \" \" ) . title () } ' ) ax2 . set_title ( 'Strategy Performance by Volatility Regime' ) ax2 . set_ylabel ( 'Cumulative Return' ) ax2 . legend () ax2 . grid ( True , alpha = 0.3 ) # Plot 3: Performance Metrics Comparison ax3 = axes [ 1 , 0 ] ax3 . axis ( 'off' ) # Create metrics table metrics_data = [] for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: if strategy_metrics [ regime ]: metrics_data . append ([ regime . replace ( '_' , ' ' ) . title (), f \" { strategy_metrics [ regime ][ 'annual_return' ] : .2% } \" , f \" { strategy_metrics [ regime ][ 'sharpe_ratio' ] : .2f } \" , f \" { strategy_metrics [ regime ][ 'max_drawdown' ] : .2% } \" , f \" { strategy_metrics [ regime ][ 'days' ] } \" ]) table = ax3 . table ( cellText = metrics_data , colLabels = [ 'Regime' , 'Ann. Return' , 'Sharpe' , 'Max DD' , 'Days' ], loc = 'center' , cellLoc = 'center' ) table . auto_set_font_size ( False ) table . set_fontsize ( 10 ) table . scale ( 1.2 , 1.5 ) ax3 . set_title ( 'Strategy Performance by Regime' ) # Plot 4: Regime Distribution ax4 = axes [ 1 , 1 ] regime_counts = regimes . value_counts () colors = [ 'green' , 'yellow' , 'red' ] ax4 . pie ( regime_counts . values , labels = regime_counts . index , autopct = ' %1.1f%% ' , colors = colors ) ax4 . set_title ( 'Distribution of Volatility Regimes' ) plt . tight_layout () plt . show () # Print summary statistics self . _print_summary ( strategy_metrics , benchmark_metrics ) Explanation: - The plot method is the main interface that users will call - Extracts data from the results dictionary - Calls helper methods to perform analysis - Creates a comprehensive 2x2 subplot layout - Each subplot shows different aspects of the analysis - Includes proper labeling, legends, and formatting - Calls a helper method to print summary statistics","title":"Step 6: Implement the Required Plot Method"},{"location":"user-guide/analysis/#step-7-add-helper-methods","text":"def _print_summary ( self , strategy_metrics , benchmark_metrics ): \"\"\" Print a summary of the analysis results. Parameters ---------- strategy_metrics : dict Strategy performance metrics by regime benchmark_metrics : dict Benchmark performance metrics by regime \"\"\" print ( \" \\n \" + \"=\" * 60 ) print ( \"VOLATILITY REGIME ANALYSIS SUMMARY\" ) print ( \"=\" * 60 ) for regime in [ 'low_vol' , 'medium_vol' , 'high_vol' ]: if strategy_metrics [ regime ]: print ( f \" \\n { regime . replace ( '_' , ' ' ) . title () } Regime:\" ) print ( f \" Days: { strategy_metrics [ regime ][ 'days' ] } \" ) print ( f \" Annual Return: { strategy_metrics [ regime ][ 'annual_return' ] : .2% } \" ) print ( f \" Sharpe Ratio: { strategy_metrics [ regime ][ 'sharpe_ratio' ] : .2f } \" ) print ( f \" Max Drawdown: { strategy_metrics [ regime ][ 'max_drawdown' ] : .2% } \" ) print ( f \" Win Rate: { strategy_metrics [ regime ][ 'win_rate' ] : .2% } \" ) print ( \" \\n \" + \"=\" * 60 ) Explanation: - Helper method to print formatted summary statistics - Provides clear, readable output of key findings - Uses consistent formatting for professional presentation","title":"Step 7: Add Helper Methods"},{"location":"user-guide/analysis/#step-8-usage-example","text":"# Create and use your custom analyzer from portwine.analyzers import VolatilityRegimeAnalyzer # Initialize with custom parameters analyzer = VolatilityRegimeAnalyzer ( volatility_window = 90 , # 90-day rolling window regime_thresholds = { 'low' : 0.25 , # Bottom 25% = low volatility 'high' : 0.75 # Top 25% = high volatility } ) # Run the analysis analyzer . plot ( results , figsize = ( 16 , 12 )) Explanation: - Shows how to instantiate your custom analyzer - Demonstrates parameter customization - Shows the simple interface for running the analysis","title":"Step 8: Usage Example"},{"location":"user-guide/analysis/#key-design-principles","text":"Inherit from Analyzer : Always inherit from the base Analyzer class Clear Documentation : Provide comprehensive docstrings for all methods Flexible Parameters : Allow users to customize key parameters Error Handling : Handle edge cases gracefully (empty data, missing regimes) Professional Visualization : Create clear, informative plots with proper formatting Modular Design : Break complex logic into smaller, focused methods Consistent Interface : Follow the same pattern as built-in analyzers This example demonstrates how to create a sophisticated custom analyzer that provides valuable insights while maintaining the same professional interface as the built-in analyzers.","title":"Key Design Principles"},{"location":"user-guide/analysis/#next-steps","text":"Learn about building strategies Explore backtesting Check out data management","title":"Next Steps"},{"location":"user-guide/backtesting/","text":"Backtesting Backtesting is the process of testing a trading strategy on historical data to evaluate its performance. Portwine makes this process simple and intuitive. Basic Backtesting Setting Up a Backtest from portwine import Backtester , SimpleMomentumStrategy , EODHDMarketDataLoader # 1. Define your strategy strategy = SimpleMomentumStrategy ( tickers = [ 'AAPL' , 'GOOGL' , 'MSFT' , 'AMZN' ], lookback_days = 20 ) # 2. Set up data loader data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/data/' ) # 3. Create backtester backtester = Backtester ( market_data_loader = data_loader ) # 4. Run backtest results = backtester . run_backtest ( strategy = strategy , benchmark_ticker = 'SPY' , start_date = '2020-01-01' , end_date = '2023-12-31' , verbose = True ) Understanding Results The backtest returns a dictionary with four key components: # Strategy allocations over time signals_df = results [ 'signals_df' ] print ( signals_df . head ()) # Output: # AAPL GOOGL MSFT AMZN # 2020-01-02 0.0 0.0 0.0 1.0 # 2020-01-03 0.0 0.0 0.0 1.0 # 2020-01-06 0.0 0.0 0.0 1.0 # Individual asset returns ticker_returns = results [ 'tickers_returns' ] print ( ticker_returns . head ()) # Output: # AAPL GOOGL MSFT AMZN # 2020-01-02 0.0123 0.0089 0.0156 0.0234 # 2020-01-03 -0.0056 0.0123 -0.0034 0.0189 # Strategy performance strategy_returns = results [ 'strategy_returns' ] print ( strategy_returns . head ()) # Output: # 2020-01-02 0.0234 # 2020-01-03 0.0189 # 2020-01-06 0.0156 # Benchmark performance benchmark_returns = results [ 'benchmark_returns' ] Key Parameters Date Range # Specific date range results = backtester . run_backtest ( strategy = strategy , start_date = '2020-01-01' , end_date = '2023-12-31' ) # No date restrictions (uses all available data) results = backtester . run_backtest ( strategy = strategy ) Benchmarks # Built-in benchmarks results = backtester . run_backtest ( strategy = strategy , benchmark = \"equal_weight\" # Equal weight portfolio ) results = backtester . run_backtest ( strategy = strategy , benchmark = \"markowitz\" # Mean-variance optimized ) # Single ticker benchmark results = backtester . run_backtest ( strategy = strategy , benchmark = \"SPY\" ) # Custom benchmark function def custom_benchmark ( returns_df ): \"\"\"Custom benchmark that weights by market cap\"\"\" # Your custom logic here return returns_df . mean ( axis = 1 ) results = backtester . run_backtest ( strategy = strategy , benchmark = custom_benchmark ) Signal Timing # Default: signals applied next day (prevents lookahead bias) results = backtester . run_backtest ( strategy = strategy , shift_signals = True ) # Signals applied same day (not recommended) results = backtester . run_backtest ( strategy = strategy , shift_signals = False # Will most likely be deprecated in the future, as this is not recommended ever. ) Data Requirements Requiring All Tickers # Error if any ticker is missing data results = backtester . run_backtest ( strategy = strategy , require_all_tickers = True ) # Warning if tickers are missing (default) results = backtester . run_backtest ( strategy = strategy , require_all_tickers = False ) Requiring Full History # Only use dates where all tickers have data results = backtester . run_backtest ( strategy = strategy , require_all_history = True ) Trading Calendars Using Exchange Calendars import pandas_market_calendars as mcal # NYSE calendar calendar = mcal . get_calendar ( 'NYSE' ) backtester = Backtester ( market_data_loader = data_loader , calendar = calendar ) # NASDAQ calendar calendar = mcal . get_calendar ( 'NASDAQ' ) backtester = Backtester ( market_data_loader = data_loader , calendar = calendar ) Calendar Benefits Accurate trading days : Only uses actual trading days Holiday handling : Automatically excludes market holidays Time zone support : Handles different exchange time zones Alternative Data Adding Alternative Data Sources from portwine import AlternativeDataLoader # Set up alternative data loader alt_loader = AlternativeDataLoader () # Create backtester with alternative data backtester = Backtester ( market_data_loader = market_loader , alternative_data_loader = alt_loader ) # Strategy can now access alternative data class AltDataStrategy ( StrategyBase ): def step ( self , current_date , daily_data ): # Access alternative data if 'alt:sentiment' in daily_data : sentiment = daily_data [ 'alt:sentiment' ] # Use sentiment in strategy logic Performance Analysis Basic Performance Metrics You can now use the results to calculate any metrics you'd like: import pandas as pd import numpy as np # Calculate cumulative returns cumulative_returns = ( 1 + results [ 'strategy_returns' ]) . cumprod ( axis = 0 ) # axis=0 for time series benchmark_cumulative = ( 1 + results [ 'benchmark_returns' ]) . cumprod ( axis = 0 ) # Calculate annualized return annual_return = results [ 'strategy_returns' ] . mean () * 252 # Calculate volatility volatility = results [ 'strategy_returns' ] . std () * np . sqrt ( 252 ) # Calculate Sharpe ratio risk_free_rate = 0.02 # 2% annual sharpe_ratio = ( annual_return - risk_free_rate ) / volatility # Calculate maximum drawdown cumulative = ( 1 + results [ 'strategy_returns' ]) . cumprod ( axis = 0 ) # axis=0 for time series running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min () Using Built-in Analyzers However, you'd probably prefer the prebuilt analyzers that offer raw analysis (output as Dataframes in most cases) and visual plotting: from portwine.analyzers import ( EquityDrawdownAnalyzer , MonteCarloAnalyzer , SeasonalityAnalyzer ) # Equity and drawdown analysis EquityDrawdownAnalyzer () . plot ( results ) # Monte Carlo simulation MonteCarloAnalyzer () . plot ( results ) # Seasonality analysis SeasonalityAnalyzer () . plot ( results ) Best Practices 1. Prevent Lookahead Bias Always use shift_signals=True (default): # \u2705 Good results = backtester . run_backtest ( strategy = strategy , shift_signals = True ) # \u274c Bad - introduces lookahead bias results = backtester . run_backtest ( strategy = strategy , shift_signals = False ) 2. Use Appropriate Benchmarks # For equity strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"SPY\" ) # For multi-asset strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"equal_weight\" ) # For factor strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"markowitz\" ) Next Steps Learn about performance analysis Explore data management Check out advanced strategies","title":"Backtesting"},{"location":"user-guide/backtesting/#backtesting","text":"Backtesting is the process of testing a trading strategy on historical data to evaluate its performance. Portwine makes this process simple and intuitive.","title":"Backtesting"},{"location":"user-guide/backtesting/#basic-backtesting","text":"","title":"Basic Backtesting"},{"location":"user-guide/backtesting/#setting-up-a-backtest","text":"from portwine import Backtester , SimpleMomentumStrategy , EODHDMarketDataLoader # 1. Define your strategy strategy = SimpleMomentumStrategy ( tickers = [ 'AAPL' , 'GOOGL' , 'MSFT' , 'AMZN' ], lookback_days = 20 ) # 2. Set up data loader data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/data/' ) # 3. Create backtester backtester = Backtester ( market_data_loader = data_loader ) # 4. Run backtest results = backtester . run_backtest ( strategy = strategy , benchmark_ticker = 'SPY' , start_date = '2020-01-01' , end_date = '2023-12-31' , verbose = True )","title":"Setting Up a Backtest"},{"location":"user-guide/backtesting/#understanding-results","text":"The backtest returns a dictionary with four key components: # Strategy allocations over time signals_df = results [ 'signals_df' ] print ( signals_df . head ()) # Output: # AAPL GOOGL MSFT AMZN # 2020-01-02 0.0 0.0 0.0 1.0 # 2020-01-03 0.0 0.0 0.0 1.0 # 2020-01-06 0.0 0.0 0.0 1.0 # Individual asset returns ticker_returns = results [ 'tickers_returns' ] print ( ticker_returns . head ()) # Output: # AAPL GOOGL MSFT AMZN # 2020-01-02 0.0123 0.0089 0.0156 0.0234 # 2020-01-03 -0.0056 0.0123 -0.0034 0.0189 # Strategy performance strategy_returns = results [ 'strategy_returns' ] print ( strategy_returns . head ()) # Output: # 2020-01-02 0.0234 # 2020-01-03 0.0189 # 2020-01-06 0.0156 # Benchmark performance benchmark_returns = results [ 'benchmark_returns' ]","title":"Understanding Results"},{"location":"user-guide/backtesting/#key-parameters","text":"","title":"Key Parameters"},{"location":"user-guide/backtesting/#date-range","text":"# Specific date range results = backtester . run_backtest ( strategy = strategy , start_date = '2020-01-01' , end_date = '2023-12-31' ) # No date restrictions (uses all available data) results = backtester . run_backtest ( strategy = strategy )","title":"Date Range"},{"location":"user-guide/backtesting/#benchmarks","text":"# Built-in benchmarks results = backtester . run_backtest ( strategy = strategy , benchmark = \"equal_weight\" # Equal weight portfolio ) results = backtester . run_backtest ( strategy = strategy , benchmark = \"markowitz\" # Mean-variance optimized ) # Single ticker benchmark results = backtester . run_backtest ( strategy = strategy , benchmark = \"SPY\" ) # Custom benchmark function def custom_benchmark ( returns_df ): \"\"\"Custom benchmark that weights by market cap\"\"\" # Your custom logic here return returns_df . mean ( axis = 1 ) results = backtester . run_backtest ( strategy = strategy , benchmark = custom_benchmark )","title":"Benchmarks"},{"location":"user-guide/backtesting/#signal-timing","text":"# Default: signals applied next day (prevents lookahead bias) results = backtester . run_backtest ( strategy = strategy , shift_signals = True ) # Signals applied same day (not recommended) results = backtester . run_backtest ( strategy = strategy , shift_signals = False # Will most likely be deprecated in the future, as this is not recommended ever. )","title":"Signal Timing"},{"location":"user-guide/backtesting/#data-requirements","text":"","title":"Data Requirements"},{"location":"user-guide/backtesting/#requiring-all-tickers","text":"# Error if any ticker is missing data results = backtester . run_backtest ( strategy = strategy , require_all_tickers = True ) # Warning if tickers are missing (default) results = backtester . run_backtest ( strategy = strategy , require_all_tickers = False )","title":"Requiring All Tickers"},{"location":"user-guide/backtesting/#requiring-full-history","text":"# Only use dates where all tickers have data results = backtester . run_backtest ( strategy = strategy , require_all_history = True )","title":"Requiring Full History"},{"location":"user-guide/backtesting/#trading-calendars","text":"","title":"Trading Calendars"},{"location":"user-guide/backtesting/#using-exchange-calendars","text":"import pandas_market_calendars as mcal # NYSE calendar calendar = mcal . get_calendar ( 'NYSE' ) backtester = Backtester ( market_data_loader = data_loader , calendar = calendar ) # NASDAQ calendar calendar = mcal . get_calendar ( 'NASDAQ' ) backtester = Backtester ( market_data_loader = data_loader , calendar = calendar )","title":"Using Exchange Calendars"},{"location":"user-guide/backtesting/#calendar-benefits","text":"Accurate trading days : Only uses actual trading days Holiday handling : Automatically excludes market holidays Time zone support : Handles different exchange time zones","title":"Calendar Benefits"},{"location":"user-guide/backtesting/#alternative-data","text":"","title":"Alternative Data"},{"location":"user-guide/backtesting/#adding-alternative-data-sources","text":"from portwine import AlternativeDataLoader # Set up alternative data loader alt_loader = AlternativeDataLoader () # Create backtester with alternative data backtester = Backtester ( market_data_loader = market_loader , alternative_data_loader = alt_loader ) # Strategy can now access alternative data class AltDataStrategy ( StrategyBase ): def step ( self , current_date , daily_data ): # Access alternative data if 'alt:sentiment' in daily_data : sentiment = daily_data [ 'alt:sentiment' ] # Use sentiment in strategy logic","title":"Adding Alternative Data Sources"},{"location":"user-guide/backtesting/#performance-analysis","text":"","title":"Performance Analysis"},{"location":"user-guide/backtesting/#basic-performance-metrics","text":"You can now use the results to calculate any metrics you'd like: import pandas as pd import numpy as np # Calculate cumulative returns cumulative_returns = ( 1 + results [ 'strategy_returns' ]) . cumprod ( axis = 0 ) # axis=0 for time series benchmark_cumulative = ( 1 + results [ 'benchmark_returns' ]) . cumprod ( axis = 0 ) # Calculate annualized return annual_return = results [ 'strategy_returns' ] . mean () * 252 # Calculate volatility volatility = results [ 'strategy_returns' ] . std () * np . sqrt ( 252 ) # Calculate Sharpe ratio risk_free_rate = 0.02 # 2% annual sharpe_ratio = ( annual_return - risk_free_rate ) / volatility # Calculate maximum drawdown cumulative = ( 1 + results [ 'strategy_returns' ]) . cumprod ( axis = 0 ) # axis=0 for time series running_max = cumulative . expanding () . max () drawdown = ( cumulative - running_max ) / running_max max_drawdown = drawdown . min ()","title":"Basic Performance Metrics"},{"location":"user-guide/backtesting/#using-built-in-analyzers","text":"However, you'd probably prefer the prebuilt analyzers that offer raw analysis (output as Dataframes in most cases) and visual plotting: from portwine.analyzers import ( EquityDrawdownAnalyzer , MonteCarloAnalyzer , SeasonalityAnalyzer ) # Equity and drawdown analysis EquityDrawdownAnalyzer () . plot ( results ) # Monte Carlo simulation MonteCarloAnalyzer () . plot ( results ) # Seasonality analysis SeasonalityAnalyzer () . plot ( results )","title":"Using Built-in Analyzers"},{"location":"user-guide/backtesting/#best-practices","text":"","title":"Best Practices"},{"location":"user-guide/backtesting/#1-prevent-lookahead-bias","text":"Always use shift_signals=True (default): # \u2705 Good results = backtester . run_backtest ( strategy = strategy , shift_signals = True ) # \u274c Bad - introduces lookahead bias results = backtester . run_backtest ( strategy = strategy , shift_signals = False )","title":"1. Prevent Lookahead Bias"},{"location":"user-guide/backtesting/#2-use-appropriate-benchmarks","text":"# For equity strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"SPY\" ) # For multi-asset strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"equal_weight\" ) # For factor strategies results = backtester . run_backtest ( strategy = strategy , benchmark = \"markowitz\" )","title":"2. Use Appropriate Benchmarks"},{"location":"user-guide/backtesting/#next-steps","text":"Learn about performance analysis Explore data management Check out advanced strategies","title":"Next Steps"},{"location":"user-guide/data-management/","text":"Data Management Portwine provides flexible data management through its data loader system, making it easy to work with various data sources and formats. Data loaders are responsible for fetching and providing market data to the backtester. Base Market Data Loader The MarketDataLoader is the foundation of Portwine's data system. It provides a standardized interface for loading and accessing market data, with built-in caching and efficient data retrieval. Core Functionality The base loader provides three main capabilities: Data Loading : Fetch and cache market data for multiple tickers Date Management : Build unified trading calendars across multiple assets Time-based Access : Retrieve data at specific timestamps with efficient lookups Data Format All data loaders must return data in a standardized format: # DataFrame with required columns and index DataFrame : Index : pd . Timestamp ( datetime ) Columns : [ 'open' , 'high' , 'low' , 'close' , 'volume' ] # Example: # open high low close volume # 2020-01-02 100.0 102.5 99.0 101.2 1000000 # 2020-01-03 101.2 103.8 100.8 102.9 1200000 # 2020-01-06 102.9 105.2 102.1 104.5 1100000 Key Methods load_ticker(ticker: str) -> pd.DataFrame | None Purpose : Load data for a single ticker (must be implemented by subclasses) Returns : - pd.DataFrame with OHLCV data indexed by timestamp - None if data is unavailable Example Implementation : def load_ticker ( self , ticker : str ) -> pd . DataFrame | None : # Load from CSV file file_path = f \"data/ { ticker } .csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) return df [[ 'open' , 'high' , 'low' , 'close' , 'volume' ]] fetch_data(tickers: list[str]) -> dict[str, pd.DataFrame] Purpose : Load and cache data for multiple tickers Returns : Dictionary mapping ticker symbols to their DataFrames Features : - Automatic caching (data loaded once, reused) - Handles missing data gracefully - Returns only available tickers # Usage loader = MyDataLoader () data = loader . fetch_data ([ 'AAPL' , 'GOOGL' , 'MSFT' ]) # Returns: # { # 'AAPL': DataFrame(...), # 'GOOGL': DataFrame(...), # 'MSFT': DataFrame(...) # } get_all_dates(tickers: list[str]) -> list[pd.Timestamp] Purpose : Build a unified trading calendar across multiple tickers Returns : Sorted list of all unique timestamps Use Case : Creating trading calendars for backtesting # Get all trading dates across multiple assets dates = loader . get_all_dates ([ 'AAPL' , 'GOOGL' , 'MSFT' ]) # Returns: [2020-01-02, 2020-01-03, 2020-01-06, ...] next(tickers: list[str], ts: pd.Timestamp) -> dict[str, dict[str, float] | None] Purpose : Get OHLCV data at or immediately before a specific timestamp Returns : Dictionary with ticker data at the requested time Features : - Efficient binary search using searchsorted - Returns data from the most recent bar before the timestamp - Handles missing data with None values # Get data at specific time bar_data = loader . next ([ 'AAPL' , 'GOOGL' ], pd . Timestamp ( '2020-01-02 10:30:00' )) # Returns: # { # 'AAPL': { # 'open': 100.0, # 'high': 102.5, # 'low': 99.0, # 'close': 101.2, # 'volume': 1000000.0 # }, # 'GOOGL': { # 'open': 1500.0, # 'high': 1520.0, # 'low': 1495.0, # 'close': 1510.0, # 'volume': 500000.0 # } # } Data Caching The base loader includes automatic caching to improve performance: # First call loads from source data1 = loader . fetch_data ([ 'AAPL' ]) # Loads from file/API # Subsequent calls use cached data data2 = loader . fetch_data ([ 'AAPL' ]) # Uses cache, no I/O Error Handling The loader handles missing data gracefully: # Missing ticker returns empty dict data = loader . fetch_data ([ 'INVALID_TICKER' ]) # Returns: {} # Missing timestamp returns None bar = loader . next ([ 'AAPL' ], pd . Timestamp ( '1900-01-01' )) # Returns: {'AAPL': None} Creating Custom Loaders To create a custom data loader, inherit from MarketDataLoader and implement load_ticker : from portwine.loaders.base import MarketDataLoader import pandas as pd class MyCustomLoader ( MarketDataLoader ): def __init__ ( self , api_key ): self . api_key = api_key super () . __init__ () def load_ticker ( self , ticker : str ) -> pd . DataFrame | None : # Your custom data loading logic here # Must return DataFrame with ['open', 'high', 'low', 'close', 'volume'] # or None if data unavailable pass Integration with Backtester The backtester uses the data loader's methods automatically: # Backtester calls these methods internally: loader . fetch_data ( strategy . tickers ) # Load all required data loader . get_all_dates ( strategy . tickers ) # Build trading calendar loader . next ( tickers , current_time ) # Get data for each step This design provides a clean separation between data management and strategy execution, making it easy to switch data sources or add new ones without changing the backtesting logic. Out-of-the-Box Loaders Portwine comes with several out of the box loaders for loading saved data from different providers. These are not downloaders , which actually fetch the data from the source. You will need one of those prior (coming soon...) EODHD Market Data Loader The EODHD loader reads historical market data from CSV files downloaded from EODHD (End of Day Historical Data). It automatically handles price adjustments for splits and dividends. from portwine.loaders import EODHDMarketDataLoader # Initialize with your data directory data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/eodhd/data/' , exchange_code = 'US' # Default is 'US' ) # Fetch data for specific tickers data = data_loader . fetch_data ([ 'AAPL' , 'GOOGL' , 'MSFT' ]) File Structure CSV files must be named as TICKER.EXCHANGE.csv and contain these columns: data_path/ \u251c\u2500\u2500 AAPL.US.csv \u251c\u2500\u2500 GOOGL.US.csv \u251c\u2500\u2500 MSFT.US.csv \u2514\u2500\u2500 SPY.US.csv Required CSV Columns Each CSV file must contain these columns: - date - Date column (will become the index) - open - Opening price - high - High price - low - Low price - close - Closing price - adjusted_close - Split/dividend adjusted closing price - volume - Trading volume Price Adjustment The loader automatically adjusts all OHLC prices using the adjusted_close ratio: # The loader calculates: adj_ratio = adjusted_close / close # Then applies: open = open * adj_ratio, high = high * adj_ratio, etc. # Final close = adjusted_close This ensures all prices are adjusted for stock splits and dividends, making them suitable for backtesting. Example CSV Format date,open,high,low,close,adjusted_close,volume 2020-01-02,100.0,102.5,99.0,101.2,101.2,1000000 2020-01-03,101.2,103.8,100.8,102.9,102.9,1200000 2020-01-06,102.9,105.2,102.1,104.5,104.5,1100000 Polygon Market Data Loader For Polygon.io data: from portwine.loaders import PolygonMarketDataLoader data_loader = PolygonMarketDataLoader ( data_path = 'path/to/polygon/data/' ) Data Format Requirements OHLCV Data Structure Portwine expects data in the following format: # DataFrame with columns: open, high, low, close, volume data = { 'AAPL' : pd . DataFrame ({ 'open' : [ 150.0 , 151.0 , 152.0 ], 'high' : [ 152.0 , 153.0 , 154.0 ], 'low' : [ 149.0 , 150.0 , 151.0 ], 'close' : [ 151.0 , 152.0 , 153.0 ], 'volume' : [ 1000000 , 1100000 , 1200000 ] }, index = pd . DatetimeIndex ([ '2023-01-01' , '2023-01-02' , '2023-01-03' ])) } Data Quality Requirements No missing values : All OHLCV fields should be present Valid dates : Index should be datetime objects Sorted index : Dates should be in ascending order Consistent timezone : All data should use the same timezone Alternative Data Portwine supports alternative data sources through a specifier system that distinguishes between different types of data. This allows you to combine market data with alternative data sources like sentiment, news, economic indicators, and more. Data Source Specifiers Data sources are identified using a SOURCE:TICKER format, where: - SOURCE - Identifies the data provider or type - TICKER - The specific identifier for that data source # Market data (no specifier needed) market_tickers = [ 'AAPL' , 'GOOGL' , 'MSFT' ] # Alternative data (with specifier) alt_tickers = [ 'sentiment:AAPL' , 'news:GOOGL' , 'fred:GDP' , 'custom:my_data' ] Built-in Alternative Data Loaders FRED Economic Data Load economic indicators from the Federal Reserve Economic Data (FRED): from portwine.loaders import FREDDataLoader # Initialize FRED loader fred_loader = FREDDataLoader ( api_key = 'your_fred_api_key' ) # Fetch economic data data = fred_loader . fetch_data ([ 'fred:GDP' , 'fred:UNRATE' , 'fred:CPIAUCSL' ]) # Returns: # { # 'fred:GDP': DataFrame(...), # Gross Domestic Product # 'fred:UNRATE': DataFrame(...), # Unemployment Rate # 'fred:CPIAUCSL': DataFrame(...) # Consumer Price Index # } Custom Alternative Data Create your own alternative data loader: from portwine.loaders.base import MarketDataLoader class SentimentDataLoader ( MarketDataLoader ): def __init__ ( self , data_path ): self . data_path = data_path super () . __init__ () def load_ticker ( self , ticker ): # Remove 'sentiment:' prefix to get actual ticker base_ticker = ticker . replace ( 'sentiment:' , '' ) file_path = f \" { self . data_path } / { base_ticker } _sentiment.csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) # Alternative data can have different columns return df [[ 'sentiment_score' , 'volume' ]] # Not OHLCV format # Use your custom loader sentiment_loader = SentimentDataLoader ( 'path/to/sentiment/data/' ) Combining Market and Alternative Data The backtester can handle both market data and alternative data simultaneously: from portwine.backtester import Backtester from portwine.loaders import EODHDMarketDataLoader # Set up market data loader market_loader = EODHDMarketDataLoader ( 'path/to/market/data/' ) # Set up alternative data loader alt_loader = SentimentDataLoader ( 'path/to/sentiment/data/' ) # Create backtester with both loaders backtester = Backtester ( market_data_loader = market_loader , alternative_data_loader = alt_loader ) # Strategy can access both types of data class HybridStrategy ( StrategyBase ): def __init__ ( self , tickers ): # Market tickers self . market_tickers = [ 'AAPL' , 'GOOGL' ] # Alternative data tickers self . alt_tickers = [ 'sentiment:AAPL' , 'sentiment:GOOGL' ] # Combined list tickers = self . market_tickers + self . alt_tickers super () . __init__ ( tickers ) def step ( self , current_date , daily_data ): allocations = {} for ticker in self . market_tickers : if ticker in daily_data and daily_data [ ticker ]: # Market data has OHLCV format price = daily_data [ ticker ][ 'close' ] sentiment_key = f 'sentiment: { ticker } ' if sentiment_key in daily_data and daily_data [ sentiment_key ]: # Alternative data has custom format sentiment = daily_data [ sentiment_key ][ 'sentiment_score' ] # Use both market price and sentiment if sentiment > 0.5 and price > 100 : allocations [ ticker ] = 1.0 else : allocations [ ticker ] = 0.0 else : allocations [ ticker ] = 0.0 return allocations Data Format Differences Market Data Format Market data always follows the standard OHLCV format: # Market data structure { 'AAPL' : { 'open' : 100.0 , 'high' : 102.5 , 'low' : 99.0 , 'close' : 101.2 , 'volume' : 1000000.0 } } Alternative Data Format Alternative data can have any structure, but should be consistent: # Sentiment data structure { 'sentiment:AAPL' : { 'sentiment_score' : 0.75 , 'volume' : 5000 , 'confidence' : 0.9 } } # Economic data structure { 'fred:GDP' : { 'value' : 21433.2 , 'change' : 0.5 , 'units' : 'Billions of Dollars' } } Data Source Management Automatic Source Detection The backtester automatically detects and routes data to the appropriate loader: # The backtester splits tickers based on specifiers market_tickers , alt_tickers = backtester . _split_tickers ( strategy . tickers ) # Market tickers: ['AAPL', 'GOOGL'] # Alt tickers: ['sentiment:AAPL', 'fred:GDP'] Multiple Alternative Data Sources You can combine multiple alternative data sources: from portwine.loaders import FREDDataLoader , SentimentDataLoader , NewsDataLoader , AlternativeDataLoader # Multiple alternative data loaders fred_loader = FREDDataLoader ( api_key = 'your_fred_key' ) sentiment_loader = SentimentDataLoader ( 'path/to/sentiment/' ) news_loader = NewsDataLoader ( 'path/to/news/' ) # Initialize the main alternative data loader with all sub-loaders alt_loader = AlternativeDataLoader () alt_loader . add_loader ( 'fred' , fred_loader ) alt_loader . add_loader ( 'sentiment' , sentiment_loader ) alt_loader . add_loader ( 'news' , news_loader ) # Strategy with multiple data sources class MultiSourceStrategy ( StrategyBase ): def __init__ ( self ): self . tickers = [ # Market data 'AAPL' , 'GOOGL' , # Economic data 'fred:GDP' , 'fred:UNRATE' , # Sentiment data 'sentiment:AAPL' , 'sentiment:GOOGL' , # News data 'news:AAPL' , 'news:GOOGL' ] super () . __init__ ( self . tickers ) def step ( self , current_date , daily_data ): # Access different data types aapl_price = daily_data . get ( 'AAPL' , {}) . get ( 'close' ) gdp = daily_data . get ( 'fred:GDP' , {}) . get ( 'value' ) sentiment = daily_data . get ( 'sentiment:AAPL' , {}) . get ( 'sentiment_score' ) news_count = daily_data . get ( 'news:AAPL' , {}) . get ( 'article_count' ) # Combine all signals if ( aapl_price and gdp and sentiment and news_count ): # Your strategy logic here pass Best Practices for Alternative Data 1. Consistent Naming Use consistent specifier prefixes: # Good: Consistent naming alt_tickers = [ 'sentiment:AAPL' , 'sentiment:GOOGL' , 'news:AAPL' , 'news:GOOGL' , 'fred:GDP' , 'fred:UNRATE' ] # Avoid: Inconsistent naming alt_tickers = [ 'sentiment:AAPL' , 'news_GOOGL' , # Mixed separators 'FRED:GDP' , 'fred:UNRATE' # Mixed case ] 2. Data Synchronization Ensure alternative data aligns with market data dates: def synchronize_alt_data ( market_data , alt_data ): \"\"\"Align alternative data with market data dates.\"\"\" market_dates = set ( market_data [ 'AAPL' ] . index ) for ticker , df in alt_data . items (): # Filter to market trading days alt_data [ ticker ] = df [ df . index . isin ( market_dates )] return alt_data 3. Missing Data Handling Handle missing alternative data gracefully: def step ( self , current_date , daily_data ): allocations = {} for ticker in self . market_tickers : # Check if we have both market and alternative data has_market = ticker in daily_data and daily_data [ ticker ] is not None has_sentiment = f 'sentiment: { ticker } ' in daily_data and daily_data [ f 'sentiment: { ticker } ' ] is not None if has_market and has_sentiment : # Use both data sources price = daily_data [ ticker ][ 'close' ] sentiment = daily_data [ f 'sentiment: { ticker } ' ][ 'sentiment_score' ] allocations [ ticker ] = self . calculate_weight ( price , sentiment ) elif has_market : # Fall back to market data only allocations [ ticker ] = self . calculate_weight_market_only ( daily_data [ ticker ]) else : # No data available allocations [ ticker ] = 0.0 return allocations Creating Custom Alternative Data Loaders To create a custom alternative data loader: from portwine.loaders.base import MarketDataLoader class CustomAltDataLoader ( MarketDataLoader ): def __init__ ( self , data_path , source_name ): self . data_path = data_path self . source_name = source_name # e.g., 'sentiment', 'news' super () . __init__ () def load_ticker ( self , ticker ): # Extract base ticker from specifier if not ticker . startswith ( f ' { self . source_name } :' ): return None base_ticker = ticker . replace ( f ' { self . source_name } :' , '' ) file_path = f \" { self . data_path } / { base_ticker } .csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) # Return whatever columns your alternative data has return df # Usage sentiment_loader = CustomAltDataLoader ( 'path/to/data/' , 'sentiment' ) data = sentiment_loader . fetch_data ([ 'sentiment:AAPL' , 'sentiment:GOOGL' ]) This system provides flexibility to combine any type of alternative data with market data while maintaining clean separation between different data sources. Data Caching Implementing Caching import pickle import os class CachedDataLoader ( MarketDataLoader ): def __init__ ( self , base_loader , cache_dir = './cache' ): self . base_loader = base_loader self . cache_dir = cache_dir os . makedirs ( cache_dir , exist_ok = True ) def fetch_data ( self , tickers ): \"\"\"Fetch data with caching.\"\"\" cached_data = {} uncached_tickers = [] # Check cache first for ticker in tickers : cache_file = f \" { self . cache_dir } / { ticker } .pkl\" if os . path . exists ( cache_file ): with open ( cache_file , 'rb' ) as f : cached_data [ ticker ] = pickle . load ( f ) else : uncached_tickers . append ( ticker ) # Fetch uncached data if uncached_tickers : new_data = self . base_loader . fetch_data ( uncached_tickers ) # Cache new data for ticker , df in new_data . items (): cache_file = f \" { self . cache_dir } / { ticker } .pkl\" with open ( cache_file , 'wb' ) as f : pickle . dump ( df , f ) cached_data [ ticker ] = df return cached_data # Use cached loader cached_loader = CachedDataLoader ( base_loader ) Best Practices 1. Data Quality Checks def check_data_quality ( data_dict ): \"\"\"Comprehensive data quality check.\"\"\" issues = [] for ticker , df in data_dict . items (): # Check for required columns if not all ( col in df . columns for col in [ 'open' , 'high' , 'low' , 'close' , 'volume' ]): issues . append ( f \" { ticker } : Missing required columns\" ) # Check for negative prices if ( df [[ 'open' , 'high' , 'low' , 'close' ]] <= 0 ) . any () . any (): issues . append ( f \" { ticker } : Negative prices detected\" ) # Check for price consistency if not (( df [ 'low' ] <= df [ 'open' ]) & ( df [ 'low' ] <= df [ 'close' ]) & ( df [ 'high' ] >= df [ 'open' ]) & ( df [ 'high' ] >= df [ 'close' ])) . all (): issues . append ( f \" { ticker } : Price consistency issues\" ) # Check for reasonable volume if ( df [ 'volume' ] < 0 ) . any (): issues . append ( f \" { ticker } : Negative volume detected\" ) return issues # Run quality checks issues = check_data_quality ( data ) if issues : print ( \"Data quality issues found:\" ) for issue in issues : print ( f \" - { issue } \" ) 2. Data Synchronization def synchronize_data ( data_dict ): \"\"\"Ensure all tickers have data for the same date range.\"\"\" # Find common date range all_dates = [] for df in data_dict . values (): all_dates . extend ( df . index . tolist ()) common_start = max ( df . index . min () for df in data_dict . values ()) common_end = min ( df . index . max () for df in data_dict . values ()) # Filter to common range synchronized_data = {} for ticker , df in data_dict . items (): mask = ( df . index >= common_start ) & ( df . index <= common_end ) synchronized_data [ ticker ] = df [ mask ] return synchronized_data # Synchronize your data sync_data = synchronize_data ( data ) 3. Memory Management # For large datasets, consider loading data in chunks def load_data_in_chunks ( data_loader , tickers , chunk_size = 100 ): \"\"\"Load data in chunks to manage memory.\"\"\" all_data = {} for i in range ( 0 , len ( tickers ), chunk_size ): chunk_tickers = tickers [ i : i + chunk_size ] chunk_data = data_loader . fetch_data ( chunk_tickers ) all_data . update ( chunk_data ) # Optional: clear memory del chunk_data return all_data Troubleshooting Common Issues Missing Data Files # Check if files exist import os for ticker in tickers : file_path = f \"data_path/ { ticker } .csv\" if not os . path . exists ( file_path ): print ( f \"Warning: { file_path } not found\" ) Date Format Issues # Ensure proper date parsing df . index = pd . to_datetime ( df . index , errors = 'coerce' ) df = df . dropna () # Remove rows with invalid dates Timezone Issues # Normalize timezones df . index = df . index . tz_localize ( None ) # Remove timezone info Next Steps Learn about building strategies Explore backtesting Check out performance analysis","title":"Data Management"},{"location":"user-guide/data-management/#data-management","text":"Portwine provides flexible data management through its data loader system, making it easy to work with various data sources and formats. Data loaders are responsible for fetching and providing market data to the backtester.","title":"Data Management"},{"location":"user-guide/data-management/#base-market-data-loader","text":"The MarketDataLoader is the foundation of Portwine's data system. It provides a standardized interface for loading and accessing market data, with built-in caching and efficient data retrieval.","title":"Base Market Data Loader"},{"location":"user-guide/data-management/#core-functionality","text":"The base loader provides three main capabilities: Data Loading : Fetch and cache market data for multiple tickers Date Management : Build unified trading calendars across multiple assets Time-based Access : Retrieve data at specific timestamps with efficient lookups","title":"Core Functionality"},{"location":"user-guide/data-management/#data-format","text":"All data loaders must return data in a standardized format: # DataFrame with required columns and index DataFrame : Index : pd . Timestamp ( datetime ) Columns : [ 'open' , 'high' , 'low' , 'close' , 'volume' ] # Example: # open high low close volume # 2020-01-02 100.0 102.5 99.0 101.2 1000000 # 2020-01-03 101.2 103.8 100.8 102.9 1200000 # 2020-01-06 102.9 105.2 102.1 104.5 1100000","title":"Data Format"},{"location":"user-guide/data-management/#key-methods","text":"","title":"Key Methods"},{"location":"user-guide/data-management/#load_tickerticker-str-pddataframe-none","text":"Purpose : Load data for a single ticker (must be implemented by subclasses) Returns : - pd.DataFrame with OHLCV data indexed by timestamp - None if data is unavailable Example Implementation : def load_ticker ( self , ticker : str ) -> pd . DataFrame | None : # Load from CSV file file_path = f \"data/ { ticker } .csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) return df [[ 'open' , 'high' , 'low' , 'close' , 'volume' ]]","title":"load_ticker(ticker: str) -&gt; pd.DataFrame | None"},{"location":"user-guide/data-management/#fetch_datatickers-liststr-dictstr-pddataframe","text":"Purpose : Load and cache data for multiple tickers Returns : Dictionary mapping ticker symbols to their DataFrames Features : - Automatic caching (data loaded once, reused) - Handles missing data gracefully - Returns only available tickers # Usage loader = MyDataLoader () data = loader . fetch_data ([ 'AAPL' , 'GOOGL' , 'MSFT' ]) # Returns: # { # 'AAPL': DataFrame(...), # 'GOOGL': DataFrame(...), # 'MSFT': DataFrame(...) # }","title":"fetch_data(tickers: list[str]) -&gt; dict[str, pd.DataFrame]"},{"location":"user-guide/data-management/#get_all_datestickers-liststr-listpdtimestamp","text":"Purpose : Build a unified trading calendar across multiple tickers Returns : Sorted list of all unique timestamps Use Case : Creating trading calendars for backtesting # Get all trading dates across multiple assets dates = loader . get_all_dates ([ 'AAPL' , 'GOOGL' , 'MSFT' ]) # Returns: [2020-01-02, 2020-01-03, 2020-01-06, ...]","title":"get_all_dates(tickers: list[str]) -&gt; list[pd.Timestamp]"},{"location":"user-guide/data-management/#nexttickers-liststr-ts-pdtimestamp-dictstr-dictstr-float-none","text":"Purpose : Get OHLCV data at or immediately before a specific timestamp Returns : Dictionary with ticker data at the requested time Features : - Efficient binary search using searchsorted - Returns data from the most recent bar before the timestamp - Handles missing data with None values # Get data at specific time bar_data = loader . next ([ 'AAPL' , 'GOOGL' ], pd . Timestamp ( '2020-01-02 10:30:00' )) # Returns: # { # 'AAPL': { # 'open': 100.0, # 'high': 102.5, # 'low': 99.0, # 'close': 101.2, # 'volume': 1000000.0 # }, # 'GOOGL': { # 'open': 1500.0, # 'high': 1520.0, # 'low': 1495.0, # 'close': 1510.0, # 'volume': 500000.0 # } # }","title":"next(tickers: list[str], ts: pd.Timestamp) -&gt; dict[str, dict[str, float] | None]"},{"location":"user-guide/data-management/#data-caching","text":"The base loader includes automatic caching to improve performance: # First call loads from source data1 = loader . fetch_data ([ 'AAPL' ]) # Loads from file/API # Subsequent calls use cached data data2 = loader . fetch_data ([ 'AAPL' ]) # Uses cache, no I/O","title":"Data Caching"},{"location":"user-guide/data-management/#error-handling","text":"The loader handles missing data gracefully: # Missing ticker returns empty dict data = loader . fetch_data ([ 'INVALID_TICKER' ]) # Returns: {} # Missing timestamp returns None bar = loader . next ([ 'AAPL' ], pd . Timestamp ( '1900-01-01' )) # Returns: {'AAPL': None}","title":"Error Handling"},{"location":"user-guide/data-management/#creating-custom-loaders","text":"To create a custom data loader, inherit from MarketDataLoader and implement load_ticker : from portwine.loaders.base import MarketDataLoader import pandas as pd class MyCustomLoader ( MarketDataLoader ): def __init__ ( self , api_key ): self . api_key = api_key super () . __init__ () def load_ticker ( self , ticker : str ) -> pd . DataFrame | None : # Your custom data loading logic here # Must return DataFrame with ['open', 'high', 'low', 'close', 'volume'] # or None if data unavailable pass","title":"Creating Custom Loaders"},{"location":"user-guide/data-management/#integration-with-backtester","text":"The backtester uses the data loader's methods automatically: # Backtester calls these methods internally: loader . fetch_data ( strategy . tickers ) # Load all required data loader . get_all_dates ( strategy . tickers ) # Build trading calendar loader . next ( tickers , current_time ) # Get data for each step This design provides a clean separation between data management and strategy execution, making it easy to switch data sources or add new ones without changing the backtesting logic.","title":"Integration with Backtester"},{"location":"user-guide/data-management/#out-of-the-box-loaders","text":"Portwine comes with several out of the box loaders for loading saved data from different providers. These are not downloaders , which actually fetch the data from the source. You will need one of those prior (coming soon...)","title":"Out-of-the-Box Loaders"},{"location":"user-guide/data-management/#eodhd-market-data-loader","text":"The EODHD loader reads historical market data from CSV files downloaded from EODHD (End of Day Historical Data). It automatically handles price adjustments for splits and dividends. from portwine.loaders import EODHDMarketDataLoader # Initialize with your data directory data_loader = EODHDMarketDataLoader ( data_path = 'path/to/your/eodhd/data/' , exchange_code = 'US' # Default is 'US' ) # Fetch data for specific tickers data = data_loader . fetch_data ([ 'AAPL' , 'GOOGL' , 'MSFT' ])","title":"EODHD Market Data Loader"},{"location":"user-guide/data-management/#file-structure","text":"CSV files must be named as TICKER.EXCHANGE.csv and contain these columns: data_path/ \u251c\u2500\u2500 AAPL.US.csv \u251c\u2500\u2500 GOOGL.US.csv \u251c\u2500\u2500 MSFT.US.csv \u2514\u2500\u2500 SPY.US.csv","title":"File Structure"},{"location":"user-guide/data-management/#required-csv-columns","text":"Each CSV file must contain these columns: - date - Date column (will become the index) - open - Opening price - high - High price - low - Low price - close - Closing price - adjusted_close - Split/dividend adjusted closing price - volume - Trading volume","title":"Required CSV Columns"},{"location":"user-guide/data-management/#price-adjustment","text":"The loader automatically adjusts all OHLC prices using the adjusted_close ratio: # The loader calculates: adj_ratio = adjusted_close / close # Then applies: open = open * adj_ratio, high = high * adj_ratio, etc. # Final close = adjusted_close This ensures all prices are adjusted for stock splits and dividends, making them suitable for backtesting.","title":"Price Adjustment"},{"location":"user-guide/data-management/#example-csv-format","text":"date,open,high,low,close,adjusted_close,volume 2020-01-02,100.0,102.5,99.0,101.2,101.2,1000000 2020-01-03,101.2,103.8,100.8,102.9,102.9,1200000 2020-01-06,102.9,105.2,102.1,104.5,104.5,1100000","title":"Example CSV Format"},{"location":"user-guide/data-management/#polygon-market-data-loader","text":"For Polygon.io data: from portwine.loaders import PolygonMarketDataLoader data_loader = PolygonMarketDataLoader ( data_path = 'path/to/polygon/data/' )","title":"Polygon Market Data Loader"},{"location":"user-guide/data-management/#data-format-requirements","text":"","title":"Data Format Requirements"},{"location":"user-guide/data-management/#ohlcv-data-structure","text":"Portwine expects data in the following format: # DataFrame with columns: open, high, low, close, volume data = { 'AAPL' : pd . DataFrame ({ 'open' : [ 150.0 , 151.0 , 152.0 ], 'high' : [ 152.0 , 153.0 , 154.0 ], 'low' : [ 149.0 , 150.0 , 151.0 ], 'close' : [ 151.0 , 152.0 , 153.0 ], 'volume' : [ 1000000 , 1100000 , 1200000 ] }, index = pd . DatetimeIndex ([ '2023-01-01' , '2023-01-02' , '2023-01-03' ])) }","title":"OHLCV Data Structure"},{"location":"user-guide/data-management/#data-quality-requirements","text":"No missing values : All OHLCV fields should be present Valid dates : Index should be datetime objects Sorted index : Dates should be in ascending order Consistent timezone : All data should use the same timezone","title":"Data Quality Requirements"},{"location":"user-guide/data-management/#alternative-data","text":"Portwine supports alternative data sources through a specifier system that distinguishes between different types of data. This allows you to combine market data with alternative data sources like sentiment, news, economic indicators, and more.","title":"Alternative Data"},{"location":"user-guide/data-management/#data-source-specifiers","text":"Data sources are identified using a SOURCE:TICKER format, where: - SOURCE - Identifies the data provider or type - TICKER - The specific identifier for that data source # Market data (no specifier needed) market_tickers = [ 'AAPL' , 'GOOGL' , 'MSFT' ] # Alternative data (with specifier) alt_tickers = [ 'sentiment:AAPL' , 'news:GOOGL' , 'fred:GDP' , 'custom:my_data' ]","title":"Data Source Specifiers"},{"location":"user-guide/data-management/#built-in-alternative-data-loaders","text":"","title":"Built-in Alternative Data Loaders"},{"location":"user-guide/data-management/#fred-economic-data","text":"Load economic indicators from the Federal Reserve Economic Data (FRED): from portwine.loaders import FREDDataLoader # Initialize FRED loader fred_loader = FREDDataLoader ( api_key = 'your_fred_api_key' ) # Fetch economic data data = fred_loader . fetch_data ([ 'fred:GDP' , 'fred:UNRATE' , 'fred:CPIAUCSL' ]) # Returns: # { # 'fred:GDP': DataFrame(...), # Gross Domestic Product # 'fred:UNRATE': DataFrame(...), # Unemployment Rate # 'fred:CPIAUCSL': DataFrame(...) # Consumer Price Index # }","title":"FRED Economic Data"},{"location":"user-guide/data-management/#custom-alternative-data","text":"Create your own alternative data loader: from portwine.loaders.base import MarketDataLoader class SentimentDataLoader ( MarketDataLoader ): def __init__ ( self , data_path ): self . data_path = data_path super () . __init__ () def load_ticker ( self , ticker ): # Remove 'sentiment:' prefix to get actual ticker base_ticker = ticker . replace ( 'sentiment:' , '' ) file_path = f \" { self . data_path } / { base_ticker } _sentiment.csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) # Alternative data can have different columns return df [[ 'sentiment_score' , 'volume' ]] # Not OHLCV format # Use your custom loader sentiment_loader = SentimentDataLoader ( 'path/to/sentiment/data/' )","title":"Custom Alternative Data"},{"location":"user-guide/data-management/#combining-market-and-alternative-data","text":"The backtester can handle both market data and alternative data simultaneously: from portwine.backtester import Backtester from portwine.loaders import EODHDMarketDataLoader # Set up market data loader market_loader = EODHDMarketDataLoader ( 'path/to/market/data/' ) # Set up alternative data loader alt_loader = SentimentDataLoader ( 'path/to/sentiment/data/' ) # Create backtester with both loaders backtester = Backtester ( market_data_loader = market_loader , alternative_data_loader = alt_loader ) # Strategy can access both types of data class HybridStrategy ( StrategyBase ): def __init__ ( self , tickers ): # Market tickers self . market_tickers = [ 'AAPL' , 'GOOGL' ] # Alternative data tickers self . alt_tickers = [ 'sentiment:AAPL' , 'sentiment:GOOGL' ] # Combined list tickers = self . market_tickers + self . alt_tickers super () . __init__ ( tickers ) def step ( self , current_date , daily_data ): allocations = {} for ticker in self . market_tickers : if ticker in daily_data and daily_data [ ticker ]: # Market data has OHLCV format price = daily_data [ ticker ][ 'close' ] sentiment_key = f 'sentiment: { ticker } ' if sentiment_key in daily_data and daily_data [ sentiment_key ]: # Alternative data has custom format sentiment = daily_data [ sentiment_key ][ 'sentiment_score' ] # Use both market price and sentiment if sentiment > 0.5 and price > 100 : allocations [ ticker ] = 1.0 else : allocations [ ticker ] = 0.0 else : allocations [ ticker ] = 0.0 return allocations","title":"Combining Market and Alternative Data"},{"location":"user-guide/data-management/#data-format-differences","text":"","title":"Data Format Differences"},{"location":"user-guide/data-management/#market-data-format","text":"Market data always follows the standard OHLCV format: # Market data structure { 'AAPL' : { 'open' : 100.0 , 'high' : 102.5 , 'low' : 99.0 , 'close' : 101.2 , 'volume' : 1000000.0 } }","title":"Market Data Format"},{"location":"user-guide/data-management/#alternative-data-format","text":"Alternative data can have any structure, but should be consistent: # Sentiment data structure { 'sentiment:AAPL' : { 'sentiment_score' : 0.75 , 'volume' : 5000 , 'confidence' : 0.9 } } # Economic data structure { 'fred:GDP' : { 'value' : 21433.2 , 'change' : 0.5 , 'units' : 'Billions of Dollars' } }","title":"Alternative Data Format"},{"location":"user-guide/data-management/#data-source-management","text":"","title":"Data Source Management"},{"location":"user-guide/data-management/#automatic-source-detection","text":"The backtester automatically detects and routes data to the appropriate loader: # The backtester splits tickers based on specifiers market_tickers , alt_tickers = backtester . _split_tickers ( strategy . tickers ) # Market tickers: ['AAPL', 'GOOGL'] # Alt tickers: ['sentiment:AAPL', 'fred:GDP']","title":"Automatic Source Detection"},{"location":"user-guide/data-management/#multiple-alternative-data-sources","text":"You can combine multiple alternative data sources: from portwine.loaders import FREDDataLoader , SentimentDataLoader , NewsDataLoader , AlternativeDataLoader # Multiple alternative data loaders fred_loader = FREDDataLoader ( api_key = 'your_fred_key' ) sentiment_loader = SentimentDataLoader ( 'path/to/sentiment/' ) news_loader = NewsDataLoader ( 'path/to/news/' ) # Initialize the main alternative data loader with all sub-loaders alt_loader = AlternativeDataLoader () alt_loader . add_loader ( 'fred' , fred_loader ) alt_loader . add_loader ( 'sentiment' , sentiment_loader ) alt_loader . add_loader ( 'news' , news_loader ) # Strategy with multiple data sources class MultiSourceStrategy ( StrategyBase ): def __init__ ( self ): self . tickers = [ # Market data 'AAPL' , 'GOOGL' , # Economic data 'fred:GDP' , 'fred:UNRATE' , # Sentiment data 'sentiment:AAPL' , 'sentiment:GOOGL' , # News data 'news:AAPL' , 'news:GOOGL' ] super () . __init__ ( self . tickers ) def step ( self , current_date , daily_data ): # Access different data types aapl_price = daily_data . get ( 'AAPL' , {}) . get ( 'close' ) gdp = daily_data . get ( 'fred:GDP' , {}) . get ( 'value' ) sentiment = daily_data . get ( 'sentiment:AAPL' , {}) . get ( 'sentiment_score' ) news_count = daily_data . get ( 'news:AAPL' , {}) . get ( 'article_count' ) # Combine all signals if ( aapl_price and gdp and sentiment and news_count ): # Your strategy logic here pass","title":"Multiple Alternative Data Sources"},{"location":"user-guide/data-management/#best-practices-for-alternative-data","text":"","title":"Best Practices for Alternative Data"},{"location":"user-guide/data-management/#1-consistent-naming","text":"Use consistent specifier prefixes: # Good: Consistent naming alt_tickers = [ 'sentiment:AAPL' , 'sentiment:GOOGL' , 'news:AAPL' , 'news:GOOGL' , 'fred:GDP' , 'fred:UNRATE' ] # Avoid: Inconsistent naming alt_tickers = [ 'sentiment:AAPL' , 'news_GOOGL' , # Mixed separators 'FRED:GDP' , 'fred:UNRATE' # Mixed case ]","title":"1. Consistent Naming"},{"location":"user-guide/data-management/#2-data-synchronization","text":"Ensure alternative data aligns with market data dates: def synchronize_alt_data ( market_data , alt_data ): \"\"\"Align alternative data with market data dates.\"\"\" market_dates = set ( market_data [ 'AAPL' ] . index ) for ticker , df in alt_data . items (): # Filter to market trading days alt_data [ ticker ] = df [ df . index . isin ( market_dates )] return alt_data","title":"2. Data Synchronization"},{"location":"user-guide/data-management/#3-missing-data-handling","text":"Handle missing alternative data gracefully: def step ( self , current_date , daily_data ): allocations = {} for ticker in self . market_tickers : # Check if we have both market and alternative data has_market = ticker in daily_data and daily_data [ ticker ] is not None has_sentiment = f 'sentiment: { ticker } ' in daily_data and daily_data [ f 'sentiment: { ticker } ' ] is not None if has_market and has_sentiment : # Use both data sources price = daily_data [ ticker ][ 'close' ] sentiment = daily_data [ f 'sentiment: { ticker } ' ][ 'sentiment_score' ] allocations [ ticker ] = self . calculate_weight ( price , sentiment ) elif has_market : # Fall back to market data only allocations [ ticker ] = self . calculate_weight_market_only ( daily_data [ ticker ]) else : # No data available allocations [ ticker ] = 0.0 return allocations","title":"3. Missing Data Handling"},{"location":"user-guide/data-management/#creating-custom-alternative-data-loaders","text":"To create a custom alternative data loader: from portwine.loaders.base import MarketDataLoader class CustomAltDataLoader ( MarketDataLoader ): def __init__ ( self , data_path , source_name ): self . data_path = data_path self . source_name = source_name # e.g., 'sentiment', 'news' super () . __init__ () def load_ticker ( self , ticker ): # Extract base ticker from specifier if not ticker . startswith ( f ' { self . source_name } :' ): return None base_ticker = ticker . replace ( f ' { self . source_name } :' , '' ) file_path = f \" { self . data_path } / { base_ticker } .csv\" if not os . path . exists ( file_path ): return None df = pd . read_csv ( file_path , parse_dates = [ 'date' ], index_col = 'date' ) # Return whatever columns your alternative data has return df # Usage sentiment_loader = CustomAltDataLoader ( 'path/to/data/' , 'sentiment' ) data = sentiment_loader . fetch_data ([ 'sentiment:AAPL' , 'sentiment:GOOGL' ]) This system provides flexibility to combine any type of alternative data with market data while maintaining clean separation between different data sources.","title":"Creating Custom Alternative Data Loaders"},{"location":"user-guide/data-management/#data-caching_1","text":"","title":"Data Caching"},{"location":"user-guide/data-management/#implementing-caching","text":"import pickle import os class CachedDataLoader ( MarketDataLoader ): def __init__ ( self , base_loader , cache_dir = './cache' ): self . base_loader = base_loader self . cache_dir = cache_dir os . makedirs ( cache_dir , exist_ok = True ) def fetch_data ( self , tickers ): \"\"\"Fetch data with caching.\"\"\" cached_data = {} uncached_tickers = [] # Check cache first for ticker in tickers : cache_file = f \" { self . cache_dir } / { ticker } .pkl\" if os . path . exists ( cache_file ): with open ( cache_file , 'rb' ) as f : cached_data [ ticker ] = pickle . load ( f ) else : uncached_tickers . append ( ticker ) # Fetch uncached data if uncached_tickers : new_data = self . base_loader . fetch_data ( uncached_tickers ) # Cache new data for ticker , df in new_data . items (): cache_file = f \" { self . cache_dir } / { ticker } .pkl\" with open ( cache_file , 'wb' ) as f : pickle . dump ( df , f ) cached_data [ ticker ] = df return cached_data # Use cached loader cached_loader = CachedDataLoader ( base_loader )","title":"Implementing Caching"},{"location":"user-guide/data-management/#best-practices","text":"","title":"Best Practices"},{"location":"user-guide/data-management/#1-data-quality-checks","text":"def check_data_quality ( data_dict ): \"\"\"Comprehensive data quality check.\"\"\" issues = [] for ticker , df in data_dict . items (): # Check for required columns if not all ( col in df . columns for col in [ 'open' , 'high' , 'low' , 'close' , 'volume' ]): issues . append ( f \" { ticker } : Missing required columns\" ) # Check for negative prices if ( df [[ 'open' , 'high' , 'low' , 'close' ]] <= 0 ) . any () . any (): issues . append ( f \" { ticker } : Negative prices detected\" ) # Check for price consistency if not (( df [ 'low' ] <= df [ 'open' ]) & ( df [ 'low' ] <= df [ 'close' ]) & ( df [ 'high' ] >= df [ 'open' ]) & ( df [ 'high' ] >= df [ 'close' ])) . all (): issues . append ( f \" { ticker } : Price consistency issues\" ) # Check for reasonable volume if ( df [ 'volume' ] < 0 ) . any (): issues . append ( f \" { ticker } : Negative volume detected\" ) return issues # Run quality checks issues = check_data_quality ( data ) if issues : print ( \"Data quality issues found:\" ) for issue in issues : print ( f \" - { issue } \" )","title":"1. Data Quality Checks"},{"location":"user-guide/data-management/#2-data-synchronization_1","text":"def synchronize_data ( data_dict ): \"\"\"Ensure all tickers have data for the same date range.\"\"\" # Find common date range all_dates = [] for df in data_dict . values (): all_dates . extend ( df . index . tolist ()) common_start = max ( df . index . min () for df in data_dict . values ()) common_end = min ( df . index . max () for df in data_dict . values ()) # Filter to common range synchronized_data = {} for ticker , df in data_dict . items (): mask = ( df . index >= common_start ) & ( df . index <= common_end ) synchronized_data [ ticker ] = df [ mask ] return synchronized_data # Synchronize your data sync_data = synchronize_data ( data )","title":"2. Data Synchronization"},{"location":"user-guide/data-management/#3-memory-management","text":"# For large datasets, consider loading data in chunks def load_data_in_chunks ( data_loader , tickers , chunk_size = 100 ): \"\"\"Load data in chunks to manage memory.\"\"\" all_data = {} for i in range ( 0 , len ( tickers ), chunk_size ): chunk_tickers = tickers [ i : i + chunk_size ] chunk_data = data_loader . fetch_data ( chunk_tickers ) all_data . update ( chunk_data ) # Optional: clear memory del chunk_data return all_data","title":"3. Memory Management"},{"location":"user-guide/data-management/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"user-guide/data-management/#common-issues","text":"Missing Data Files # Check if files exist import os for ticker in tickers : file_path = f \"data_path/ { ticker } .csv\" if not os . path . exists ( file_path ): print ( f \"Warning: { file_path } not found\" ) Date Format Issues # Ensure proper date parsing df . index = pd . to_datetime ( df . index , errors = 'coerce' ) df = df . dropna () # Remove rows with invalid dates Timezone Issues # Normalize timezones df . index = df . index . tz_localize ( None ) # Remove timezone info","title":"Common Issues"},{"location":"user-guide/data-management/#next-steps","text":"Learn about building strategies Explore backtesting Check out performance analysis","title":"Next Steps"},{"location":"user-guide/strategies/","text":"Building Strategies Strategies in portwine are the heart of your backtesting system. They define how your portfolio allocates capital based on market conditions. Strategies are the core components of portwine that define how your portfolio allocates capital based on market conditions. Online Architecture Portwine uses an online architecture where strategies process data one time period at a time. This means: Single Time Period Data : Each call to step() receives data for only the current trading day No Historical Context : Strategies do not have access to previous time periods' data unless they explicitly store it Self-Contained Indicators : All technical indicators, moving averages, momentum calculations, and other analysis must be implemented within the strategy itself State Management : Strategies must maintain their own state (price history, indicators, etc.) across time periods This architecture is designed for: Real-time trading : Strategies can be deployed in live trading environments Memory efficiency : Only current data is processed at each step Scalability : Strategies can handle large datasets without loading everything into memory Why This Matters # \u274c WRONG - This won't work in portwine def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # This assumes you have access to historical data # But portwine only gives you current day data! historical_prices = get_historical_prices ( ticker , start_date , end_date ) # Not available sma_20 = calculate_sma ( historical_prices , 20 ) # Can't calculate without history return allocations # \u2705 CORRECT - Store and update indicators within the strategy class ProperStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Store price history within the strategy self . price_history = { ticker : [] for ticker in tickers } self . sma_20 = { ticker : None for ticker in tickers } def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Update price history with current data for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) # Calculate indicators using stored history if len ( self . price_history [ ticker ]) >= 20 : recent_prices = self . price_history [ ticker ][ - 20 :] self . sma_20 [ ticker ] = sum ( recent_prices ) / len ( recent_prices ) # Use the calculated indicators for allocation decisions allocations = self . calculate_allocations () return allocations Strategy Basics All strategies in portwine inherit from StrategyBase and implement a step method. This method receives the current date and market data, then returns allocation weights. from portwine import StrategyBase class MyStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) # Initialize your strategy state here def step ( self , current_date , daily_data ): \"\"\" Process daily data and return allocations Parameters ---------- current_date : datetime Current trading date daily_data : dict Dictionary with ticker -> OHLCV data Returns ------- dict Ticker -> allocation weight (0.0 to 1.0) \"\"\" # Your strategy logic here allocations = {} for ticker in self . tickers : allocations [ ticker ] = 0.0 return allocations The Step Method The step method is called for each trading day and receives: current_date : The current trading date as a datetime object daily_data : A dictionary where keys are tickers and values are OHLCV data dictionaries Daily Data Format daily_data = { 'AAPL' : { 'open' : 150.0 , 'high' : 152.0 , 'low' : 149.0 , 'close' : 151.0 , 'volume' : 1000000 }, 'GOOGL' : { 'open' : 2800.0 , 'high' : 2820.0 , 'low' : 2790.0 , 'close' : 2810.0 , 'volume' : 500000 }, 'FRED:SP500' : { 'open' : 4500.0 , 'high' : 4510.0 , 'low' : 4495.0 , 'close' : 4505.0 , 'volume' : None # Some alternative data may not have volume }, 'SENTIMENT:AAPL' : { 'sentiment_score' : 0.75 , 'confidence' : 0.92 , 'source_count' : 150 }, 'EARNINGS:GOOGL' : { 'eps' : 2.45 , 'revenue' : 75000000000 , 'guidance' : 'positive' } # ... more tickers including alternative data sources } Important Notes: The daily_data dictionary is guaranteed to contain keys for all tickers in your strategy, even if no market data exists for that day (values will be None ) Alternative data sources appear as separate tickers with the format \"SOURCE:TICKER\" (e.g., \"FRED:SP500\" , \"SENTIMENT:AAPL\" ) Alternative data sources can define their own schemas - they are not limited to OHLCV format and can include any fields relevant to their data type Each alternative data loader should document its schema so you know what fields are available Some alternative data sources may not have all OHLCV fields (e.g., volume might be None ) Always check for None values and handle missing data gracefully in your strategy logic Example: Simple Equal Weight Strategy class EqualWeightStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) def step ( self , current_date , daily_data ): # Equal weight allocation weight = 1.0 / len ( self . tickers ) return { ticker : weight for ticker in self . tickers } Example: Moving Average Crossover class MACrossoverStrategy ( StrategyBase ): def __init__ ( self , tickers , short_window = 10 , long_window = 50 ): super () . __init__ ( tickers ) self . short_window = short_window self . long_window = long_window self . price_history = { ticker : [] for ticker in tickers } def step ( self , current_date , daily_data ): # Update price history for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) allocations = {} for ticker in self . tickers : prices = self . price_history [ ticker ] if len ( prices ) >= self . long_window : short_ma = sum ( prices [ - self . short_window :]) / self . short_window long_ma = sum ( prices [ - self . long_window :]) / self . long_window # Buy signal when short MA > long MA if short_ma > long_ma : allocations [ ticker ] = 1.0 / len ( self . tickers ) else : allocations [ ticker ] = 0.0 else : allocations [ ticker ] = 0.0 return allocations Strategy State Management Strategies can maintain state between calls to step : class StatefulStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) self . position_history = [] self . last_rebalance_date = None def step ( self , current_date , daily_data ): # Use state to make decisions if self . should_rebalance ( current_date ): self . last_rebalance_date = current_date # ... rebalancing logic # ... rest of strategy logic Best Practices 1. Handle Missing Data def step ( self , current_date , daily_data ): allocations = {} for ticker in self . tickers : if ticker in daily_data and daily_data [ ticker ] is not None : # Process valid data allocations [ ticker ] = self . calculate_weight ( ticker , daily_data [ ticker ]) else : # Handle missing data allocations [ ticker ] = 0.0 return allocations 2. Validate Allocations def step ( self , current_date , daily_data ): allocations = self . calculate_allocations ( daily_data ) # Ensure weights sum to 1.0 (or 0.0 for cash) total_weight = sum ( allocations . values ()) if total_weight > 0 : # Normalize weights for ticker in allocations : allocations [ ticker ] /= total_weight return allocations 3. Use Efficient Data Structures def __init__ ( self , tickers ): super () . __init__ ( tickers ) # Pre-allocate data structures self . price_history = { ticker : [] for ticker in tickers } self . signals = { ticker : 0.0 for ticker in tickers } Advanced Features Alternative Data Support Strategies can access alternative data through the backtester: def step ( self , current_date , daily_data ): # Access alternative data with custom schemas if 'FRED:SP500' in daily_data : sp500_data = daily_data [ 'FRED:SP500' ] # Use alternative data in your strategy if sp500_data and sp500_data [ 'close' ] > 4500 : # SP500 is above threshold, adjust allocations pass # Access sentiment data with custom schema if 'SENTIMENT:AAPL' in daily_data : sentiment_data = daily_data [ 'SENTIMENT:AAPL' ] if sentiment_data and sentiment_data [ 'sentiment_score' ] > 0.7 : # High sentiment, consider overweighting pass # Access earnings data with custom schema if 'EARNINGS:GOOGL' in daily_data : earnings_data = daily_data [ 'EARNINGS:GOOGL' ] if earnings_data and earnings_data [ 'guidance' ] == 'positive' : # Positive guidance, bullish signal pass Calendar Awareness Strategies can be aware of trading calendars: def step ( self , current_date , daily_data ): # Check if it's a rebalancing day if current_date . weekday () == 4 : # Friday # Weekly rebalancing logic pass Next Steps Learn about backtesting your strategies Explore data management Check out performance analysis","title":"Strategies"},{"location":"user-guide/strategies/#building-strategies","text":"Strategies in portwine are the heart of your backtesting system. They define how your portfolio allocates capital based on market conditions. Strategies are the core components of portwine that define how your portfolio allocates capital based on market conditions.","title":"Building Strategies"},{"location":"user-guide/strategies/#online-architecture","text":"Portwine uses an online architecture where strategies process data one time period at a time. This means: Single Time Period Data : Each call to step() receives data for only the current trading day No Historical Context : Strategies do not have access to previous time periods' data unless they explicitly store it Self-Contained Indicators : All technical indicators, moving averages, momentum calculations, and other analysis must be implemented within the strategy itself State Management : Strategies must maintain their own state (price history, indicators, etc.) across time periods This architecture is designed for: Real-time trading : Strategies can be deployed in live trading environments Memory efficiency : Only current data is processed at each step Scalability : Strategies can handle large datasets without loading everything into memory","title":"Online Architecture"},{"location":"user-guide/strategies/#why-this-matters","text":"# \u274c WRONG - This won't work in portwine def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # This assumes you have access to historical data # But portwine only gives you current day data! historical_prices = get_historical_prices ( ticker , start_date , end_date ) # Not available sma_20 = calculate_sma ( historical_prices , 20 ) # Can't calculate without history return allocations # \u2705 CORRECT - Store and update indicators within the strategy class ProperStrategy ( StrategyBase ): def __init__ ( self , tickers : List [ str ]): super () . __init__ ( tickers ) # Store price history within the strategy self . price_history = { ticker : [] for ticker in tickers } self . sma_20 = { ticker : None for ticker in tickers } def step ( self , current_date : pd . Timestamp , daily_data : Dict [ str , Dict ]) -> Dict [ str , float ]: # Update price history with current data for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) # Calculate indicators using stored history if len ( self . price_history [ ticker ]) >= 20 : recent_prices = self . price_history [ ticker ][ - 20 :] self . sma_20 [ ticker ] = sum ( recent_prices ) / len ( recent_prices ) # Use the calculated indicators for allocation decisions allocations = self . calculate_allocations () return allocations","title":"Why This Matters"},{"location":"user-guide/strategies/#strategy-basics","text":"All strategies in portwine inherit from StrategyBase and implement a step method. This method receives the current date and market data, then returns allocation weights. from portwine import StrategyBase class MyStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) # Initialize your strategy state here def step ( self , current_date , daily_data ): \"\"\" Process daily data and return allocations Parameters ---------- current_date : datetime Current trading date daily_data : dict Dictionary with ticker -> OHLCV data Returns ------- dict Ticker -> allocation weight (0.0 to 1.0) \"\"\" # Your strategy logic here allocations = {} for ticker in self . tickers : allocations [ ticker ] = 0.0 return allocations","title":"Strategy Basics"},{"location":"user-guide/strategies/#the-step-method","text":"The step method is called for each trading day and receives: current_date : The current trading date as a datetime object daily_data : A dictionary where keys are tickers and values are OHLCV data dictionaries","title":"The Step Method"},{"location":"user-guide/strategies/#daily-data-format","text":"daily_data = { 'AAPL' : { 'open' : 150.0 , 'high' : 152.0 , 'low' : 149.0 , 'close' : 151.0 , 'volume' : 1000000 }, 'GOOGL' : { 'open' : 2800.0 , 'high' : 2820.0 , 'low' : 2790.0 , 'close' : 2810.0 , 'volume' : 500000 }, 'FRED:SP500' : { 'open' : 4500.0 , 'high' : 4510.0 , 'low' : 4495.0 , 'close' : 4505.0 , 'volume' : None # Some alternative data may not have volume }, 'SENTIMENT:AAPL' : { 'sentiment_score' : 0.75 , 'confidence' : 0.92 , 'source_count' : 150 }, 'EARNINGS:GOOGL' : { 'eps' : 2.45 , 'revenue' : 75000000000 , 'guidance' : 'positive' } # ... more tickers including alternative data sources } Important Notes: The daily_data dictionary is guaranteed to contain keys for all tickers in your strategy, even if no market data exists for that day (values will be None ) Alternative data sources appear as separate tickers with the format \"SOURCE:TICKER\" (e.g., \"FRED:SP500\" , \"SENTIMENT:AAPL\" ) Alternative data sources can define their own schemas - they are not limited to OHLCV format and can include any fields relevant to their data type Each alternative data loader should document its schema so you know what fields are available Some alternative data sources may not have all OHLCV fields (e.g., volume might be None ) Always check for None values and handle missing data gracefully in your strategy logic","title":"Daily Data Format"},{"location":"user-guide/strategies/#example-simple-equal-weight-strategy","text":"class EqualWeightStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) def step ( self , current_date , daily_data ): # Equal weight allocation weight = 1.0 / len ( self . tickers ) return { ticker : weight for ticker in self . tickers }","title":"Example: Simple Equal Weight Strategy"},{"location":"user-guide/strategies/#example-moving-average-crossover","text":"class MACrossoverStrategy ( StrategyBase ): def __init__ ( self , tickers , short_window = 10 , long_window = 50 ): super () . __init__ ( tickers ) self . short_window = short_window self . long_window = long_window self . price_history = { ticker : [] for ticker in tickers } def step ( self , current_date , daily_data ): # Update price history for ticker in self . tickers : if daily_data . get ( ticker ): self . price_history [ ticker ] . append ( daily_data [ ticker ][ 'close' ]) allocations = {} for ticker in self . tickers : prices = self . price_history [ ticker ] if len ( prices ) >= self . long_window : short_ma = sum ( prices [ - self . short_window :]) / self . short_window long_ma = sum ( prices [ - self . long_window :]) / self . long_window # Buy signal when short MA > long MA if short_ma > long_ma : allocations [ ticker ] = 1.0 / len ( self . tickers ) else : allocations [ ticker ] = 0.0 else : allocations [ ticker ] = 0.0 return allocations","title":"Example: Moving Average Crossover"},{"location":"user-guide/strategies/#strategy-state-management","text":"Strategies can maintain state between calls to step : class StatefulStrategy ( StrategyBase ): def __init__ ( self , tickers ): super () . __init__ ( tickers ) self . position_history = [] self . last_rebalance_date = None def step ( self , current_date , daily_data ): # Use state to make decisions if self . should_rebalance ( current_date ): self . last_rebalance_date = current_date # ... rebalancing logic # ... rest of strategy logic","title":"Strategy State Management"},{"location":"user-guide/strategies/#best-practices","text":"","title":"Best Practices"},{"location":"user-guide/strategies/#1-handle-missing-data","text":"def step ( self , current_date , daily_data ): allocations = {} for ticker in self . tickers : if ticker in daily_data and daily_data [ ticker ] is not None : # Process valid data allocations [ ticker ] = self . calculate_weight ( ticker , daily_data [ ticker ]) else : # Handle missing data allocations [ ticker ] = 0.0 return allocations","title":"1. Handle Missing Data"},{"location":"user-guide/strategies/#2-validate-allocations","text":"def step ( self , current_date , daily_data ): allocations = self . calculate_allocations ( daily_data ) # Ensure weights sum to 1.0 (or 0.0 for cash) total_weight = sum ( allocations . values ()) if total_weight > 0 : # Normalize weights for ticker in allocations : allocations [ ticker ] /= total_weight return allocations","title":"2. Validate Allocations"},{"location":"user-guide/strategies/#3-use-efficient-data-structures","text":"def __init__ ( self , tickers ): super () . __init__ ( tickers ) # Pre-allocate data structures self . price_history = { ticker : [] for ticker in tickers } self . signals = { ticker : 0.0 for ticker in tickers }","title":"3. Use Efficient Data Structures"},{"location":"user-guide/strategies/#advanced-features","text":"","title":"Advanced Features"},{"location":"user-guide/strategies/#alternative-data-support","text":"Strategies can access alternative data through the backtester: def step ( self , current_date , daily_data ): # Access alternative data with custom schemas if 'FRED:SP500' in daily_data : sp500_data = daily_data [ 'FRED:SP500' ] # Use alternative data in your strategy if sp500_data and sp500_data [ 'close' ] > 4500 : # SP500 is above threshold, adjust allocations pass # Access sentiment data with custom schema if 'SENTIMENT:AAPL' in daily_data : sentiment_data = daily_data [ 'SENTIMENT:AAPL' ] if sentiment_data and sentiment_data [ 'sentiment_score' ] > 0.7 : # High sentiment, consider overweighting pass # Access earnings data with custom schema if 'EARNINGS:GOOGL' in daily_data : earnings_data = daily_data [ 'EARNINGS:GOOGL' ] if earnings_data and earnings_data [ 'guidance' ] == 'positive' : # Positive guidance, bullish signal pass","title":"Alternative Data Support"},{"location":"user-guide/strategies/#calendar-awareness","text":"Strategies can be aware of trading calendars: def step ( self , current_date , daily_data ): # Check if it's a rebalancing day if current_date . weekday () == 4 : # Friday # Weekly rebalancing logic pass","title":"Calendar Awareness"},{"location":"user-guide/strategies/#next-steps","text":"Learn about backtesting your strategies Explore data management Check out performance analysis","title":"Next Steps"}]}